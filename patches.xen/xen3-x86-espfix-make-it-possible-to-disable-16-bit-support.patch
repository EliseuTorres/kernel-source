From: "H. Peter Anvin" <hpa@zytor.com>
Date: Sun, 4 May 2014 10:36:22 -0700
Subject: x86, espfix: Make it possible to disable 16-bit support
Git-commit: 34273f41d57ee8d854dcd2a1d754cbb546cb548f
Patch-mainline: v3.16-rc1
References: bsc#907818,CVE-2014-9090

Embedded systems, which may be very memory-size-sensitive, are
extremely unlikely to ever encounter any 16-bit software, so make it
a CONFIG_EXPERT option to turn off support for any 16-bit software
whatsoever.

Signed-off-by: H. Peter Anvin <hpa@zytor.com>
Link: http://lkml.kernel.org/r/1398816946-3351-1-git-send-email-hpa@linux.intel.com
Acked-by: Borislav Petkov <bp@suse.de>
--
Automatically created from "patches.fixes/x86-espfix-make-it-possible-to-disable-16-bit-support.patch" by xen-port-patches.py

--- 13.1.orig/arch/x86/kernel/entry_32-xen.S	2013-08-12 13:00:59.000000000 +0200
+++ 13.1/arch/x86/kernel/entry_32-xen.S	2014-07-29 11:21:59.000000000 +0200
@@ -556,7 +556,7 @@ syscall_exit:
 restore_all:
 	TRACE_IRQS_IRET
 restore_all_notrace:
-#ifndef CONFIG_XEN
+#ifdef CONFIG_X86_ESPFIX32
 	movl PT_EFLAGS(%esp), %eax	# mix EFLAGS, SS and CS
 	# Warning: PT_OLDSS(%esp) contains the wrong/random values if we
 	# are returning to the kernel.
@@ -567,9 +567,9 @@ restore_all_notrace:
 	cmpl $((SEGMENT_LDT << 8) | USER_RPL), %eax
 	CFI_REMEMBER_STATE
 	je ldt_ss			# returning to user-space with LDT SS
+#endif
 restore_nocheck:
-#else
-restore_nocheck:
+#ifdef CONFIG_XEN
 	movl PT_EFLAGS(%esp), %eax
 	testl $(X86_EFLAGS_VM|NMI_MASK), %eax
 	CFI_REMEMBER_STATE
@@ -593,7 +593,7 @@ ENTRY(iret_exc)
 	_ASM_EXTABLE(irq_return,iret_exc)
 
 	CFI_RESTORE_STATE
-#ifndef CONFIG_XEN
+#ifdef CONFIG_X86_ESPFIX32
 ldt_ss:
 	larl PT_OLDSS(%esp), %eax
 	jnz restore_nocheck
@@ -641,7 +641,8 @@ ldt_ss:
 	lss (%esp), %esp		/* switch to espfix segment */
 	CFI_ADJUST_CFA_OFFSET -8
 	jmp restore_nocheck
-#else
+#endif
+#ifdef CONFIG_XEN
         ALIGN
 restore_all_enable_events:
 	TRACE_IRQS_ON
@@ -771,6 +772,7 @@ END(syscall_badsys)
  * the high word of the segment base from the GDT and swiches to the
  * normal stack and adjusts ESP with the matching offset.
  */
+#ifdef CONFIG_X86_ESPFIX32
 	/* fixup the stack */
 	mov GDT_ESPFIX_SS + 4, %al /* bits 16..23 */
 	mov GDT_ESPFIX_SS + 7, %ah /* bits 24..31 */
@@ -780,8 +782,10 @@ END(syscall_badsys)
 	pushl_cfi %eax
 	lss (%esp), %esp		/* switch to the normal stack segment */
 	CFI_ADJUST_CFA_OFFSET -8
+#endif
 .endm
 .macro UNWIND_ESPFIX_STACK
+#ifdef CONFIG_X86_ESPFIX32
 	movl %ss, %eax
 	/* see if on espfix stack */
 	cmpw $__ESPFIX_SS, %ax
@@ -792,6 +796,7 @@ END(syscall_badsys)
 	/* switch to normal stack */
 	FIXUP_ESPFIX_STACK
 27:
+#endif
 .endm
 
 /*
@@ -1586,12 +1591,14 @@ END(debug)
 ENTRY(nmi)
 	RING0_INT_FRAME
 	ASM_CLAC
+#ifdef CONFIG_X86_ESPFIX32
 	pushl_cfi %eax
-#ifndef CONFIG_XEN
 	movl %ss, %eax
 	cmpw $__ESPFIX_SS, %ax
 	popl_cfi %eax
 	je nmi_espfix_stack
+#endif
+#ifndef CONFIG_XEN
 	cmpl $ia32_sysenter_target,(%esp)
 	je nmi_stack_fixup
 	pushl_cfi %eax
@@ -1631,6 +1638,7 @@ nmi_debug_stack_check:
 	FIX_STACK 24, nmi_stack_correct, 1
 	jmp nmi_stack_correct
 
+#ifdef CONFIG_X86_ESPFIX32
 nmi_espfix_stack:
 	/* We have a RING0_INT_FRAME here.
 	 *
@@ -1652,7 +1660,9 @@ nmi_espfix_stack:
 	lss 12+4(%esp), %esp		# back to espfix stack
 	CFI_ADJUST_CFA_OFFSET -24
 	jmp irq_return
-#else
+#endif
+#else /* CONFIG_XEN */
+ 	pushl_cfi %eax
 	SAVE_ALL
 	xorl %edx,%edx		# zero error code
 	movl %esp,%eax		# pt_regs pointer
--- 13.1.orig/arch/x86/kernel/ldt-xen.c	2012-04-11 13:26:23.000000000 +0200
+++ 13.1/arch/x86/kernel/ldt-xen.c	2014-06-27 10:54:54.000000000 +0200
@@ -234,6 +234,11 @@ static int write_ldt(void __user *ptr, u
 		}
 	}
 
+	if (!IS_ENABLED(CONFIG_X86_16BIT) && !ldt_info.seg_32bit) {
+		error = -EINVAL;
+		goto out_unlock;
+	}
+
 	fill_ldt(&ldt, &ldt_info);
 	if (oldmode)
 		ldt.avl = 0;
