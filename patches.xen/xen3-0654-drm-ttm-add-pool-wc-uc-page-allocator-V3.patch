From 16e7b119a307ca589a3d5eb0bf09cf20a16e617a Mon Sep 17 00:00:00 2001
From: Pauli Nieminen <suokkos@gmail.com>
Date: Thu, 1 Apr 2010 12:44:57 +0000
Patch-mainline: 2.6.35
References: fate#310916
Subject: [PATCH 0654/2588] drm/ttm: add pool wc/uc page allocator V3

On AGP system we might allocate/free routinely uncached or wc memory,
changing page from cached (wb) to uc or wc is very expensive and involves
a lot of flushing. To improve performance this allocator use a pool
of uc,wc pages.

Pools are protected with spinlocks to allow multiple threads to allocate pages
simultanously. Expensive operations are done outside of spinlock to maximize
concurrency.

Pools are linked lists of pages that were recently freed. mm shrink callback
allows kernel to claim back pages when they are required for something else.

Fixes:
* set_pages_array_wb handles highmem pages so we don't have to remove them
  from pool.
* Add count parameter to ttm_put_pages to avoid looping in free code.
* Change looping from _safe to normal in pool fill error path.
* Initialize sum variable and make the loop prettier in get_num_unused_pages.

* Moved pages_freed reseting inside the loop in ttm_page_pool_free.
* Add warning comment about spinlock context in ttm_page_pool_free.

Based on Jerome Glisse's and Dave Airlie's pool allocator.

Signed-off-by: Jerome Glisse <jglisse@redhat.com>
Signed-off-by: Dave Airlie <airlied@redhat.com>
Signed-off-by: Pauli Nieminen <suokkos@gmail.com>
Reviewed-by: Jerome Glisse <jglisse@redhat.com>
Signed-off-by: Dave Airlie <airlied@redhat.com>
(cherry picked from commit 1403b1a38e8b19a4cc17e2c158e278628943a436)

Signed-off-by: Takashi Iwai <tiwai@suse.de>
Automatically created from "patches.drm/0654-drm-ttm-add-pool-wc-uc-page-allocator-V3.patch" by xen-port-patches.py

--- sle11sp2-2011-08-08.orig/drivers/gpu/drm/ttm/ttm_page_alloc.c	2011-08-08 12:59:54.000000000 +0200
+++ sle11sp2-2011-08-08/drivers/gpu/drm/ttm/ttm_page_alloc.c	2011-08-08 14:13:48.000000000 +0200
@@ -498,6 +498,19 @@ static int ttm_alloc_new_pages(struct li
 	for (i = 0, cpages = 0; i < count; ++i) {
 		p = alloc_page(gfp_flags);
 
+#ifdef CONFIG_XEN
+		if (p && (gfp_flags & __GFP_DMA32)) {
+			r = xen_limit_pages_to_max_mfn(p, 0, 32);
+			if (r) {
+				__free_page(p);
+				printk(KERN_ERR TTM_PFX
+				       "Cannot restrict page (%d).", r);
+				p = NULL;
+			} else if (gfp_flags & __GFP_ZERO)
+				clear_page(page_address(p));
+		}
+#endif
+
 		if (!p) {
 			printk(KERN_ERR TTM_PFX "Unable to get page %u.\n", i);
 
