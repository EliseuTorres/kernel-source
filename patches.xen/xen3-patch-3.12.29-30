From: Jiri Slaby <jslaby@suse.cz>
Subject: Linux 3.12.30
Patch-mainline: Never, SUSE-Xen specific

Signed-off-by: Jiri Slaby <jslaby@suse.cz>
Automatically created from "patches.kernel.org/patch-3.12.29-30" by xen-port-patches.py

--- sle12.orig/arch/x86/include/mach-xen/asm/tlbflush.h	2013-10-10 17:49:53.000000000 +0200
+++ sle12/arch/x86/include/mach-xen/asm/tlbflush.h	2014-01-09 12:02:13.000000000 +0100
@@ -19,7 +19,7 @@ static inline void __flush_tlb_all(void)
 
 static inline void __flush_tlb_one(unsigned long addr)
 {
-	count_vm_event(NR_TLB_LOCAL_FLUSH_ONE);
+	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);
 	__flush_tlb_single(addr);
 }
 
@@ -49,13 +49,13 @@ static inline void __flush_tlb_one(unsig
  */
 static inline void __flush_tlb_up(void)
 {
-	count_vm_event(NR_TLB_LOCAL_FLUSH_ALL);
+	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);
 	__flush_tlb();
 }
 
 static inline void flush_tlb_all(void)
 {
-	count_vm_event(NR_TLB_LOCAL_FLUSH_ALL);
+	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);
 	__flush_tlb_all();
 }
 
--- sle12.orig/arch/x86/mm/tlb-xen.c	2013-09-26 15:33:39.000000000 +0200
+++ sle12/arch/x86/mm/tlb-xen.c	2014-02-20 10:49:08.000000000 +0100
@@ -9,37 +9,12 @@
 #include <asm/cache.h>
 #include <linux/debugfs.h>
 
-/*
- * It can find out the THP large page, or
- * HUGETLB page in tlb_flush when THP disabled
- */
-static inline unsigned long has_large_page(struct mm_struct *mm,
-				 unsigned long start, unsigned long end)
-{
-	pgd_t *pgd;
-	pud_t *pud;
-	pmd_t *pmd;
-	unsigned long addr = ALIGN(start, HPAGE_SIZE);
-	for (; addr < end; addr += HPAGE_SIZE) {
-		pgd = pgd_offset(mm, addr);
-		if (likely(!pgd_none(*pgd))) {
-			pud = pud_offset(pgd, addr);
-			if (likely(!pud_none(*pud))) {
-				pmd = pmd_offset(pud, addr);
-				if (likely(!pmd_none(*pmd)))
-					if (pmd_large(*pmd))
-						return addr;
-			}
-		}
-	}
-	return 0;
-}
-
 void flush_tlb_mm_range(struct mm_struct *mm, unsigned long start,
 				unsigned long end, unsigned long vmflag)
 {
 	unsigned long addr;
 	unsigned act_entries, tlb_entries = 0;
+	unsigned long nr_base_pages;
 	const cpumask_t *mask = mm_cpumask(mm);
 	cpumask_var_t temp;
 
@@ -65,21 +40,22 @@ void flush_tlb_mm_range(struct mm_struct
 		tlb_entries = tlb_lli_4k[ENTRIES];
 	else
 		tlb_entries = tlb_lld_4k[ENTRIES];
+
 	/* Assume all of TLB entries was occupied by this task */
-	act_entries = mm->total_vm > tlb_entries ? tlb_entries : mm->total_vm;
+	act_entries = tlb_entries >> tlb_flushall_shift;
+	act_entries = mm->total_vm > act_entries ? act_entries : mm->total_vm;
+	nr_base_pages = (end - start) >> PAGE_SHIFT;
 
 	/* tlb_flushall_shift is on balance point, details in commit log */
-	if (((end - start) >> PAGE_SHIFT)
-	    <= (act_entries >> tlb_flushall_shift)
-	    && !has_large_page(mm, start, end)) {
+	if (nr_base_pages <= act_entries) {
 		/* flush range by one by one 'invlpg' */
 		for (addr = start; addr < end; addr += PAGE_SIZE) {
-			count_vm_event(NR_TLB_LOCAL_FLUSH_ONE);
+			count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);
 			xen_invlpg_mask(mask, addr);
 		}
 	} else {
 flush_all:
-		count_vm_event(NR_TLB_LOCAL_FLUSH_ALL);
+		count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);
 		xen_tlb_flush_mask(mask);
 	}
 
