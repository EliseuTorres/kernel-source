Subject: hugetlbfs: fix deadlock in unmap_hugepage_range()
From: Gerald Schaefer <gerald.schaefer@de.ibm.com>
Patch-mainline: Yes
Git-commit: d5feaea364281a7e9b80b4712e790ab908d61711
References: bnc#781484,LTC#85449

Symptom:      System hangs. lockdep will show kernel message if configured.
Problem:      git commit cd2934a3 moved the flush_tlb_range() within
              __unmap_hugepage_range() inside the mm->page_table_lock. That
              triggered a deadlock in s390 tlb flushing code, which also
              tries to acquire the page_table_lock.
Solution:     All callers already have an exclusive mm->mmap_sem or
              mm->page_table_lock, so the spin_lock in s390 tlb flushing code
              can be safely removed to fix the deadlock.
Reproduction: Exit a program that is using hugetlbfs pages.

Acked-by: John Jolly <jjolly@suse.de>
---
 arch/s390/include/asm/tlbflush.h |    2 --
 1 file changed, 2 deletions(-)

--- a/arch/s390/include/asm/tlbflush.h
+++ b/arch/s390/include/asm/tlbflush.h
@@ -89,12 +89,10 @@ static inline void __tlb_flush_mm(struct
 
 static inline void __tlb_flush_mm_cond(struct mm_struct * mm)
 {
-	spin_lock(&mm->page_table_lock);
 	if (mm->context.flush_mm) {
 		__tlb_flush_mm(mm);
 		mm->context.flush_mm = 0;
 	}
-	spin_unlock(&mm->page_table_lock);
 }
 
 /*
