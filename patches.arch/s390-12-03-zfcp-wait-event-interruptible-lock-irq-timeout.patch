From: Martin Peschke <mpeschke@linux.vnet.ibm.com>
Subject: zfcp: fix lock imbalance by reworking request queue locking
Patch-mainline: not yet
Git-commit: -
References: bnc#835175, LTC#96825

Description:  zfcp: fix lock imbalance by reworking request queue locking 
Symptom:      Kernel message
              "BUG: workqueue leaked lock or atomic: events/1/0xffffff00/10
              last function: zfcp_fc_wka_port_offline+0x0/0xa0 [zfcp]".
              and call trace, followed by kernel panic. Warnings from the
              code checking tool called sparse hinted at the issue
              "drivers/s390/scsi/zfcp_qdio.c:224:12: warning: context
              imbalance in 'zfcp_qdio_sbal_check' - wrong count at exit
              drivers/s390/scsi/zfcp_qdio.c:244:5: warning: context
              imbalance in 'zfcp_qdio_sbal_get' - unexpected unlock",
Problem:      A locking imbalance in zfcp_qdio_sbal_get() was introduced by
              commit c2af7545aaff3495d9bf9a7608c52f0af86fb194 "[SCSI] zfcp:
              Do not wait for SBALs on stopped queue", which had a new
              code path related to ZFCP_STATUS_ADAPTER_QDIOUP that took an
              early exit without a required lock being held.
Solution:     This patch adds wait_event_interruptible_lock_irq_timeout(),
              which is a straight-forward descendant of
              wait_event_interruptible_timeout() and
              wait_event_interruptible_lock_irq().
              Using wait_event_interruptible_lock_irq_timeout() as a
              replacement for wait_event_interruptible_timeout() nicely
              simplifies and corrects that error-prone locking scheme.
              As an extra we get rid of that crappy lock-unlock-lock
              sequence at the beginning of the critical section.
              The above fix doesn't apply to older code levels which
              use spin_lock_bh(). In order to fix those code levels
              just add the missing lock-statement instead.
Reproduction: CHPID on/off test loop during heavy I/O workload may trigger
              this issue in rare cases.

Signed-off-by: Martin Peschke <mpeschke@linux.vnet.ibm.com>
Acked-by: John Jolly <jjolly@suse.de>
---
 drivers/s390/scsi/zfcp_qdio.c |    8 +----
 include/linux/wait.h          |   57 ++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 59 insertions(+), 6 deletions(-)

--- a/drivers/s390/scsi/zfcp_qdio.c
+++ b/drivers/s390/scsi/zfcp_qdio.c
@@ -223,11 +223,9 @@ int zfcp_qdio_sbals_from_sg(struct zfcp_
 
 static int zfcp_qdio_sbal_check(struct zfcp_qdio *qdio)
 {
-	spin_lock_irq(&qdio->req_q_lock);
 	if (atomic_read(&qdio->req_q_free) ||
 	    !(atomic_read(&qdio->adapter->status) & ZFCP_STATUS_ADAPTER_QDIOUP))
 		return 1;
-	spin_unlock_irq(&qdio->req_q_lock);
 	return 0;
 }
 
@@ -245,9 +243,8 @@ int zfcp_qdio_sbal_get(struct zfcp_qdio
 {
 	long ret;
 
-	spin_unlock_irq(&qdio->req_q_lock);
-	ret = wait_event_interruptible_timeout(qdio->req_q_wq,
-			       zfcp_qdio_sbal_check(qdio), 5 * HZ);
+	ret = wait_event_interruptible_lock_irq_timeout(qdio->req_q_wq,
+		       zfcp_qdio_sbal_check(qdio), qdio->req_q_lock, 5 * HZ);
 
 	if (!(atomic_read(&qdio->adapter->status) & ZFCP_STATUS_ADAPTER_QDIOUP))
 		return -EIO;
@@ -261,7 +258,6 @@ int zfcp_qdio_sbal_get(struct zfcp_qdio
 		zfcp_erp_adapter_reopen(qdio->adapter, 0, "qdsbg_1");
 	}
 
-	spin_lock_irq(&qdio->req_q_lock);
 	return -EIO;
 }
 
--- a/include/linux/wait.h
+++ b/include/linux/wait.h
@@ -531,6 +531,63 @@ do {									\
 	 ? 0 : __wait_event_interruptible_locked(wq, condition, 1, 1))
 
 
+#define __wait_event_interruptible_lock_irq_timeout(wq, condition,	\
+						    lock, ret)		\
+do {									\
+	DEFINE_WAIT(__wait);						\
+									\
+	for (;;) {							\
+		prepare_to_wait(&wq, &__wait, TASK_INTERRUPTIBLE);	\
+		if (condition)						\
+			break;						\
+		if (signal_pending(current)) {				\
+			ret = -ERESTARTSYS;				\
+			break;						\
+		}							\
+		spin_unlock_irq(&lock);					\
+		ret = schedule_timeout(ret);				\
+		spin_lock_irq(&lock);					\
+		if (!ret)						\
+			break;						\
+	}								\
+	finish_wait(&wq, &__wait);					\
+} while (0)
+
+/**
+ * wait_event_interruptible_lock_irq_timeout - sleep until a condition gets true or a timeout elapses.
+ *		The condition is checked under the lock. This is expected
+ *		to be called with the lock taken.
+ * @wq: the waitqueue to wait on
+ * @condition: a C expression for the event to wait for
+ * @lock: a locked spinlock_t, which will be released before schedule()
+ *	  and reacquired afterwards.
+ * @timeout: timeout, in jiffies
+ *
+ * The process is put to sleep (TASK_INTERRUPTIBLE) until the
+ * @condition evaluates to true or signal is received. The @condition is
+ * checked each time the waitqueue @wq is woken up.
+ *
+ * wake_up() has to be called after changing any variable that could
+ * change the result of the wait condition.
+ *
+ * This is supposed to be called while holding the lock. The lock is
+ * dropped before going to sleep and is reacquired afterwards.
+ *
+ * The function returns 0 if the @timeout elapsed, -ERESTARTSYS if it
+ * was interrupted by a signal, and the remaining jiffies otherwise
+ * if the condition evaluated to true before the timeout elapsed.
+ */
+#define wait_event_interruptible_lock_irq_timeout(wq, condition, lock,	\
+						  timeout)		\
+({									\
+	int __ret = timeout;						\
+									\
+	if (!(condition))						\
+		__wait_event_interruptible_lock_irq_timeout(		\
+					wq, condition, lock, __ret);	\
+	__ret;								\
+})
+
 
 #define __wait_event_killable(wq, condition, ret)			\
 do {									\
