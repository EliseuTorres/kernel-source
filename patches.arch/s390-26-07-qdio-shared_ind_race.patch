From: Gerald Schaefer <geraldsc@de.ibm.com>
Subject: qdio: prevent race for shared indicators
References: bnc#659101,LTC#69028
Patch-mainline: Yes

Symptom:     Traffic on qdio devices may hang forever.
Problem:     The shared DSCI is set at the end of the interrupt
             handler to scan the queues that use the shared DSCI
             for further traffic. Since interrupts may be avoided
             if the DSCI is set this can lead to stalled queues.
             Also the usage of the ALSI to detect further incoming
             traffic on the shared DSCI queues is not race safe.
Solution:    Only reset the shared DSCI if it was set at the beginning
             of the interrupt handler so the tasklets for all queues
             that use the shared DSCI are scheduled to run after
             the interrupt handler.

Acked-by: John Jolly <jjolly@suse.de>
---
 drivers/s390/cio/qdio_thinint.c |   43 ++++++++++++++++------------------------
 1 file changed, 18 insertions(+), 25 deletions(-)

--- a/drivers/s390/cio/qdio_thinint.c
+++ b/drivers/s390/cio/qdio_thinint.c
@@ -130,6 +130,7 @@ static inline int shared_ind(struct qdio
  */
 static void tiqdio_thinint_handler(void *ind, void *drv_data)
 {
+	u32 si_used = q_indicators[TIQDIO_SHARED_IND].ind;
 	struct qdio_q *q;
 
 	qdio_perf_stat_inc(&perf_stats.thin_int);
@@ -141,43 +142,35 @@ static void tiqdio_thinint_handler(void
 	if (!css_qdio_omit_svs)
 		do_clear_global_summary();
 
-	/*
-	 * reset local summary indicator (tiqdio_alsi) to stop adapter
-	 * interrupts for now
-	 */
-	xchg((u8 *)ind, 0);
-
 	/* protect tiq_list entries, only changed in activate or shutdown */
 	rcu_read_lock();
 
 	/* check for work on all inbound thinint queues */
-	list_for_each_entry_rcu(q, &tiq_list, entry)
+	list_for_each_entry_rcu(q, &tiq_list, entry) {
 		/* only process queues from changed sets */
-		if (*q->irq_ptr->dsci) {
-
-			/* only clear it if the indicator is non-shared */
-			if (!shared_ind(q->irq_ptr))
-				xchg(q->irq_ptr->dsci, 0);
-			/*
-			 * don't call inbound processing directly since
-			 * that could starve other thinint queues
-			 */
-			tasklet_schedule(&q->tasklet);
-		}
-
+		if (unlikely(shared_ind(q->irq_ptr))) {
+			if (!si_used)
+				continue;
+		} else if (!*q->irq_ptr->dsci)
+			continue;
+
+		/* only clear it if the indicator is non-shared */
+		if (!shared_ind(q->irq_ptr))
+			xchg(q->irq_ptr->dsci, 0);
+		/*
+		 * don't call inbound processing directly since
+		 * that could starve other thinint queues
+		 */
+		tasklet_schedule(&q->tasklet);
+	}
 	rcu_read_unlock();
 
 	/*
 	 * if we used the shared indicator clear it now after all queues
 	 * were processed
 	 */
-	if (atomic_read(&q_indicators[TIQDIO_SHARED_IND].count)) {
+	if (si_used)
 		xchg(&q_indicators[TIQDIO_SHARED_IND].ind, 0);
-
-		/* prevent racing */
-		if (*tiqdio_alsi)
-			xchg(&q_indicators[TIQDIO_SHARED_IND].ind, 1);
-	}
 }
 
 static int set_subchannel_ind(struct qdio_irq *irq_ptr, int reset)
