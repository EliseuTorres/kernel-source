From: Mel Gorman <mgorman@suse.de>
Date: Wed, 30 May 2012 11:13:02 +0100
Subject: [PATCH] paravirt: Split paravirt MMU ops
References: bnc#556135, bnc#754690, FATE#306453
Patch-mainline: No, will be rendered obsolete by future MMU changes

Currently using paravirt ops is mostly an all-or-nothing approach and
tends towards the "all" end of the scale.

There are use cases which do not need the full feature set and the MMU
operations in particular are not needed in many cases but is impossible
to cherry pick on its own.

This patch creates a KVM_MMU and PARAVIRT_MMU option that allows
paravirtualisation support to be configured out if necessary.

All credit goes to Alaxander Graf whose work this patch is completely
based on.

Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 arch/x86/Kconfig                            |   15 +++++++++++++++
 arch/x86/include/asm/fixmap.h               |    2 +-
 arch/x86/include/asm/mmu_context.h          |    4 ++--
 arch/x86/include/asm/paravirt.h             |    8 ++++++++
 arch/x86/include/asm/paravirt_types.h       |    2 ++
 arch/x86/include/asm/pgalloc.h              |    2 +-
 arch/x86/include/asm/pgtable-3level_types.h |    2 +-
 arch/x86/include/asm/pgtable.h              |    2 +-
 arch/x86/include/asm/required-features.h    |    2 +-
 arch/x86/include/asm/system.h               |    7 ++++++-
 arch/x86/include/asm/tlbflush.h             |    4 ++--
 arch/x86/kernel/head_64.S                   |    2 +-
 arch/x86/kernel/kvm.c                       |   19 ++++++++++++++++---
 13 files changed, 57 insertions(+), 14 deletions(-)

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 1744797..4f395b5 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -555,6 +555,18 @@ config KVM_CLOCK
 	  provides the guest with timing infrastructure such as time of day, and
 	  system time
 
+config KVM_MMU
+	bool "KVM PV MMU support"
+	select PARAVIRT_MMU
+	---help---
+	  This option enables the paravirtualized MMU for KVM. In most cases
+	  it's pretty useless and shouldn't be used.
+
+	  It will only cost you performance, because it drags in pv-ops for
+	  memory management.
+
+	  If in doubt, say N.
+
 config KVM_GUEST
 	bool "KVM Guest support"
 	select PARAVIRT
@@ -588,6 +600,9 @@ config PARAVIRT_SPINLOCKS
 config PARAVIRT_CLOCK
 	bool
 
+config PARAVIRT_MMU
+	bool
+
 endif
 
 config PARAVIRT_DEBUG
diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 4729b2b..06ec9d1 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -166,7 +166,7 @@ void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);
 void native_set_fixmap(enum fixed_addresses idx,
 		       phys_addr_t phys, pgprot_t flags);
 
-#ifndef CONFIG_PARAVIRT
+#ifndef CONFIG_PARAVIRT_MMU
 static inline void __set_fixmap(enum fixed_addresses idx,
 				phys_addr_t phys, pgprot_t flags)
 {
diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h
index 8b5393e..00aa12e 100644
--- a/arch/x86/include/asm/mmu_context.h
+++ b/arch/x86/include/asm/mmu_context.h
@@ -6,14 +6,14 @@
 #include <asm/pgalloc.h>
 #include <asm/tlbflush.h>
 #include <asm/paravirt.h>
-#ifndef CONFIG_PARAVIRT
+#ifndef CONFIG_PARAVIRT_MMU
 #include <asm-generic/mm_hooks.h>
 
 static inline void paravirt_activate_mm(struct mm_struct *prev,
 					struct mm_struct *next)
 {
 }
-#endif	/* !CONFIG_PARAVIRT */
+#endif	/* !CONFIG_PARAVIRT_MMU */
 
 /*
  * Used for LDT copy/destruction.
diff --git a/arch/x86/include/asm/paravirt.h b/arch/x86/include/asm/paravirt.h
index ebbc4d8..0a86f78 100644
--- a/arch/x86/include/asm/paravirt.h
+++ b/arch/x86/include/asm/paravirt.h
@@ -59,6 +59,7 @@ static inline void write_cr0(unsigned long x)
 	PVOP_VCALL1(pv_cpu_ops.write_cr0, x);
 }
 
+#ifdef CONFIG_PARAVIRT_MMU
 static inline unsigned long read_cr2(void)
 {
 	return PVOP_CALL0(unsigned long, pv_mmu_ops.read_cr2);
@@ -78,6 +79,7 @@ static inline void write_cr3(unsigned long x)
 {
 	PVOP_VCALL1(pv_mmu_ops.write_cr3, x);
 }
+#endif /* CONFIG_PARAVIRT_MMU */
 
 static inline unsigned long read_cr4(void)
 {
@@ -355,6 +357,7 @@ static inline void startup_ipi_hook(int phys_apicid, unsigned long start_eip,
 }
 #endif
 
+#ifdef CONFIG_PARAVIRT_MMU
 static inline void paravirt_activate_mm(struct mm_struct *prev,
 					struct mm_struct *next)
 {
@@ -708,6 +711,7 @@ static inline void pmd_clear(pmd_t *pmdp)
 	set_pmd(pmdp, __pmd(0));
 }
 #endif	/* CONFIG_X86_PAE */
+#endif  /* CONFIG_PARAVIRT_MMU */
 
 #define  __HAVE_ARCH_START_CONTEXT_SWITCH
 static inline void arch_start_context_switch(struct task_struct *prev)
@@ -720,6 +724,7 @@ static inline void arch_end_context_switch(struct task_struct *next)
 	PVOP_VCALL1(pv_cpu_ops.end_context_switch, next);
 }
 
+#ifdef CONFIG_PARAVIRT_MMU
 #define  __HAVE_ARCH_ENTER_LAZY_MMU_MODE
 static inline void arch_enter_lazy_mmu_mode(void)
 {
@@ -738,6 +743,7 @@ static inline void __set_fixmap(unsigned /* enum fixed_addresses */ idx,
 {
 	pv_mmu_ops.set_fixmap(idx, phys, flags);
 }
+#endif /* CONFIG_PARAVIRT_MMU */
 
 #if defined(CONFIG_SMP) && defined(CONFIG_PARAVIRT_SPINLOCKS)
 
@@ -1013,10 +1019,12 @@ extern void default_banner(void);
 		  call PARA_INDIRECT(pv_cpu_ops+PV_CPU_swapgs)		\
 		 )
 
+#ifdef CONFIG_PARAVIRT_MMU
 #define GET_CR2_INTO_RCX				\
 	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_read_cr2);	\
 	movq %rax, %rcx;				\
 	xorq %rax, %rax;
+#endif /* CONFIG_PARAVIRT_MMU */
 
 #define PARAVIRT_ADJUST_EXCEPTION_FRAME					\
 	PARA_SITE(PARA_PATCH(pv_irq_ops, PV_IRQ_adjust_exception_frame), \
diff --git a/arch/x86/include/asm/paravirt_types.h b/arch/x86/include/asm/paravirt_types.h
index 8288509..453503a 100644
--- a/arch/x86/include/asm/paravirt_types.h
+++ b/arch/x86/include/asm/paravirt_types.h
@@ -338,7 +338,9 @@ struct paravirt_patch_template {
 	struct pv_cpu_ops pv_cpu_ops;
 	struct pv_irq_ops pv_irq_ops;
 	struct pv_apic_ops pv_apic_ops;
+#ifdef CONFIG_PARAVIRT_MMU
 	struct pv_mmu_ops pv_mmu_ops;
+#endif
 	struct pv_lock_ops pv_lock_ops;
 };
 
diff --git a/arch/x86/include/asm/pgalloc.h b/arch/x86/include/asm/pgalloc.h
index b4389a4..84ee977 100644
--- a/arch/x86/include/asm/pgalloc.h
+++ b/arch/x86/include/asm/pgalloc.h
@@ -7,7 +7,7 @@
 
 static inline int  __paravirt_pgd_alloc(struct mm_struct *mm) { return 0; }
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #include <asm/paravirt.h>
 #else
 #define paravirt_pgd_alloc(mm)	__paravirt_pgd_alloc(mm)
diff --git a/arch/x86/include/asm/pgtable-3level_types.h b/arch/x86/include/asm/pgtable-3level_types.h
index 1bd5876..be58e74 100644
--- a/arch/x86/include/asm/pgtable-3level_types.h
+++ b/arch/x86/include/asm/pgtable-3level_types.h
@@ -18,7 +18,7 @@ typedef union {
 } pte_t;
 #endif	/* !__ASSEMBLY__ */
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #define SHARED_KERNEL_PMD	(pv_info.shared_kernel_pmd)
 #else
 #define SHARED_KERNEL_PMD	1
diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h
index 18601c8..4143aba 100644
--- a/arch/x86/include/asm/pgtable.h
+++ b/arch/x86/include/asm/pgtable.h
@@ -30,7 +30,7 @@ extern struct list_head pgd_list;
 
 extern struct mm_struct *pgd_page_get_mm(struct page *page);
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #include <asm/paravirt.h>
 #else  /* !CONFIG_PARAVIRT */
 #define set_pte(ptep, pte)		native_set_pte(ptep, pte)
diff --git a/arch/x86/include/asm/required-features.h b/arch/x86/include/asm/required-features.h
index 6c7fc25..dc24208 100644
--- a/arch/x86/include/asm/required-features.h
+++ b/arch/x86/include/asm/required-features.h
@@ -48,7 +48,7 @@
 #endif
 
 #ifdef CONFIG_X86_64
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 /* Paravirtualized systems may not have PSE or PGE available */
 #define NEED_PSE	0
 #define NEED_PGE	0
diff --git a/arch/x86/include/asm/system.h b/arch/x86/include/asm/system.h
index 389bc1a..3706243 100644
--- a/arch/x86/include/asm/system.h
+++ b/arch/x86/include/asm/system.h
@@ -312,8 +312,9 @@ static inline void native_wbinvd(void)
 
 #ifdef CONFIG_PARAVIRT
 #include <asm/paravirt.h>
-#else
+#endif
 
+#ifndef CONFIG_PARAVIRT
 static inline unsigned long read_cr0(void)
 {
 	return native_read_cr0();
@@ -323,7 +324,9 @@ static inline void write_cr0(unsigned long x)
 {
 	native_write_cr0(x);
 }
+#endif
 
+#ifndef CONFIG_PARAVIRT_MMU
 static inline unsigned long read_cr2(void)
 {
 	return native_read_cr2();
@@ -343,7 +346,9 @@ static inline void write_cr3(unsigned long x)
 {
 	native_write_cr3(x);
 }
+#endif /* CONFIG_PARAVIRT_MMU */
 
+#ifndef CONFIG_PARAVIRT
 static inline unsigned long read_cr4(void)
 {
 	return native_read_cr4();
diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h
index 169be89..042f6e1 100644
--- a/arch/x86/include/asm/tlbflush.h
+++ b/arch/x86/include/asm/tlbflush.h
@@ -7,7 +7,7 @@
 #include <asm/processor.h>
 #include <asm/system.h>
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #include <asm/paravirt.h>
 #else
 #define __flush_tlb() __native_flush_tlb()
@@ -162,7 +162,7 @@ static inline void reset_lazy_tlbstate(void)
 
 #endif	/* SMP */
 
-#ifndef CONFIG_PARAVIRT
+#ifndef CONFIG_PARAVIRT_MMU
 #define flush_tlb_others(mask, mm, va)	native_flush_tlb_others(mask, mm, va)
 #endif
 
diff --git a/arch/x86/kernel/head_64.S b/arch/x86/kernel/head_64.S
index a9b3381..9eaf893 100644
--- a/arch/x86/kernel/head_64.S
+++ b/arch/x86/kernel/head_64.S
@@ -20,7 +20,7 @@
 #include <asm/processor-flags.h>
 #include <asm/percpu.h>
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #include <asm/asm-offsets.h>
 #include <asm/paravirt.h>
 #else
diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c
index 33c07b0..13b1bc8 100644
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@ -51,18 +51,20 @@ static int parse_no_kvmapf(char *arg)
 
 early_param("no-kvmapf", parse_no_kvmapf);
 
+#ifdef CONFIG_KVM_MMU
 struct kvm_para_state {
 	u8 mmu_queue[MMU_QUEUE_SIZE];
 	int mmu_queue_len;
 };
 
 static DEFINE_PER_CPU(struct kvm_para_state, para_state);
-static DEFINE_PER_CPU(struct kvm_vcpu_pv_apf_data, apf_reason) __aligned(64);
 
 static struct kvm_para_state *kvm_para_state(void)
 {
 	return &per_cpu(para_state, raw_smp_processor_id());
 }
+#endif
+static DEFINE_PER_CPU(struct kvm_vcpu_pv_apf_data, apf_reason) __aligned(64);
 
 /*
  * No need for any "IO delay" on KVM
@@ -260,6 +262,7 @@ do_async_page_fault(struct pt_regs *regs, unsigned long error_code)
 	}
 }
 
+#ifdef CONFIG_KVM_MMU
 static void kvm_mmu_op(void *buffer, unsigned len)
 {
 	int r;
@@ -340,9 +343,10 @@ static void kvm_set_pmd(pmd_t *pmdp, pmd_t pmd)
 {
 	kvm_mmu_write(pmdp, pmd_val(pmd));
 }
+#endif /* CONFIG_KVM_MMU */
 
 #if PAGETABLE_LEVELS >= 3
-#ifdef CONFIG_X86_PAE
+#if defined(CONFIG_X86_PAE) && defined(CONFIG_KVM_MMU)
 static void kvm_set_pte_atomic(pte_t *ptep, pte_t pte)
 {
 	kvm_mmu_write(ptep, pte_val(pte));
@@ -358,7 +362,6 @@ static void kvm_pmd_clear(pmd_t *pmdp)
 {
 	kvm_mmu_write(pmdp, 0);
 }
-#endif
 
 static void kvm_set_pud(pud_t *pudp, pud_t pud)
 {
@@ -371,8 +374,10 @@ static void kvm_set_pgd(pgd_t *pgdp, pgd_t pgd)
 	kvm_mmu_write(pgdp, pgd_val(pgd));
 }
 #endif
+#endif
 #endif /* PAGETABLE_LEVELS >= 3 */
 
+#ifdef CONFIG_KVM_MMU
 static void kvm_flush_tlb(void)
 {
 	struct kvm_mmu_op_flush_tlb ftlb = {
@@ -404,6 +409,7 @@ static void kvm_leave_lazy_mmu(void)
 	mmu_queue_flush(state);
 	paravirt_leave_lazy_mmu();
 }
+#endif /* CONFIG_KVM_MMU */
 
 static void __init paravirt_ops_setup(void)
 {
@@ -414,20 +420,26 @@ static void __init paravirt_ops_setup(void)
 		pv_cpu_ops.io_delay = kvm_io_delay;
 
 	if (kvm_para_has_feature(KVM_FEATURE_MMU_OP)) {
+#ifdef CONFIG_KVM_MMU
 		pv_mmu_ops.set_pte = kvm_set_pte;
 		pv_mmu_ops.set_pte_at = kvm_set_pte_at;
 		pv_mmu_ops.set_pmd = kvm_set_pmd;
+#endif /* CONFIG_KVM_MMU */
 #if PAGETABLE_LEVELS >= 3
+#ifdef CONFIG_KVM_MMU
 #ifdef CONFIG_X86_PAE
 		pv_mmu_ops.set_pte_atomic = kvm_set_pte_atomic;
 		pv_mmu_ops.pte_clear = kvm_pte_clear;
 		pv_mmu_ops.pmd_clear = kvm_pmd_clear;
 #endif
+
 		pv_mmu_ops.set_pud = kvm_set_pud;
 #if PAGETABLE_LEVELS == 4
 		pv_mmu_ops.set_pgd = kvm_set_pgd;
 #endif
 #endif
+#endif
+#ifdef CONFIG_KVM_MMU
 		pv_mmu_ops.flush_tlb_user = kvm_flush_tlb;
 		pv_mmu_ops.release_pte = kvm_release_pt;
 		pv_mmu_ops.release_pmd = kvm_release_pt;
@@ -435,6 +447,7 @@ static void __init paravirt_ops_setup(void)
 
 		pv_mmu_ops.lazy_mode.enter = kvm_enter_lazy_mmu;
 		pv_mmu_ops.lazy_mode.leave = kvm_leave_lazy_mmu;
+#endif /* CONFIG_KVM_MMU */
 	}
 #ifdef CONFIG_X86_IO_APIC
 	no_timer_check = 1;
