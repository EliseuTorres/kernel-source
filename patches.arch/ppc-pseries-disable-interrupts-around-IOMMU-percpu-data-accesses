From: Anton Blanchard <anton@samba.org>
Subject: powerpc/pseries: Disable interrupts around IOMMU percpu data accesses
Git-commit: c1703e85a7b20ffcefd5360e2542460737ecc15c
Patch-mainline: yes
References: bnc#795789,fate#314056 IBM:83657

powerpc/pseries: Disable interrupts around IOMMU percpu data accesses
    
tce_buildmulti_pSeriesLP uses a per cpu page to communicate with the
hypervisor. We currently rely on the IOMMU table spinlock but
subsequent patches will be removing that so disable interrupts
around all accesses of tce_page.

Signed-off-by: Anton Blanchard <anton@samba.org>
Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Acked-by: Torsten Duwe <duwe@suse.de>

diff -urpN linux-3.0-1/arch/powerpc/kernel/iommu.c linux-3.0-2/arch/powerpc/kernel/iommu.c
--- linux-3.0-1/arch/powerpc/kernel/iommu.c	2011-07-22 03:17:23.000000000 +0100
+++ linux-3.0-2/arch/powerpc/kernel/iommu.c	2012-12-05 22:33:26.000000000 +0000
@@ -169,13 +169,11 @@ static dma_addr_t iommu_alloc(struct dev
 	int build_fail;
 
 	spin_lock_irqsave(&(tbl->it_lock), flags);
-
 	entry = iommu_range_alloc(dev, tbl, npages, NULL, mask, align_order);
+	spin_unlock_irqrestore(&(tbl->it_lock), flags);
 
-	if (unlikely(entry == DMA_ERROR_CODE)) {
-		spin_unlock_irqrestore(&(tbl->it_lock), flags);
+	if (unlikely(entry == DMA_ERROR_CODE))
 		return DMA_ERROR_CODE;
-	}
 
 	entry += tbl->it_offset;	/* Offset into real TCE table */
 	ret = entry << IOMMU_PAGE_SHIFT;	/* Set the return dma address */
@@ -191,9 +189,10 @@ static dma_addr_t iommu_alloc(struct dev
 	 * not altered.
 	 */
 	if (unlikely(build_fail)) {
+		spin_lock_irqsave(&(tbl->it_lock), flags);
 		__iommu_free(tbl, ret, npages);
-
 		spin_unlock_irqrestore(&(tbl->it_lock), flags);
+
 		return DMA_ERROR_CODE;
 	}
 
@@ -201,8 +200,6 @@ static dma_addr_t iommu_alloc(struct dev
 	if (ppc_md.tce_flush)
 		ppc_md.tce_flush(tbl);
 
-	spin_unlock_irqrestore(&(tbl->it_lock), flags);
-
 	/* Make sure updates are seen by hardware */
 	mb();
 
@@ -243,8 +240,8 @@ static void iommu_free(struct iommu_tabl
 	unsigned long flags;
 
 	spin_lock_irqsave(&(tbl->it_lock), flags);
-
 	__iommu_free(tbl, dma_addr, npages);
+	spin_unlock_irqrestore(&(tbl->it_lock), flags);
 
 	/* Make sure TLB cache is flushed if the HW needs it. We do
 	 * not do an mb() here on purpose, it is not needed on any of
@@ -252,8 +249,6 @@ static void iommu_free(struct iommu_tabl
 	 */
 	if (ppc_md.tce_flush)
 		ppc_md.tce_flush(tbl);
-
-	spin_unlock_irqrestore(&(tbl->it_lock), flags);
 }
 
 int iommu_map_sg(struct device *dev, struct iommu_table *tbl,
