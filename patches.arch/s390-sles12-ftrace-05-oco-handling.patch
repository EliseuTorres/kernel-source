From: Heiko Carstens <heiko.carstens@de.ibm.com>
Subject: ftrace: add oco handling patch
Patch-mainline: no
Git-commit: n/a
References: bnc#924526, LTC#123020

Description:  kernel: use hotpatch feature to reduce function tracer overhead
Symptom:      The kernel uses more cpu cycles for each function being
              executed.
Problem:      The kGraft feature requires to instrument the kernel. In
              order to do that the kernel gets compiled with the function
              tracer enabled which causes the compiler to emit code that
              adds an "mcount" call to the prologue of each function.
              This code will be modified by the kernel for function tracing.
              The current implementation uses the "-pg" compiler option to
              generate a 24 byte function prologue which will be used by
              the function tracer.
              This 24 byte prologue however is larger than the 6 bytes that
              are needed and do cause a performance regression compared to
              kernels without function tracing enabled.
Solution:     Use gcc's hotpatch feature so that only a single 6 byte
              instruction will be added to the prologue of each function.
              With this change the impact of enabling the function tracer
              feature is close to zero compared to a kernel which has this
              feature disabled.
Reproduction: Compile the kernel with and without function tracer enabled
              and compare cpu time spent in the kernel for identical
              workloads.

Upstream-Description:

              ftrace: add oco handling patch

              This patch adds special oco handling for the SLES12 GA kernel
              only. This allow the ftrace code to deal with modules that
              have been compiled with either the -pg or hotpatch compile flag.
              This patch should be removed for SLES12SP1, so the code matches
              upstream.

Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
Acked-by: John Jolly <jjolly@suse.de>
---
 arch/s390/include/asm/ftrace.h |   87 ++++++++++++++++++++++++++++++++++---
 arch/s390/kernel/ftrace.c      |   95 ++++++++++++++++++++++++++++++++++-------
 arch/s390/kernel/kprobes.c     |   40 +++++++++++++----
 arch/s390/kernel/mcount.S      |   49 ++++++++++++++++++++-
 scripts/recordmcount.pl        |    4 -
 5 files changed, 240 insertions(+), 35 deletions(-)

--- a/arch/s390/include/asm/ftrace.h
+++ b/arch/s390/include/asm/ftrace.h
@@ -10,21 +10,44 @@
 #define MCOUNT_RETURN_FIXUP	18
 #endif
 
+#define MCOUNT_OCO_INSN_SIZE	24
+#define MCOUNT_OCO_RETURN_FIXUP	18
+
+/*
+ * This is a SLES12 GA hack only:
+ * After GA the ftrace code got changed to convert the first instead of
+ * the second instruction. However we cannot change the recorded offsets
+ * within the __mcount_loc section, due to out of tree built modules.
+ * Therefore all (struct dyn_ftrace *) rec->ip passed instruction
+ * addresses do not point to the instruction being changed, but six bytes
+ * further.
+ * The MCOUNT_IP_FIXUP define must be used everywhere to fixup the address.
+ */
+#define MCOUNT_IP_FIXUP		6
+
 #ifndef __ASSEMBLY__
 
 void _mcount(void);
 void ftrace_caller(void);
 
 extern char ftrace_graph_caller_end;
+extern char ftrace_oco_graph_caller_end;
 extern unsigned long ftrace_plt;
+extern unsigned long ftrace_oco_plt;
+
+void ftrace_oco_caller(void);
+void ftrace_oco_graph_caller(void);
 
 struct dyn_arch_ftrace { };
 
 #define MCOUNT_ADDR ((unsigned long)_mcount)
 #define FTRACE_ADDR ((unsigned long)ftrace_caller)
+#define FTRACE_OCO_ADDR ((unsigned long)ftrace_oco_caller)
 
 #define KPROBE_ON_FTRACE_NOP	0
 #define KPROBE_ON_FTRACE_CALL	1
+#define KPROBE_ON_FTRACE_OCO_NOP	2
+#define KPROBE_ON_FTRACE_OCO_CALL	3
 
 static inline unsigned long ftrace_call_adjust(unsigned long addr)
 {
@@ -36,13 +59,19 @@ struct ftrace_insn {
 	s32 disp;
 } __packed;
 
-static inline void ftrace_generate_nop_insn(struct ftrace_insn *insn)
+static inline void ftrace_generate_nop_insn(struct ftrace_insn *insn, int oco)
 {
 #ifdef CONFIG_FUNCTION_TRACER
 #ifdef CC_USING_HOTPATCH
-	/* brcl 0,0 */
-	insn->opc = 0xc004;
-	insn->disp = 0;
+	if (oco) {
+		/* jg .+24 */
+		insn->opc = 0xc0f4;
+		insn->disp = MCOUNT_OCO_INSN_SIZE / 2;
+	} else {
+		/* brcl 0,0 */
+		insn->opc = 0xc004;
+		insn->disp = 0;
+	}
 #else
 	/* jg .+24 */
 	insn->opc = 0xc0f4;
@@ -51,7 +80,7 @@ static inline void ftrace_generate_nop_i
 #endif
 }
 
-static inline int is_ftrace_nop(struct ftrace_insn *insn)
+static inline int is_ftrace_nop(struct ftrace_insn *insn, unsigned long ip)
 {
 #ifdef CONFIG_FUNCTION_TRACER
 #ifdef CC_USING_HOTPATCH
@@ -65,14 +94,58 @@ static inline int is_ftrace_nop(struct f
 	return 0;
 }
 
+static inline int is_ftrace_oco_orig(struct ftrace_insn *insn, unsigned long ip)
+{
+#ifdef CC_USING_HOTPATCH
+	if (!is_module_addr((void *) ip))
+		return 0;
+	/* stg r14,8(r15) */
+	if (insn->opc == 0xe3e0 && insn->disp == 0xf0080024)
+		return 1;
+#endif
+	return 0;
+}
+
+static inline int is_ftrace_oco_nop(struct ftrace_insn *insn, unsigned long ip)
+{
+#ifdef CC_USING_HOTPATCH
+	if (!is_module_addr((void *) ip))
+		return 0;
+	if (insn->disp == MCOUNT_OCO_INSN_SIZE / 2)
+		return 1;
+#endif
+	return 0;
+}
+
+static inline int is_ftrace_call(struct ftrace_insn *insn, unsigned long ip)
+{
+	if (insn->disp == (s32)((ftrace_plt - ip) / 2))
+		return 1;
+	return 0;
+}
+
+static inline int is_ftrace_oco_call(struct ftrace_insn *insn, unsigned long ip)
+{
+#ifdef CC_USING_HOTPATCH
+	if (!is_module_addr((void *) ip))
+		return 0;
+	if (insn->disp == (s32)((ftrace_oco_plt - ip) / 2))
+		return 1;
+#endif
+	return 0;
+}
+
 static inline void ftrace_generate_call_insn(struct ftrace_insn *insn,
-					     unsigned long ip)
+					     unsigned long ip, int oco)
 {
 #ifdef CONFIG_FUNCTION_TRACER
 	unsigned long target;
 
 	/* brasl r0,ftrace_caller */
-	target = is_module_addr((void *) ip) ? ftrace_plt : FTRACE_ADDR;
+	if (oco)
+		target = is_module_addr((void *) ip) ? ftrace_oco_plt : FTRACE_ADDR;
+	else
+		target = is_module_addr((void *) ip) ? ftrace_plt : FTRACE_ADDR;
 	insn->opc = 0xc005;
 	insn->disp = (target - ip) / 2;
 #endif
--- a/arch/s390/kernel/ftrace.c
+++ b/arch/s390/kernel/ftrace.c
@@ -56,6 +56,7 @@
  */
 
 unsigned long ftrace_plt;
+unsigned long ftrace_oco_plt;
 
 int ftrace_modify_call(struct dyn_ftrace *rec, unsigned long old_addr,
 		       unsigned long addr)
@@ -66,21 +67,28 @@ int ftrace_modify_call(struct dyn_ftrace
 int ftrace_make_nop(struct module *mod, struct dyn_ftrace *rec,
 		    unsigned long addr)
 {
+	void *ip = (void *) rec->ip - MCOUNT_IP_FIXUP;
 	struct ftrace_insn orig, new, old;
+	int oco = 0;
 
-	if (probe_kernel_read(&old, (void *) rec->ip, sizeof(old)))
+	if (probe_kernel_read(&old, ip, sizeof(old)))
 		return -EFAULT;
 	if (addr == MCOUNT_ADDR) {
 		/* Initial code replacement */
 #ifdef CC_USING_HOTPATCH
-		/* We expect to see brcl 0,0 */
-		ftrace_generate_nop_insn(&orig);
+		/* Special oco code detection... */
+		oco = is_ftrace_oco_orig(&old, (unsigned long) ip);
+		if (oco)
+			orig = old;
+		else
+			/* We expect to see brcl 0,0 */
+			ftrace_generate_nop_insn(&orig, 0);
 #else
 		/* We expect to see stg r14,8(r15) */
 		orig.opc = 0xe3e0;
 		orig.disp = 0xf0080024;
 #endif
-		ftrace_generate_nop_insn(&new);
+		ftrace_generate_nop_insn(&new, oco);
 	} else if (old.opc == BREAKPOINT_INSTRUCTION) {
 		/*
 		 * If we find a breakpoint instruction, a kprobe has been
@@ -90,26 +98,34 @@ int ftrace_make_nop(struct module *mod,
 		 * handler can execute a nop, if it reaches this breakpoint.
 		 */
 		new.opc = orig.opc = BREAKPOINT_INSTRUCTION;
-		orig.disp = KPROBE_ON_FTRACE_CALL;
-		new.disp = KPROBE_ON_FTRACE_NOP;
+		if (old.disp == KPROBE_ON_FTRACE_CALL) {
+			orig.disp = KPROBE_ON_FTRACE_CALL;
+			new.disp = KPROBE_ON_FTRACE_NOP;
+		} else {
+			orig.disp = KPROBE_ON_FTRACE_OCO_CALL;
+			new.disp = KPROBE_ON_FTRACE_OCO_NOP;
+		}
 	} else {
 		/* Replace ftrace call with a nop. */
-		ftrace_generate_call_insn(&orig, rec->ip);
-		ftrace_generate_nop_insn(&new);
+		oco = is_ftrace_oco_call(&old, (unsigned long) ip);
+		ftrace_generate_call_insn(&orig, (unsigned long) ip, oco);
+		ftrace_generate_nop_insn(&new, oco);
 	}
 	/* Verify that the to be replaced code matches what we expect. */
 	if (memcmp(&orig, &old, sizeof(old)))
 		return -EINVAL;
-	if (probe_kernel_write((void *) rec->ip, &new, sizeof(new)))
+	if (probe_kernel_write(ip, &new, sizeof(new)))
 		return -EPERM;
 	return 0;
 }
 
 int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
 {
+	void *ip = (void *) rec->ip - MCOUNT_IP_FIXUP;
 	struct ftrace_insn orig, new, old;
+	int oco;
 
-	if (probe_kernel_read(&old, (void *) rec->ip, sizeof(old)))
+	if (probe_kernel_read(&old, ip, sizeof(old)))
 		return -EFAULT;
 	if (old.opc == BREAKPOINT_INSTRUCTION) {
 		/*
@@ -120,17 +136,23 @@ int ftrace_make_call(struct dyn_ftrace *
 		 * handler can execute a brasl if it reaches this breakpoint.
 		 */
 		new.opc = orig.opc = BREAKPOINT_INSTRUCTION;
-		orig.disp = KPROBE_ON_FTRACE_NOP;
-		new.disp = KPROBE_ON_FTRACE_CALL;
+		if (old.disp == KPROBE_ON_FTRACE_NOP) {
+			orig.disp = KPROBE_ON_FTRACE_NOP;
+			new.disp = KPROBE_ON_FTRACE_CALL;
+		} else {
+			orig.disp = KPROBE_ON_FTRACE_OCO_NOP;
+			new.disp = KPROBE_ON_FTRACE_OCO_CALL;
+		}
 	} else {
 		/* Replace nop with an ftrace call. */
-		ftrace_generate_nop_insn(&orig);
-		ftrace_generate_call_insn(&new, rec->ip);
+		oco = is_ftrace_oco_nop(&old, (unsigned long) ip);
+		ftrace_generate_nop_insn(&orig, oco);
+		ftrace_generate_call_insn(&new, (unsigned long) ip, oco);
 	}
 	/* Verify that the to be replaced code matches what we expect. */
 	if (memcmp(&orig, &old, sizeof(old)))
 		return -EINVAL;
-	if (probe_kernel_write((void *) rec->ip, &new, sizeof(new)))
+	if (probe_kernel_write(ip, &new, sizeof(new)))
 		return -EPERM;
 	return 0;
 }
@@ -160,6 +182,18 @@ static int __init ftrace_plt_init(void)
 	ip[3] = FTRACE_ADDR >> 32;
 	ip[4] = FTRACE_ADDR & 0xffffffff;
 	set_memory_ro(ftrace_plt, 1);
+#ifdef CC_USING_HOTPATCH
+	ftrace_oco_plt = (unsigned long) module_alloc(PAGE_SIZE);
+	if (!ftrace_oco_plt)
+		panic("cannot allocate ftrace oco plt\n");
+	ip = (unsigned int *) ftrace_oco_plt;
+	ip[0] = 0x0d10e310; /* basr 1,0; lg 1,10(1); br 1 */
+	ip[1] = 0x100a0004;
+	ip[2] = 0x07f10000;
+	ip[3] = FTRACE_OCO_ADDR >> 32;
+	ip[4] = FTRACE_OCO_ADDR & 0xffffffff;
+	set_memory_ro(ftrace_oco_plt, 1);
+#endif /* CC_USING_HOTPATCH */
 	return 0;
 }
 device_initcall(ftrace_plt_init);
@@ -176,7 +210,7 @@ unsigned long __kprobes prepare_ftrace_r
 
 	if (unlikely(atomic_read(&current->tracing_graph_pause)))
 		goto out;
-	ip = (ip & PSW_ADDR_INSN) - MCOUNT_INSN_SIZE;
+	ip = (ip & PSW_ADDR_INSN) - MCOUNT_INSN_SIZE + MCOUNT_IP_FIXUP;
 	if (ftrace_push_return_trace(parent, ip, &trace.depth, 0) == -EBUSY)
 		goto out;
 	trace.func = ip;
@@ -190,6 +224,29 @@ out:
 	return parent;
 }
 
+#ifdef CC_USING_HOTPATCH
+unsigned long __kprobes prepare_ftrace_oco_return(unsigned long parent,
+						  unsigned long ip)
+{
+	struct ftrace_graph_ent trace;
+
+	if (unlikely(atomic_read(&current->tracing_graph_pause)))
+		goto out;
+	ip = (ip & PSW_ADDR_INSN) - MCOUNT_OCO_INSN_SIZE + MCOUNT_IP_FIXUP;
+	if (ftrace_push_return_trace(parent, ip, &trace.depth, 0) == -EBUSY)
+		goto out;
+	trace.func = ip;
+	/* Only trace if the calling function expects to. */
+	if (!ftrace_graph_entry(&trace)) {
+		current->curr_ret_stack--;
+		goto out;
+	}
+	parent = (unsigned long) return_to_handler;
+out:
+	return parent;
+}
+#endif /* CC_USING_HOTPATCH */
+
 /*
  * Patch the kernel code at ftrace_graph_caller location. The instruction
  * there is branch relative on condition. To enable the ftrace graph code
@@ -202,6 +259,9 @@ int ftrace_enable_ftrace_graph_caller(vo
 {
 	u8 op = 0x04; /* set mask field to zero */
 
+#ifdef CC_USING_HOTPATCH
+	probe_kernel_write(__va(ftrace_oco_graph_caller)+1, &op, sizeof(op));
+#endif
 	return probe_kernel_write(__va(ftrace_graph_caller)+1, &op, sizeof(op));
 }
 
@@ -209,6 +269,9 @@ int ftrace_disable_ftrace_graph_caller(v
 {
 	u8 op = 0xf4; /* set mask field to all ones */
 
+#ifdef CC_USING_HOTPATCH
+	probe_kernel_write(__va(ftrace_oco_graph_caller)+1, &op, sizeof(op));
+#endif
 	return probe_kernel_write(__va(ftrace_graph_caller)+1, &op, sizeof(op));
 }
 
--- a/arch/s390/kernel/kprobes.c
+++ b/arch/s390/kernel/kprobes.c
@@ -210,14 +210,17 @@ static void __kprobes copy_instruction(s
 	s64 disp, new_disp;
 	u64 addr, new_addr;
 
-	if (ftrace_location(ip) == ip) {
+	if (ftrace_location(ip + MCOUNT_IP_FIXUP) == ip + MCOUNT_IP_FIXUP) {
+		int oco;
 		/*
 		 * If kprobes patches the instruction that is morphed by
 		 * ftrace make sure that kprobes always sees the branch
 		 * "jg .+24" that skips the mcount block or the "brcl 0,0"
 		 * in case of hotpatch.
 		 */
-		ftrace_generate_nop_insn((struct ftrace_insn *)p->ainsn.insn);
+		oco = is_ftrace_oco_nop((struct ftrace_insn *)ip, ip) ||
+			is_ftrace_oco_call((struct ftrace_insn *)ip, ip);
+		ftrace_generate_nop_insn((struct ftrace_insn *)p->ainsn.insn, oco);
 		p->ainsn.is_ftrace_insn = 1;
 	} else
 		memcpy(p->ainsn.insn, p->addr, ((*p->addr >> 14) + 3) & -2);
@@ -299,6 +302,7 @@ static int __kprobes swap_instruction(vo
 	struct swap_insn_args *args = data;
 	struct ftrace_insn new_insn, *insn;
 	struct kprobe *p = args->p;
+	unsigned long ip;
 	size_t len;
 
 	new_insn.opc = args->arm_kprobe ? BREAKPOINT_INSTRUCTION : p->opcode;
@@ -307,15 +311,31 @@ static int __kprobes swap_instruction(vo
 		goto skip_ftrace;
 	len = sizeof(new_insn);
 	insn = (struct ftrace_insn *) p->addr;
+	ip = (unsigned long) p->addr;
 	if (args->arm_kprobe) {
-		if (is_ftrace_nop(insn))
+		if (is_ftrace_nop(insn, ip))
 			new_insn.disp = KPROBE_ON_FTRACE_NOP;
-		else
+		else if (is_ftrace_call(insn, ip))
 			new_insn.disp = KPROBE_ON_FTRACE_CALL;
+		else if (is_ftrace_oco_nop(insn, ip))
+			new_insn.disp = KPROBE_ON_FTRACE_OCO_NOP;
+		else /* is_ftrace_oco_call */
+			new_insn.disp = KPROBE_ON_FTRACE_OCO_CALL;
 	} else {
-		ftrace_generate_call_insn(&new_insn, (unsigned long)p->addr);
-		if (insn->disp == KPROBE_ON_FTRACE_NOP)
-			ftrace_generate_nop_insn(&new_insn);
+		switch (insn->disp) {
+		case KPROBE_ON_FTRACE_NOP:
+			ftrace_generate_nop_insn(&new_insn, 0);
+			break;
+		case KPROBE_ON_FTRACE_CALL:
+			ftrace_generate_call_insn(&new_insn, ip, 0);
+			break;
+		case KPROBE_ON_FTRACE_OCO_NOP:
+			ftrace_generate_nop_insn(&new_insn, 1);
+			break;
+		case KPROBE_ON_FTRACE_OCO_CALL:
+			ftrace_generate_call_insn(&new_insn, ip, 1);
+			break;
+		}
 	}
 skip_ftrace:
 	kcb->kprobe_status = KPROBE_SWAP_INST;
@@ -630,7 +650,6 @@ static void __kprobes resume_execution(s
 		struct ftrace_insn *insn = (struct ftrace_insn *) p->addr;
 		struct ftrace_insn call_insn;
 
-		ftrace_generate_call_insn(&call_insn, (unsigned long) p->addr);
 		/*
 		 * A kprobe on an enabled ftrace call site actually single
 		 * stepped an unconditional branch (ftrace nop equivalent).
@@ -638,8 +657,13 @@ static void __kprobes resume_execution(s
 		 * was executed instead.
 		 */
 		if (insn->disp == KPROBE_ON_FTRACE_CALL) {
+			ftrace_generate_call_insn(&call_insn, (unsigned long) p->addr, 0);
 			ip += call_insn.disp * 2 - MCOUNT_INSN_SIZE;
 			regs->gprs[0] = (unsigned long)p->addr + sizeof(*insn);
+		} else if (insn->disp == KPROBE_ON_FTRACE_OCO_CALL) {
+			ftrace_generate_call_insn(&call_insn, (unsigned long) p->addr, 1);
+			ip += call_insn.disp * 2 - MCOUNT_OCO_INSN_SIZE;
+			regs->gprs[0] = (unsigned long)p->addr + sizeof(*insn);
 		}
 	}
 
--- a/arch/s390/kernel/mcount.S
+++ b/arch/s390/kernel/mcount.S
@@ -36,12 +36,12 @@ ENTRY(ftrace_caller)
 	stg	%r0,(STACK_PTREGS_PSW+8)(%r15)
 	stmg	%r2,%r14,(STACK_PTREGS_GPRS+2*8)(%r15)
 #ifdef CONFIG_HAVE_MARCH_Z196_FEATURES
-	aghik	%r2,%r0,-MCOUNT_INSN_SIZE
+	aghik	%r2,%r0,-(MCOUNT_INSN_SIZE-MCOUNT_IP_FIXUP)
 	lgrl	%r4,function_trace_op
 	lgrl	%r1,ftrace_trace_function
 #else
 	lgr	%r2,%r0
-	aghi	%r2,-MCOUNT_INSN_SIZE
+	aghi	%r2,-(MCOUNT_INSN_SIZE-MCOUNT_IP_FIXUP)
 	larl	%r4,function_trace_op
 	lg	%r4,0(%r4)
 	larl	%r1,ftrace_trace_function
@@ -80,3 +80,48 @@ ENTRY(return_to_handler)
 	br	%r14
 
 #endif
+
+#ifdef CC_USING_HOTPATCH
+
+ENTRY(ftrace_oco_caller)
+	.globl	ftrace_oco_regs_caller
+	.set	ftrace_oco_regs_caller,ftrace_oco_caller
+	lgr	%r1,%r15
+	aghi	%r0,MCOUNT_OCO_RETURN_FIXUP
+	aghi	%r15,-STACK_FRAME_SIZE
+	stg	%r1,__SF_BACKCHAIN(%r15)
+	stg	%r1,(STACK_PTREGS_GPRS+15*8)(%r15)
+	stg	%r0,(STACK_PTREGS_PSW+8)(%r15)
+	stmg	%r2,%r14,(STACK_PTREGS_GPRS+2*8)(%r15)
+#ifdef CONFIG_HAVE_MARCH_Z196_FEATURES
+	aghik	%r2,%r0,-MCOUNT_OCO_RETURN_FIXUP
+	lgrl	%r4,function_trace_op
+	lgrl	%r1,ftrace_trace_function
+#else
+	lgr	%r2,%r0
+	aghi	%r2,-MCOUNT_OCO_RETURN_FIXUP
+	larl	%r4,function_trace_op
+	lg	%r4,0(%r4)
+	larl	%r1,ftrace_trace_function
+	lg	%r1,0(%r1)
+#endif
+	lgr	%r3,%r14
+	la	%r5,STACK_PTREGS(%r15)
+	basr	%r14,%r1
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+# The j instruction gets runtime patched to a nop instruction.
+# See ftrace_enable_ftrace_graph_caller.
+ENTRY(ftrace_oco_graph_caller)
+	j	ftrace_oco_graph_caller_end
+	lg	%r2,(STACK_PTREGS_GPRS+14*8)(%r15)
+	lg	%r3,(STACK_PTREGS_PSW+8)(%r15)
+	brasl	%r14,prepare_ftrace_oco_return
+	stg	%r2,(STACK_PTREGS_GPRS+14*8)(%r15)
+ftrace_oco_graph_caller_end:
+	.globl	ftrace_oco_graph_caller_end
+#endif
+	lg	%r1,(STACK_PTREGS_PSW+8)(%r15)
+	lmg	%r2,%r15,(STACK_PTREGS_GPRS+2*8)(%r15)
+	br	%r1
+
+#endif /* CC_USING_HOTPATCH */
--- a/scripts/recordmcount.pl
+++ b/scripts/recordmcount.pl
@@ -244,10 +244,10 @@ if ($arch eq "x86_64") {
 } elsif ($arch eq "s390" && $bits == 64) {
     if ($cc =~ /-DCC_USING_HOTPATCH/) {
 	$mcount_regex = "^\\s*([0-9a-fA-F]+):\\s*c0 04 00 00 00 00\\s*brcl\\s*0,[0-9a-f]+ <([^\+]*)>\$";
-	$mcount_adjust = 0;
+	$mcount_adjust = 6;
     } else {
 	$mcount_regex = "^\\s*([0-9a-fA-F]+):\\s*R_390_(PC|PLT)32DBL\\s+_mcount\\+0x2\$";
-	$mcount_adjust = -14;
+	$mcount_adjust = -8;
     }
     $alignment = 8;
     $type = ".quad";
