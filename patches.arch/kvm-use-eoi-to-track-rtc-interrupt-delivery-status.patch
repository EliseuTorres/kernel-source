From: Yang Zhang <yang.z.zhang@Intel.com>
Date: Thu, 11 Apr 2013 19:21:41 +0800
Subject: [PATCH 7/7] KVM: Use eoi to track RTC interrupt delivery status
References: fate#313618
Git-commit: 2c2bf01136971c33e3b3fabce23925f372c1017e
Patch-mainline: v3.10

Current interrupt coalescing logci which only used by RTC has conflict
with Posted Interrupt.
This patch introduces a new mechinism to use eoi to track interrupt:
When delivering an interrupt to vcpu, the pending_eoi set to number of
vcpu that received the interrupt. And decrease it when each vcpu writing
eoi. No subsequent RTC interrupt can deliver to vcpu until all vcpus
write eoi.

Signed-off-by: Yang Zhang <yang.z.zhang@Intel.com>
Reviewed-by: Gleb Natapov <gleb@redhat.com>
Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
Acked-by: Bruce Rogers <brogers@suse.com>
---
 virt/kvm/ioapic.c |   48 +++++++++++++++++++++++++++++++++++++++++-------
 1 file changed, 41 insertions(+), 7 deletions(-)

Index: b/virt/kvm/ioapic.c
===================================================================
--- a/virt/kvm/ioapic.c
+++ b/virt/kvm/ioapic.c
@@ -144,6 +144,22 @@ static void kvm_rtc_eoi_tracking_restore
 	    __rtc_irq_eoi_tracking_restore_one(vcpu);
 }
 
+static void rtc_irq_eoi(struct kvm_ioapic *ioapic, struct kvm_vcpu *vcpu)
+{
+	if (test_and_clear_bit(vcpu->vcpu_id, ioapic->rtc_status.dest_map))
+		--ioapic->rtc_status.pending_eoi;
+
+	WARN_ON(ioapic->rtc_status.pending_eoi < 0);
+}
+
+static bool rtc_irq_check_coalesced(struct kvm_ioapic *ioapic)
+{
+	if (ioapic->rtc_status.pending_eoi > 0)
+		return true; /* coalesced */
+
+	return false;
+}
+
 static int ioapic_service(struct kvm_ioapic *ioapic, unsigned int idx,
 		bool line_status)
 {
@@ -260,6 +276,7 @@ static int ioapic_deliver(struct kvm_ioa
 {
 	union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
 	struct kvm_lapic_irq irqe;
+	int ret;
 
 	ioapic_debug("dest=%x dest_mode=%x delivery_mode=%x "
 		     "vector=%x trig_mode=%x\n",
@@ -284,7 +301,15 @@ static int ioapic_deliver(struct kvm_ioa
 		irqe.dest_id = ioapic->kvm->bsp_vcpu->vcpu_id;
 	}
 #endif
-	return kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);
+	if (irq == RTC_GSI && line_status) {
+		BUG_ON(ioapic->rtc_status.pending_eoi != 0);
+		ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,
+				ioapic->rtc_status.dest_map);
+		ioapic->rtc_status.pending_eoi = ret;
+	} else
+		ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);
+
+	return ret;
 }
 
 int kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int level,
@@ -305,12 +330,19 @@ int kvm_ioapic_set_irq(struct kvm_ioapic
 			ioapic->irr &= ~mask;
 		else {
 			int edge = (entry.fields.trig_mode == IOAPIC_EDGE_TRIG);
-			ioapic->irr |= mask;
-			if ((edge && old_irr != ioapic->irr) ||
-			    (!edge && !entry.fields.remote_irr))
-				ret = ioapic_service(ioapic, irq, line_status);
-			else
-				ret = 0; /* report coalesced interrupt */
+
+			if (irq == RTC_GSI && line_status &&
+				rtc_irq_check_coalesced(ioapic)) {
+				ret = 0; /* coalesced */
+			} else {
+				ioapic->irr |= mask;
+				if ((edge && old_irr != ioapic->irr) ||
+				    (!edge && !entry.fields.remote_irr))
+					ret = ioapic_service(ioapic, irq,
+							     line_status);
+				else
+					ret = 0; /* report coalesced interrupt */
+			}
 		}
 		trace_kvm_ioapic_set_irq(entry.bits, irq, ret == 0);
 	}
@@ -330,6 +362,8 @@ static void __kvm_ioapic_update_eoi(stru
 		if (ent->fields.vector != vector)
 			continue;
 
+		if (i == RTC_GSI)
+			rtc_irq_eoi(ioapic, vcpu);
 		/*
 		 * We are dropping lock while calling ack notifiers because ack
 		 * notifier callbacks for assigned devices call into IOAPIC
