From: Heiko Carstens <heiko.carstens@de.ibm.com>
Subject: kernel: pfault task state race
Patch-mainline: yes
References: bnc#764091,LTC#81724

Symptom:     Kernel crashes in pfault interrupt handler.
Problem:     When the kernel receives an initial pfault interrupt for a task
             it will set its state to TASK_UNINTERRUPTIBLE, put it on a pfault
             list and then schedule the task away so it will sleep until it
             gets woken up when the corresponding pfault completion interrupt
             arrives.
             Setting the current task state of a task to TASK_UNINTERRUPTIBLE
             can race with a task state change from a different cpu.
             The other cpu could set the task state after it inspected it
             (while it was still TASK_RUNNING) to TASK_RUNNING which would
             change the state from TASK_UNINTERRUPTIBLE back to TASK_RUNNING.
             If this happens the task will not sleep while the pfault handler
             code still thinks it is sleeping.
             If the task then generates another initial pfault interrupt it
             will be put a second time on the pfault list, using the same data
             structure that was used when it intially was put on the list.
             The result is a corrupted pfault list which can cause invalid
             memory accesses and a crash.
Solution:    Get another reference of the affected task when receiving the
             initial pfault interrupt and prevent that the task will be
             enqueued in the pfault list a second time if yet another initial
             pfault interrupt is received when the task is already enqueued.

Acked-by: John Jolly <jjolly@suse.de>
---
 arch/s390/mm/fault.c |   14 ++++++++++++--
 1 file changed, 12 insertions(+), 2 deletions(-)

--- a/arch/s390/mm/fault.c
+++ b/arch/s390/mm/fault.c
@@ -567,6 +567,7 @@ static void pfault_interrupt(unsigned in
 			tsk->thread.pfault_wait = 0;
 			list_del(&tsk->thread.list);
 			wake_up_process(tsk);
+			put_task_struct(tsk);
 		} else {
 			/* Completion interrupt was faster than initial
 			 * interrupt. Set pfault_wait to -1 so the initial
@@ -576,14 +577,22 @@ static void pfault_interrupt(unsigned in
 		put_task_struct(tsk);
 	} else {
 		/* signal bit not set -> a real page is missing. */
-		if (tsk->thread.pfault_wait == -1) {
+		if (tsk->thread.pfault_wait == 1) {
+			/* Already on the list with a reference: put to sleep */
+			set_task_state(tsk, TASK_UNINTERRUPTIBLE);
+			set_tsk_need_resched(tsk);
+		} else if (tsk->thread.pfault_wait == -1) {
 			/* Completion interrupt was faster than the initial
 			 * interrupt (pfault_wait == -1). Set pfault_wait
 			 * back to zero and exit. */
 			tsk->thread.pfault_wait = 0;
 		} else {
 			/* Initial interrupt arrived before completion
-			 * interrupt. Let the task sleep. */
+			 * interrupt. Let the task sleep.
+			 * An extra task reference is needed since a different
+			 * cpu may set the task state to TASK_RUNNING again
+			 * before the scheduler is reached. */
+			get_task_struct(tsk);
 			tsk->thread.pfault_wait = 1;
 			list_add(&tsk->thread.list, &pfault_list);
 			set_task_state(tsk, TASK_UNINTERRUPTIBLE);
@@ -608,6 +617,7 @@ static int __cpuinit pfault_cpu_notify(s
 			list_del(&thread->list);
 			tsk = container_of(thread, struct task_struct, thread);
 			wake_up_process(tsk);
+			put_task_struct(tsk);
 		}
 		spin_unlock_irq(&pfault_lock);
 		break;
