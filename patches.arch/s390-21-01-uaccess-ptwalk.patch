From: Heiko Carstens <heiko.carstens@de.ibm.com>
Subject: kernel: avoid page table walk on user space access
Patch-mainline: v3.15-rc1
Git-commit: 457f2180951cdcbfb4657ddcc83b486e93497f56 (partial)
References: bnc#878407, LTC#110316

Description:  kernel: avoid page table walk on user space access
Symptom:      Unexpected program crashes, random data corruption.
Problem:      The user space access functions perform page table walks in order
              to translate a user space virtual address to a physical address.
              While doing that the kernel must make sure the page table can not
              be changed concurrently from a different cpu.
              Therefore the page table lock must be held. However instead of
              acquiring the per page table split page table lock the kernel
              incorrectly acquired the per mm global page table lock.
              This allows different cpus to modify the page table contents
              while its contents are inspected and being used to access the
              corresponding user space address space.
              Therefore the kernel may access a page which was concurrently
              freed on a different cpu, which can lead to data corruption.
              This problem exists only on machines prior to IBM System z10.
              With the z10 machine the mvcos instruction was made available
              which is used to access user space without a page table walk.
              Furthermore if the "switch_amode" kernel parameter was specified
              (default since kernel version 3.7) the same problem exists for
              futex operations also for z10 machines and newer.
Solution:     Avoid page table walks and use machine instructions to access
              user space. This avoids all locking issues.
              This is a partial backport of upstream commit id
              457f2180951cdcbfb4657ddcc83b486e93497f56 "s390/uaccess: rework
              uaccess code - fix locking issues".
Reproduction: -


Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
Acked-by: John Jolly <jjolly@suse.de>
---
 arch/s390/lib/uaccess_mvcos.c |   77 ++++++++++++++++++++++++++++++++++++++++--
 arch/s390/lib/uaccess_std.c   |   20 +---------
 2 files changed, 77 insertions(+), 20 deletions(-)

--- a/arch/s390/lib/uaccess_mvcos.c
+++ b/arch/s390/lib/uaccess_mvcos.c
@@ -200,6 +200,79 @@ static size_t strncpy_from_user_mvcos(si
 	return done;
 }
 
+#define __futex_atomic_op(insn, ret, oldval, newval, uaddr, oparg)	\
+	asm volatile(							\
+		"   sacf  256\n"					\
+		"0: l     %1,0(%6)\n"					\
+		"1:"insn						\
+		"2: cs    %1,%2,0(%6)\n"				\
+		"3: jl    1b\n"						\
+		"   lhi   %0,0\n"					\
+		"4: sacf  768\n"					\
+		EX_TABLE(0b,4b) EX_TABLE(2b,4b) EX_TABLE(3b,4b)		\
+		: "=d" (ret), "=&d" (oldval), "=&d" (newval),		\
+		  "=m" (*uaddr)						\
+		: "0" (-EFAULT), "d" (oparg), "a" (uaddr),		\
+		  "m" (*uaddr) : "cc");
+
+static int futex_atomic_op_mvcos(int op, u32 __user *uaddr, int oparg, int *old)
+{
+	int oldval = 0, newval, ret;
+	unsigned long asce;
+
+	__ctl_store(asce, 1, 1);
+	__ctl_load(S390_lowcore.kernel_asce, 1, 1);
+	switch (op) {
+	case FUTEX_OP_SET:
+		__futex_atomic_op("lr %2,%5\n",
+				  ret, oldval, newval, uaddr, oparg);
+		break;
+	case FUTEX_OP_ADD:
+		__futex_atomic_op("lr %2,%1\nar %2,%5\n",
+				  ret, oldval, newval, uaddr, oparg);
+		break;
+	case FUTEX_OP_OR:
+		__futex_atomic_op("lr %2,%1\nor %2,%5\n",
+				  ret, oldval, newval, uaddr, oparg);
+		break;
+	case FUTEX_OP_ANDN:
+		__futex_atomic_op("lr %2,%1\nnr %2,%5\n",
+				  ret, oldval, newval, uaddr, oparg);
+		break;
+	case FUTEX_OP_XOR:
+		__futex_atomic_op("lr %2,%1\nxr %2,%5\n",
+				  ret, oldval, newval, uaddr, oparg);
+		break;
+	default:
+		ret = -ENOSYS;
+	}
+	*old = oldval;
+	__ctl_load(asce, 1, 1);
+	return ret;
+}
+
+static int futex_atomic_cmpxchg_mvcos(u32 *uval, u32 __user *uaddr,
+				      u32 oldval, u32 newval)
+{
+	unsigned long asce;
+	int ret;
+
+	__ctl_store(asce, 1, 1);
+	__ctl_load(S390_lowcore.kernel_asce, 1, 1);
+	asm volatile(
+		"   sacf 256\n"
+		"0: cs   %1,%4,0(%5)\n"
+		"1: la   %0,0\n"
+		"2: sacf 768\n"
+		EX_TABLE(0b,2b) EX_TABLE(1b,2b)
+		: "=d" (ret), "+d" (oldval), "=m" (*uaddr)
+		: "0" (-EFAULT), "d" (newval), "a" (uaddr), "m" (*uaddr)
+		: "cc", "memory" );
+	*uval = oldval;
+	__ctl_load(asce, 1, 1);
+	return ret;
+}
+
 struct uaccess_ops uaccess_mvcos = {
 	.copy_from_user = copy_from_user_mvcos_check,
 	.copy_from_user_small = copy_from_user_std,
@@ -222,6 +295,6 @@ struct uaccess_ops uaccess_mvcos_switch
 	.clear_user = clear_user_mvcos,
 	.strnlen_user = strnlen_user_mvcos,
 	.strncpy_from_user = strncpy_from_user_mvcos,
-	.futex_atomic_op = futex_atomic_op_pt,
-	.futex_atomic_cmpxchg = futex_atomic_cmpxchg_pt,
+	.futex_atomic_op = futex_atomic_op_mvcos,
+	.futex_atomic_cmpxchg = futex_atomic_cmpxchg_mvcos,
 };
--- a/arch/s390/lib/uaccess_std.c
+++ b/arch/s390/lib/uaccess_std.c
@@ -71,14 +71,6 @@ size_t copy_from_user_std(size_t size, c
 	return size;
 }
 
-static size_t copy_from_user_std_check(size_t size, const void __user *ptr,
-				       void *x)
-{
-	if (size <= 1024)
-		return copy_from_user_std(size, ptr, x);
-	return copy_from_user_pt(size, ptr, x);
-}
-
 size_t copy_to_user_std(size_t size, void __user *ptr, const void *x)
 {
 	unsigned long tmp1, tmp2;
@@ -111,14 +103,6 @@ size_t copy_to_user_std(size_t size, voi
 	return size;
 }
 
-static size_t copy_to_user_std_check(size_t size, void __user *ptr,
-				     const void *x)
-{
-	if (size <= 1024)
-		return copy_to_user_std(size, ptr, x);
-	return copy_to_user_pt(size, ptr, x);
-}
-
 static size_t copy_in_user_std(size_t size, void __user *to,
 			       const void __user *from)
 {
@@ -306,9 +290,9 @@ int futex_atomic_cmpxchg_std(u32 *uval,
 }
 
 struct uaccess_ops uaccess_std = {
-	.copy_from_user = copy_from_user_std_check,
+	.copy_from_user = copy_from_user_std,
 	.copy_from_user_small = copy_from_user_std,
-	.copy_to_user = copy_to_user_std_check,
+	.copy_to_user = copy_to_user_std,
 	.copy_to_user_small = copy_to_user_std,
 	.copy_in_user = copy_in_user_std,
 	.clear_user = clear_user_std,
