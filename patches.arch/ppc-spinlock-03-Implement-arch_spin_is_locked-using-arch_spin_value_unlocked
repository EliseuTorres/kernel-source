From: Michael Ellerman <mpe@ellerman.id.au>
Subject: powerpc: Implement arch_spin_is_locked() using arch_spin_value_unlocked()
Git-commit: 7179ba52889bef7e5e23f72908270e1ab2b7fc6f
Patch-mainline: v3.14-rc1
References: bsc#893758

 powerpc: Implement arch_spin_is_locked() using arch_spin_value_unlocked()

At a glance these are just the inverse of each other. The one subtlety
is that arch_spin_value_unlocked() takes the lock by value, rather than
as a pointer, which is important for the lockref code.

On the other hand arch_spin_is_locked() doesn't really care, so
implement it in terms of arch_spin_value_unlocked().

Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Acked-by: Torsten Duwe <duwe@suse.de>

--- a/arch/powerpc/include/asm/spinlock.h
+++ b/arch/powerpc/include/asm/spinlock.h
@@ -29,8 +29,6 @@
 #include <asm/synch.h>
 #include <asm/ppc-opcode.h>
 
-#define arch_spin_is_locked(x)		((x)->slock != 0)
-
 #ifdef CONFIG_PPC64
 /* use 0x800000yy when locked, where yy == CPU number */
 #define LOCK_TOKEN	(*(u32 *)(&get_paca()->lock_token))
@@ -56,6 +54,11 @@ static __always_inline int arch_spin_val
 	return lock.slock == 0;
 }
 
+static inline int arch_spin_is_locked(arch_spinlock_t *lock)
+{
+	return !arch_spin_value_unlocked(*lock);
+}
+
 /*
  * This returns the old value in the lock, so we succeeded
  * in getting the lock if the return value is 0.
