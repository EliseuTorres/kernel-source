From: Mel Gorman <mgorman@suse.de>
Date: Thu, 26 May 2011 09:52:18 +0100
Subject: [PATCH] mm: vmscan: kswapd should not free an excessive number of pages when balancing small zones
References: Reclaim/compaction (fate#311931)
Patch-mainline: yes (2.6.39)
Commit-ID: 8afdcece4911e51cfff2b50a269418914cab8a3f

When reclaiming for order-0 pages, kswapd requires that all zones
be balanced.  Each cycle through balance_pgdat() does background
ageing on all zones if necessary and applies equal pressure on the
inactive zone unless a lot of pages are free already.

A "lot of free pages" is defined as a "balance gap" above the high
watermark which is currently 7*high_watermark.  Historically this was
reasonable as min_free_kbytes was small.  However, on systems using
huge pages, it is recommended that min_free_kbytes is higher and it
is tuned with hugeadm --set-recommended-min_free_kbytes.  With the
introduction of transparent huge page support, this recommended value
is also applied.  On X86-64 with 4G of memory, min_free_kbytes becomes
67584 so one would expect around 68M of memory to be free.  The Normal
zone is approximately 35000 pages so under even normal memory pressure
such as copying a large file, it gets exhausted quickly.  As it
is getting exhausted, kswapd applies pressure equally to all zones,
including the DMA32 zone.  DMA32 is approximately 700,000 pages with a
high watermark of around 23,000 pages.  In this situation, kswapd will
reclaim around (23000*8 where 8 is the high watermark + balance gap of
7 * high watermark) pages or 718M of pages before the zone is ignored.
What the user sees is that free memory far higher than it should be.

To avoid an excessive number of pages being reclaimed from the
larger zones, explicitely defines the "balance gap" to be either 1%
of the zone or the low watermark for the zone, whichever is smaller.
While kswapd will check all zones to apply pressure, it'll ignore
zones that meets the (high_wmark + balance_gap) watermark.

To test this, 80G were copied from a partition
and the amount of memory being used was recorded.
A comparison of a patch and unpatched kernel can be seen at
http://www.csn.ul.ie/~mel/postings/minfree-20110222/memory-usage-hydra.ps
and shows that kswapd is not reclaiming as much memory with the
patch applied.

Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
Signed-off-by: Mel Gorman <mgorman@suse.de>
Acked-by: Rik van Riel <riel@redhat.com>
Cc: Shaohua Li <shaohua.li@intel.com>
Cc: "Chen, Tim C" <tim.c.chen@intel.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 include/linux/swap.h |    9 +++++++++
 mm/vmscan.c          |   16 +++++++++++++---
 2 files changed, 22 insertions(+), 3 deletions(-)

diff --git a/include/linux/swap.h b/include/linux/swap.h
index ca1b22e..1e7e976 100644
--- a/include/linux/swap.h
+++ b/include/linux/swap.h
@@ -114,6 +114,15 @@ enum {
 #define SWAP_CLUSTER_MAX 32
 #define COMPACT_CLUSTER_MAX SWAP_CLUSTER_MAX
 
+/*
+ * Ratio between the present memory in the zone and the "gap" that
+ * we're allowing kswapd to shrink in addition to the per-zone high
+ * wmark, even for zones that already have the high wmark satisfied,
+ * in order to provide better per-zone lru behavior. We are ok to
+ * spend not more than 1% of the memory for this zone balancing "gap".
+ */
+#define KSWAPD_ZONE_BALANCE_GAP_RATIO 100
+
 #define SWAP_MAP_MAX	0x7ffe
 #define SWAP_MAP_BAD	0x7fff
 #define SWAP_HAS_CACHE  0x8000		/* There is a swap cache of entry. */
diff --git a/mm/vmscan.c b/mm/vmscan.c
index 7876eda..f975ddd 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -2254,6 +2254,7 @@ loop_again:
 			struct zone *zone = pgdat->node_zones + i;
 			int nr_slab;
 			int nid, zid;
+			unsigned long balance_gap;
 
 			if (!populated_zone(zone))
 				continue;
@@ -2275,11 +2276,20 @@ loop_again:
 			mem_cgroup_soft_limit_reclaim(zone, order, sc.gfp_mask,
 							nid, zid);
 			/*
-			 * We put equal pressure on every zone, unless one
-			 * zone has way too many pages free already.
+			 * We put equal pressure on every zone, unless
+			 * one zone has way too many pages free
+			 * already. The "too many pages" is defined
+			 * as the high wmark plus a "gap" where the
+			 * gap is either the low watermark or 1%
+			 * of the zone, whichever is smaller.
 			 */
+			balance_gap = min(low_wmark_pages(zone),
+				(zone->present_pages +
+					KSWAPD_ZONE_BALANCE_GAP_RATIO-1) /
+				KSWAPD_ZONE_BALANCE_GAP_RATIO);
 			if (!zone_watermark_ok(zone, order,
-					8*high_wmark_pages(zone), end_zone, 0))
+					high_wmark_pages(zone) + balance_gap,
+					end_zone, 0))
 				shrink_zone(priority, zone, &sc);
 			reclaim_state->reclaimed_slab = 0;
 			nr_slab = shrink_slab(sc.nr_scanned, GFP_KERNEL,
