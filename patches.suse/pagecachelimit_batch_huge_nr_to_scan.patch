From: Michal Hocko <mhocko@suse.cz>
Subject: pagecache_limit: batch large nr_to_scan targets
Patch-mainline: never
References: bnc#895221

Although pagecache_limit is expected to be set before the load is started there
seem to be a user which sets the limit after the machine is short on memory and
has a large amount of the page cache already. Although such a usage is dubious
at best we still shouldn't fall flat under such conditions.

We had a report where a machine with 512GB of RAM crashed as a result of hard
lockup detector (which is on by default) when the limit was set to 1G because
the page cache reclaimer got a target of 22M pages and isolate_lru_pages simply
starved other spinners for too long.

This patch batches the scan target by SWAP_CLUSTER_MAX chunks to prevent
from such issues. It should be still noted that setting limit to a
very small value wrt. an already large page cache target is dangerous and can
lead to big reclaim storms and page cache over-reclaim.

Signed-off-by: Michal Hocko <mhocko@suse.cz>

---
 mm/vmscan.c |   15 ++++++++++-----
 1 file changed, 10 insertions(+), 5 deletions(-)

--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -3191,11 +3191,16 @@
 				/* shrink_list takes lru_lock with IRQ off so we
 				 * should be careful about really huge nr_to_scan
 				 */
-				nr_reclaimed += shrink_list(l, nr_to_scan, zone,
-								sc, prio);
-				if (nr_reclaimed >= nr_pages) {
-					pagecache_reclaim_unlock_zone(zone);
-					goto out_wakeup;
+				while (nr_to_scan > 0) {
+					unsigned long batch = min_t(unsigned long, nr_to_scan, SWAP_CLUSTER_MAX);
+
+					nr_reclaimed += shrink_list(l, batch, zone,
+									sc, prio);
+					if (nr_reclaimed >= nr_pages) {
+						pagecache_reclaim_unlock_zone(zone);
+						goto out_wakeup;
+					}
+					nr_to_scan -= batch;
 				}
 			}
 		}
