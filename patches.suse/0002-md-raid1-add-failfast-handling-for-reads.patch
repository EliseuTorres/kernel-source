From: NeilBrown <neilb@suse.de>
Date: Thu, 24 Nov 2011 11:12:28 +1100
Subject: [PATCH 2/5] md/raid1 add failfast handling for reads.
References: Fate#311379
Patch-mainline: no

If a device is marked FailFast and it is not the only device
we can read from, we mark the bio as REQ_FAILFAST_DEV.

If this does fail, we don't try read repair but just allow
failure.
If it was the last device it doesn't fail of course so the retry
happens on the same device - this time without FAILFAST.  A subsequent
failure will not retry but will just pass up the error.

During resync we may use FAILFAST requests and on a failure we will
simply use the other device(s).

During recovery we will only use FAILFAST in the unusual case were
there are multiple places to read from - i.e. if there are > 2
devices.
If we get a failure we will fail the device and complete the
resync/recovery with remaining devices.

Signed-off-by: NeilBrown <neilb@suse.de>
---
 drivers/md/raid1.c |   69 +++++++++++++++++++++++++++++++++++++++++++----------
 drivers/md/raid1.h |    2 +
 2 files changed, 58 insertions(+), 13 deletions(-)

--- linux-3.0-SLE11-SP2.orig/drivers/md/raid1.c
+++ linux-3.0-SLE11-SP2/drivers/md/raid1.c
@@ -257,8 +257,10 @@ static void raid1_end_read_request(struc
 	r1bio_t *r1_bio = bio->bi_private;
 	int mirror;
 	conf_t *conf = r1_bio->mddev->private;
+	mdk_rdev_t *rdev;
 
 	mirror = r1_bio->read_disk;
+	rdev = conf->mirrors[mirror].rdev;
 	/*
 	 * this branch is our 'one mirror IO has finished' event handler:
 	 */
@@ -266,6 +268,11 @@ static void raid1_end_read_request(struc
 
 	if (uptodate)
 		set_bit(R1BIO_Uptodate, &r1_bio->state);
+	else if (test_bit(FailFast, &rdev->flags) &&
+		 test_bit(R1BIO_FailFast, &r1_bio->state))
+		/* This was a fail-fast read so we definitely
+		 * want to retry */
+		;
 	else {
 		/* If all other devices have failed, we want to return
 		 * the error upwards rather than fail the last device.
@@ -428,6 +435,8 @@ static int read_balance(conf_t *conf, r1
  retry:
 	best_disk = -1;
 	best_dist = MaxSector;
+	clear_bit(R1BIO_FailFast, &r1_bio->state);
+
 	if (conf->mddev->recovery_cp < MaxSector &&
 	    (this_sector + sectors >= conf->next_resync)) {
 		choose_first = 1;
@@ -462,15 +471,21 @@ static int read_balance(conf_t *conf, r1
 		 * even be best.
 		 */
 		dist = abs(this_sector - conf->mirrors[disk].head_position);
-		if (choose_first
-		    /* Don't change to another disk for sequential reads */
-		    || conf->next_seq_sect == this_sector
-		    || dist == 0
-		    /* If device is idle, use it */
-		    || atomic_read(&rdev->nr_pending) == 0) {
+		if (choose_first) {
 			best_disk = disk;
 			break;
 		}
+		if (
+		    /* Don't change to another disk for sequential reads */
+		    conf->next_seq_sect == this_sector
+		    /* If device is idle, use it */
+		    || atomic_read(&rdev->nr_pending) == 0)
+			dist = 0;
+
+		if (best_disk >= 0)
+			/* At least two disks to choose from so failfast is OK */
+			set_bit(R1BIO_FailFast, &r1_bio->state);
+
 		if (dist < best_dist) {
 			best_dist = dist;
 			best_disk = disk;
@@ -799,6 +814,9 @@ static int make_request(mddev_t *mddev,
 		read_bio->bi_bdev = mirror->rdev->bdev;
 		read_bio->bi_end_io = raid1_end_read_request;
 		read_bio->bi_rw = READ | do_sync;
+		if (test_bit(FailFast, &mirror->rdev->flags) &&
+		    test_bit(R1BIO_FailFast, &r1_bio->state))
+			read_bio->bi_rw |= REQ_FAILFAST_DEV;
 		read_bio->bi_private = r1_bio;
 
 		generic_make_request(read_bio);
@@ -951,6 +969,7 @@ static void error(mddev_t *mddev, mdk_rd
 {
 	char b[BDEVNAME_SIZE];
 	conf_t *conf = mddev->private;
+	unsigned long flags;
 
 	/*
 	 * If it is not operational, then we have already marked it as dead
@@ -958,6 +977,7 @@ static void error(mddev_t *mddev, mdk_rd
 	 * next level up know.
 	 * else mark the drive as failed
 	 */
+	spin_lock_irqsave(&conf->device_lock, flags);
 	if (test_bit(In_sync, &rdev->flags)
 	    && (conf->raid_disks - mddev->degraded) == 1) {
 		/*
@@ -967,20 +987,19 @@ static void error(mddev_t *mddev, mdk_rd
 		 * it is very likely to fail.
 		 */
 		mddev->recovery_disabled = 1;
+		spin_unlock_irqrestore(&conf->device_lock, flags);
 		return;
 	}
 	if (test_and_clear_bit(In_sync, &rdev->flags)) {
-		unsigned long flags;
-		spin_lock_irqsave(&conf->device_lock, flags);
 		mddev->degraded++;
 		set_bit(Faulty, &rdev->flags);
-		spin_unlock_irqrestore(&conf->device_lock, flags);
 		/*
 		 * if recovery is running, make sure it aborts.
 		 */
 		set_bit(MD_RECOVERY_INTR, &mddev->recovery);
 	} else
 		set_bit(Faulty, &rdev->flags);
+	spin_unlock_irqrestore(&conf->device_lock, flags);
 	set_bit(MD_CHANGE_DEVS, &mddev->flags);
 	printk(KERN_ALERT
 	       "md/raid1:%s: Disk failure on %s, disabling device.\n"
@@ -1214,12 +1233,24 @@ static int fix_sync_read_error(r1bio_t *
 	sector_t sect = r1_bio->sector;
 	int sectors = r1_bio->sectors;
 	int idx = 0;
+	mdk_rdev_t *rdev;
+
+	rdev = conf->mirrors[r1_bio->read_disk].rdev;
+	if (test_bit(FailFast, &rdev->flags)) {
+		/* Don't try recovering from here - just fail it
+		 * ... unless it is the last working device of course */
+		md_error(mddev, rdev);
+		if (test_bit(Faulty, &rdev->flags))
+			/* Don't try to read from here, but make sure
+			 * put_buf does it's thing
+			 */
+			r1_bio->bios[r1_bio->read_disk]->bi_end_io = end_sync_write;
+	}
 
 	while(sectors) {
 		int s = sectors;
 		int d = r1_bio->read_disk;
 		int success = 0;
-		mdk_rdev_t *rdev;
 		int start;
 
 		if (s > (PAGE_SIZE>>9))
@@ -1566,7 +1597,9 @@ static void raid1d(mddev_t *mddev)
 			 * This is all done synchronously while the array is
 			 * frozen
 			 */
-			if (mddev->ro == 0) {
+			rdev = conf->mirrors[r1_bio->read_disk].rdev;
+			if (mddev->ro == 0
+			    && !test_bit(FailFast, &rdev->flags)) {
 				freeze_array(conf);
 				fix_read_error(conf, r1_bio->read_disk,
 					       r1_bio->sector,
@@ -1577,17 +1610,18 @@ static void raid1d(mddev_t *mddev)
 					 conf->mirrors[r1_bio->read_disk].rdev);
 
 			bio = r1_bio->bios[r1_bio->read_disk];
+			r1_bio->bios[r1_bio->read_disk] =
+				mddev->ro ? IO_BLOCKED : NULL;
 			if ((disk=read_balance(conf, r1_bio)) == -1) {
 				printk(KERN_ALERT "md/raid1:%s: %s: unrecoverable I/O"
 				       " read error for block %llu\n",
 				       mdname(mddev),
 				       bdevname(bio->bi_bdev,b),
 				       (unsigned long long)r1_bio->sector);
+				bio_put(bio);
 				raid_end_bio_io(r1_bio);
 			} else {
 				const unsigned long do_sync = r1_bio->master_bio->bi_rw & REQ_SYNC;
-				r1_bio->bios[r1_bio->read_disk] =
-					mddev->ro ? IO_BLOCKED : NULL;
 				r1_bio->read_disk = disk;
 				bio_put(bio);
 				bio = bio_clone_mddev(r1_bio->master_bio,
@@ -1604,6 +1638,9 @@ static void raid1d(mddev_t *mddev)
 				bio->bi_bdev = rdev->bdev;
 				bio->bi_end_io = raid1_end_read_request;
 				bio->bi_rw = READ | do_sync;
+				if (test_bit(FailFast, &rdev->flags) &&
+				    test_bit(R1BIO_FailFast, &r1_bio->state))
+					bio->bi_rw |= REQ_FAILFAST_DEV;
 				bio->bi_private = r1_bio;
 				generic_make_request(bio);
 			}
@@ -1761,6 +1798,8 @@ static sector_t sync_request(mddev_t *md
 		bio->bi_sector = sector_nr + rdev->data_offset;
 		bio->bi_bdev = rdev->bdev;
 		bio->bi_private = r1_bio;
+		if (test_bit(FailFast, &rdev->flags))
+			bio->bi_rw |= REQ_FAILFAST_DEV;
 	}
 	rcu_read_unlock();
 	if (disk < 0)
@@ -1840,6 +1879,8 @@ static sector_t sync_request(mddev_t *md
 			bio = r1_bio->bios[i];
 			if (bio->bi_end_io == end_sync_read) {
 				md_sync_acct(bio->bi_bdev, nr_sectors);
+				if (read_targets == 1)
+					bio->bi_rw &= ~REQ_FAILFAST_MASK;
 				generic_make_request(bio);
 			}
 		}
@@ -1847,6 +1888,8 @@ static sector_t sync_request(mddev_t *md
 		atomic_set(&r1_bio->remaining, 1);
 		bio = r1_bio->bios[r1_bio->read_disk];
 		md_sync_acct(bio->bi_bdev, nr_sectors);
+		if (read_targets == 1)
+			bio->bi_rw &= ~REQ_FAILFAST_MASK;
 		generic_make_request(bio);
 
 	}
--- linux-3.0-SLE11-SP2.orig/drivers/md/raid1.h
+++ linux-3.0-SLE11-SP2/drivers/md/raid1.h
@@ -126,6 +126,8 @@ struct r1bio_s {
  * Record that bi_end_io was called with this flag...
  */
 #define	R1BIO_Returned 6
+/* failfast devices did receive failfast requests. */
+#define	R1BIO_FailFast 7
 
 extern int md_raid1_congested(mddev_t *mddev, int bits);
 
