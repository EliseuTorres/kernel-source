From: Sheng Yang <sheng@linux.intel.com>
Subject: [PATCH] KVM: x86: Use unlazy_fpu() for host FPU
References: FATE#311768
Git-commit: 7cf30855e02be7a207ffebb8b9350986f2ba83e9
Patch-mainline: v2.6.36-rc1

We can avoid unnecessary fpu load when userspace process
didn't use FPU frequently.

Derived from Avi's idea.

Signed-off-by: Sheng Yang <sheng@linux.intel.com>
Signed-off-by: Avi Kivity <avi@redhat.com>
Acked-by: Bruce Rogers <brogers@suse.com>
---
 arch/x86/include/asm/kvm_host.h |    1 -
 arch/x86/kvm/x86.c              |   18 ++----------------
 2 files changed, 2 insertions(+), 17 deletions(-)

Index: linux-2.6.32-SLE11-SP2/arch/x86/include/asm/kvm_host.h
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/arch/x86/include/asm/kvm_host.h
+++ linux-2.6.32-SLE11-SP2/arch/x86/include/asm/kvm_host.h
@@ -307,7 +307,6 @@ struct kvm_vcpu_arch {
 		unsigned long mmu_seq;
 	} update_pte;
 
-	struct i387_fxsave_struct host_fx_image;
 	struct i387_fxsave_struct guest_fx_image;
 
 	gva_t mmio_fault_cr2;
Index: linux-2.6.32-SLE11-SP2/arch/x86/kvm/x86.c
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/arch/x86/kvm/x86.c
+++ linux-2.6.32-SLE11-SP2/arch/x86/kvm/x86.c
@@ -50,6 +50,7 @@
 #include <asm/mtrr.h>
 #include <asm/mce.h>
 #include <asm/pvclock.h>
+#include <asm/i387.h>
 
 #define MAX_IO_MSRS 256
 #define CR0_RESERVED_BITS						\
@@ -5039,21 +5040,10 @@ void fx_init(struct kvm_vcpu *vcpu)
 {
 	unsigned after_mxcsr_mask;
 
-	/*
-	 * Touch the fpu the first time in non atomic context as if
-	 * this is the first fpu instruction the exception handler
-	 * will fire before the instruction returns and it'll have to
-	 * allocate ram with GFP_KERNEL.
-	 */
-	if (!used_math())
-		kvm_fx_save(&vcpu->arch.host_fx_image);
-
 	/* Initialize guest FPU by resetting ours and saving into guest's */
 	preempt_disable();
-	kvm_fx_save(&vcpu->arch.host_fx_image);
 	kvm_fx_finit();
 	kvm_fx_save(&vcpu->arch.guest_fx_image);
-	kvm_fx_restore(&vcpu->arch.host_fx_image);
 	preempt_enable();
 
 	vcpu->arch.cr0 |= X86_CR0_ET;
@@ -5070,7 +5060,7 @@ void kvm_load_guest_fpu(struct kvm_vcpu
 		return;
 
 	vcpu->guest_fpu_loaded = 1;
-	kvm_fx_save(&vcpu->arch.host_fx_image);
+	unlazy_fpu(current);
 	kvm_fx_restore(&vcpu->arch.guest_fx_image);
 }
 EXPORT_SYMBOL_GPL(kvm_load_guest_fpu);
@@ -5082,7 +5072,6 @@ void kvm_put_guest_fpu(struct kvm_vcpu *
 
 	vcpu->guest_fpu_loaded = 0;
 	kvm_fx_save(&vcpu->arch.guest_fx_image);
-	kvm_fx_restore(&vcpu->arch.host_fx_image);
 	++vcpu->stat.fpu_reload;
 	set_bit(KVM_REQ_DEACTIVATE_FPU, &vcpu->requests);
 }
@@ -5108,9 +5097,6 @@ int kvm_arch_vcpu_setup(struct kvm_vcpu
 {
 	int r;
 
-	/* We do fxsave: this must be aligned. */
-	BUG_ON((unsigned long)&vcpu->arch.host_fx_image & 0xF);
-
 	vcpu->arch.mtrr_state.have_fixed = 1;
 	vcpu_load(vcpu);
 	r = kvm_arch_vcpu_reset(vcpu);
