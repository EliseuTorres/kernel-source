From: Mel Gorman <mgorman@suse.de>
Date: Fri, 18 Mar 2011 10:56:46 +0000
Subject: [PATCH] netvm: Reduce the size of the routing reserves and be careful of dst_alloc()
Patch-mainline: Not yet
References: bnc#678466

The two biggest reserves for INET are considered to be the route cache
and ip-fragment cache. The routing cache reserve is related to the
maximum number of entries that can be in the routing cache but in
practice, it is rarely this large. In fact, for swap-over-nfs, there is
an expectation that the routing cache entry is only one per swapfile and
likely to persist. This patch alters the size of the route cache reserve
to be related to the maximum number of swap files supported by the
system. Care is then taken to ensure dst_alloc does not use the reserves
for unrelated packets.

Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 net/core/dst.c   |   20 ++++++++++++++++++--
 net/ipv4/route.c |   19 ++++++++++++-------
 net/ipv6/route.c |   18 +++++++++++-------
 3 files changed, 41 insertions(+), 16 deletions(-)

Index: linux-2.6.32-SLE11-SP1/net/core/dst.c
===================================================================
--- linux-2.6.32-SLE11-SP1.orig/net/core/dst.c
+++ linux-2.6.32-SLE11-SP1/net/core/dst.c
@@ -165,14 +165,30 @@ EXPORT_SYMBOL(dst_discard);
 void * dst_alloc(struct dst_ops * ops)
 {
 	struct dst_entry * dst;
+	unsigned long pflags = current->flags;
+	current->flags &= ~PF_MEMALLOC;
 
 	if (ops->gc && atomic_read(&ops->entries) > ops->gc_thresh) {
 		if (ops->gc(ops))
 			return NULL;
 	}
 	dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC);
-	if (!dst)
-		return NULL;
+	tsk_restore_flags(current, pflags, PF_MEMALLOC);
+	if (!dst) {
+		if (current->flags & PF_MEMALLOC) {
+			/*
+			 * If current had PF_MEMALLOC, retry the allocation
+			 * with it. This shouldn't happen because the rtable
+			 * entry for a route of an emergency socket should
+			 * not be cleared up. Warn if this assumption breaks
+			 */
+			WARN_ON(1);
+			dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC);
+			if (!dst)
+				return NULL;
+		} else
+			return NULL;
+	}
 	atomic_set(&dst->__refcnt, 0);
 	dst->ops = ops;
 	dst->lastuse = jiffies;
Index: linux-2.6.32-SLE11-SP1/net/ipv4/route.c
===================================================================
--- linux-2.6.32-SLE11-SP1.orig/net/ipv4/route.c
+++ linux-2.6.32-SLE11-SP1/net/ipv4/route.c
@@ -90,6 +90,7 @@
 #include <linux/jhash.h>
 #include <linux/rcupdate.h>
 #include <linux/times.h>
+#include <linux/swap.h>
 #include <net/dst.h>
 #include <net/net_namespace.h>
 #include <net/protocol.h>
@@ -420,12 +421,8 @@ proc_dointvec_route(struct ctl_table *ta
 
 	ret = proc_dointvec(table, write, buffer, lenp, ppos);
 
-	if (!ret && write) {
-		ret = mem_reserve_kmem_cache_set(&ipv4_route_reserve,
-				ipv4_dst_ops.kmem_cachep, new_size);
-		if (!ret)
-			ip_rt_max_size = new_size;
-	}
+	if (!ret && write)
+		ip_rt_max_size = new_size;
 	mutex_unlock(&ipv4_route_lock);
 
 	return ret;
@@ -3501,8 +3498,16 @@ int __init ip_rt_init(void)
 
 	mem_reserve_init(&ipv4_route_reserve, "IPv4 route cache",
 			&net_rx_reserve);
+
+	/*
+	 * Reserve one route cache entry per swapfile that could possibly be
+	 * allocated. Even this should not be necessary as once an NFS-backed
+	 * swapfile is activated, the rtable entry should not be cleared from
+	 * the routing cache. dst_alloc will detect if this assumption ever
+	 * breaks but having the reserve will prevent a deadlock
+	 */
 	mem_reserve_kmem_cache_set(&ipv4_route_reserve,
-			ipv4_dst_ops.kmem_cachep, ip_rt_max_size);
+			ipv4_dst_ops.kmem_cachep, MAX_SWAPFILES);
 
 	devinet_init();
 	ip_fib_init();
Index: linux-2.6.32-SLE11-SP1/net/ipv6/route.c
===================================================================
--- linux-2.6.32-SLE11-SP1.orig/net/ipv6/route.c
+++ linux-2.6.32-SLE11-SP1/net/ipv6/route.c
@@ -41,6 +41,7 @@
 #include <linux/proc_fs.h>
 #include <linux/seq_file.h>
 #include <linux/nsproxy.h>
+#include <linux/swap.h>
 #include <net/net_namespace.h>
 #include <net/snmp.h>
 #include <net/ipv6.h>
@@ -2583,12 +2584,8 @@ proc_dointvec_route(struct ctl_table *ta
 
 	ret = proc_dointvec(table, write, buffer, lenp, ppos);
 
-	if (!ret && write) {
-		ret = mem_reserve_kmem_cache_set(&net->ipv6.ip6_rt_reserve,
-				net->ipv6.ip6_dst_ops.kmem_cachep, new_size);
-		if (!ret)
-			net->ipv6.sysctl.ip6_rt_max_size = new_size;
-	}
+	if (!ret && write)
+		net->ipv6.sysctl.ip6_rt_max_size = new_size;
 	mutex_unlock(&net->ipv6.sysctl.ip6_rt_lock);
 
 	return ret;
@@ -2787,9 +2784,16 @@ static int ip6_route_net_init(struct net
 
 	mem_reserve_init(&net->ipv6.ip6_rt_reserve, "IPv6 route cache",
 			 &net_rx_reserve);
+	/*
+	 * Reserve one route cache entry per swapfile that could possibly be
+	 * allocated. Even this should not be necessary as once an NFS-backed
+	 * swapfile is activated, the rtable entry should not be cleared from
+	 * the routing cache. dst_alloc will detect if this assumption ever
+	 * breaks but having the reserve will prevent a deadlock
+	 */
 	ret = mem_reserve_kmem_cache_set(&net->ipv6.ip6_rt_reserve,
 			net->ipv6.ip6_dst_ops.kmem_cachep,
-			net->ipv6.sysctl.ip6_rt_max_size);
+			MAX_SWAPFILES);
 	if (ret)
 		goto out_reserve_fail;
 
