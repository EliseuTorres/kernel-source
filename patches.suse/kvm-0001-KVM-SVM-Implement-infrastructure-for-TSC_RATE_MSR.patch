From: Joerg Roedel <joerg.roedel@amd.com>
Subject: [PATCH 1/5] KVM: SVM: Implement infrastructure for TSC_RATE_MSR
Reference: FATE#309762
Git-commit: fbc0db76b77125e0a5131fb886cbaafa1ec5c525
Patch-mainline: v3.0-rc1

This patch enhances the kvm_amd module with functions to
support the TSC_RATE_MSR which can be used to set a given
tsc frequency for the guest vcpu.

Signed-off-by: Joerg Roedel <joerg.roedel@amd.com>
Acked-by: Bruce Rogers <brogers@suse.com>
---
 arch/x86/include/asm/msr-index.h |    1 +
 arch/x86/kvm/svm.c               |   59 ++++++++++++++++++++++++++++++++++++--
 2 files changed, 57 insertions(+), 3 deletions(-)

Index: linux-2.6.32-SLE11-SP2/arch/x86/include/asm/msr-index.h
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/arch/x86/include/asm/msr-index.h
+++ linux-2.6.32-SLE11-SP2/arch/x86/include/asm/msr-index.h
@@ -106,6 +106,7 @@
    complete list. */
 
 #define MSR_AMD64_PATCH_LEVEL		0x0000008b
+#define MSR_AMD64_TSC_RATIO		0xc0000104
 #define MSR_AMD64_NB_CFG		0xc001001f
 #define MSR_AMD64_PATCH_LOADER		0xc0010020
 #define MSR_AMD64_OSVW_ID_LENGTH	0xc0010140
Index: linux-2.6.32-SLE11-SP2/arch/x86/kvm/svm.c
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/arch/x86/kvm/svm.c
+++ linux-2.6.32-SLE11-SP2/arch/x86/kvm/svm.c
@@ -48,6 +48,7 @@ MODULE_LICENSE("GPL");
 #define SVM_FEATURE_LBRV (1 << 1)
 #define SVM_FEATURE_SVML (1 << 2)
 #define SVM_FEATURE_NRIP (1 << 3)
+#define SVM_FEATURE_TSC_RATE (1 << 4)
 #define SVM_FEATURE_DECODE_ASSIST (1 << 7)
 #define SVM_FEATURE_PAUSE_FILTER (1 << 10)
 
@@ -66,6 +67,8 @@ MODULE_LICENSE("GPL");
 #define nsvm_printk(fmt, args...) do {} while(0)
 #endif
 
+#define TSC_RATIO_RSVD          0xffffff0000000000ULL
+
 static bool erratum_383_found __read_mostly;
 
 static const u32 host_save_user_msrs[] = {
@@ -118,8 +121,13 @@ struct vcpu_svm {
 	u32 *msrpm;
 
 	struct nested_state nested;
+
+	u64  tsc_ratio;
 };
 
+static DEFINE_PER_CPU(u64, current_tsc_ratio);
+#define TSC_RATIO_DEFAULT	0x100000000ULL
+
 /* enable NPT for AMD64 and X86 with PAE */
 #if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)
 static bool npt_enabled = true;
@@ -135,6 +143,7 @@ module_param(nested, int, S_IRUGO);
 
 static void svm_flush_tlb(struct kvm_vcpu *vcpu);
 static void svm_complete_interrupts(struct vcpu_svm *svm);
+static int svm_set_msr(struct kvm_vcpu *vcpu, unsigned ecx, u64 data);
 
 static int nested_svm_exit_handled(struct vcpu_svm *svm);
 static int nested_svm_vmexit(struct vcpu_svm *svm);
@@ -383,6 +392,10 @@ static int has_svm(void)
 
 static void svm_hardware_disable(void *garbage)
 {
+	/* Make sure we clean up behind us */
+	if (svm_has(SVM_FEATURE_TSC_RATE))
+		wrmsrl(MSR_AMD64_TSC_RATIO, TSC_RATIO_DEFAULT);
+
 	cpu_svm_disable();
 }
 
@@ -420,6 +433,11 @@ static void svm_hardware_enable(void *ga
 	wrmsrl(MSR_VM_HSAVE_PA,
 	       page_to_pfn(svm_data->save_area) << PAGE_SHIFT);
 
+	if (svm_has(SVM_FEATURE_TSC_RATE)) {
+		wrmsrl(MSR_AMD64_TSC_RATIO, TSC_RATIO_DEFAULT);
+		__get_cpu_var(current_tsc_ratio) = TSC_RATIO_DEFAULT;
+	}
+
 	svm_init_erratum_383();
 
 	return;
@@ -590,6 +608,32 @@ static __exit void svm_hardware_unsetup(
 	iopm_base = 0;
 }
 
+static u64 __scale_tsc(u64 ratio, u64 tsc)
+{
+	u64 mult, frac, _tsc;
+
+	mult  = ratio >> 32;
+	frac  = ratio & ((1ULL << 32) - 1);
+
+	_tsc  = tsc;
+	_tsc *= mult;
+	_tsc += (tsc >> 32) * frac;
+	_tsc += ((tsc & ((1ULL << 32) - 1)) * frac) >> 32;
+
+	return _tsc;
+}
+
+static u64 svm_scale_tsc(struct kvm_vcpu *vcpu, u64 tsc)
+{
+	struct vcpu_svm *svm = to_svm(vcpu);
+	u64 _tsc = tsc;
+
+	if (svm->tsc_ratio != TSC_RATIO_DEFAULT)
+		_tsc = __scale_tsc(svm->tsc_ratio, tsc);
+
+	return _tsc;
+}
+
 static void init_seg(struct vmcb_seg *seg)
 {
 	seg->selector = 0;
@@ -770,6 +814,8 @@ static struct kvm_vcpu *svm_create_vcpu(
 		goto out;
 	}
 
+	svm->tsc_ratio = TSC_RATIO_DEFAULT;
+
 	err = kvm_vcpu_init(&svm->vcpu, kvm, id);
 	if (err)
 		goto free_svm;
@@ -803,8 +849,7 @@ static struct kvm_vcpu *svm_create_vcpu(
 	svm->vmcb_pa = page_to_pfn(page) << PAGE_SHIFT;
 	svm->asid_generation = 0;
 	init_vmcb(svm);
-	svm->vmcb->control.tsc_offset = 0-native_read_tsc();
-	mark_dirty(svm->vmcb, VMCB_INTERCEPTS);
+	svm_set_msr(&svm->vcpu, MSR_IA32_TSC, 0);
 
 	fx_init(&svm->vcpu);
 	svm->vcpu.fpu_active = 1;
@@ -867,6 +912,12 @@ static void svm_vcpu_load(struct kvm_vcp
 
 	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
 		rdmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
+
+	if (svm_has(SVM_FEATURE_TSC_RATE) &&
+	    svm->tsc_ratio != __get_cpu_var(current_tsc_ratio)) {
+		__get_cpu_var(current_tsc_ratio) = svm->tsc_ratio;
+		wrmsrl(MSR_AMD64_TSC_RATIO, svm->tsc_ratio);
+	}
 }
 
 static void svm_vcpu_put(struct kvm_vcpu *vcpu)
@@ -2358,7 +2409,7 @@ static int svm_get_msr(struct kvm_vcpu *
 		else
 			tsc_offset = svm->vmcb->control.tsc_offset;
 
-		*data = tsc_offset + native_read_tsc();
+		*data = tsc_offset + svm_scale_tsc(vcpu, native_read_tsc());
 		break;
 	}
 	case MSR_K6_STAR:
@@ -2444,9 +2495,10 @@ static int svm_set_msr(struct kvm_vcpu *
 
 	switch (ecx) {
 	case MSR_IA32_TSC: {
-		u64 tsc_offset = data - native_read_tsc();
 		u64 g_tsc_offset = 0;
+		u64 tsc_offset;
 
+		tsc_offset = data - svm_scale_tsc(vcpu, native_read_tsc());
 		if (is_nested(svm)) {
 			g_tsc_offset = svm->vmcb->control.tsc_offset -
 				       svm->nested.hsave->control.tsc_offset;
