From 8378db99cfb63718d54afbca1de71a38bc712756 Mon Sep 17 00:00:00 2001
From: NeilBrown <neilb@suse.de>
Date: Thu, 24 Nov 2011 14:19:26 +1100
Subject: [PATCH 4/5] md/raid10 add failfast handling for reads.
References: Fate#311379
Patch-mainline: 3.3?

If a device is marked FailFast and it is not the only device
we can read from, we mark the bio as REQ_FAILFAST_DEV.

If this does fail-fast, we don't try read repair but just allow
failure.
If it was the last device it doesn't fail of course so the retry
happens on the same device - this time without FAILFAST.  A subsequent
failure will not retry but will just pass up the error.

During resync we may use FAILFAST requests and on a failure we will
simply use the other device(s).

During recovery we will only use FAILFAST in the unusual case were
there are multiple places to read from - i.e. if there are > 2
devices.
If we get a failure we will fail the device and complete the
resync/recovery with remaining devices.

Signed-off-by: NeilBrown <neilb@suse.de>
---
 drivers/md/raid10.c |   73 +++++++++++++++++++++++++++++++++++++++++-----------
 drivers/md/raid10.h |    2 +
 2 files changed, 60 insertions(+), 15 deletions(-)

--- linux-3.0-SLE11-SP2.orig/drivers/md/raid10.c
+++ linux-3.0-SLE11-SP2/drivers/md/raid10.c
@@ -500,6 +500,7 @@ retry:
 	best_slot = -1;
 	best_dist = MaxSector;
 	do_balance = 1;
+	clear_bit(R10BIO_FailFast, &r10_bio->state);
 	/*
 	 * Check if we can balance. We can balance on the whole
 	 * device if no resync is going on (recovery is ok), or below
@@ -523,15 +524,18 @@ retry:
 		if (!do_balance)
 			break;
 
+		if (best_slot >= 0)
+			/* At least 2 disks to choose from so failfast is OK */
+			set_bit(R10BIO_FailFast, &r10_bio->state);
 		/* This optimisation is debatable, and completely destroys
 		 * sequential read speed for 'far copies' arrays.  So only
 		 * keep it for 'near' arrays, and review those later.
 		 */
 		if (conf->near_copies > 1 && !atomic_read(&rdev->nr_pending))
-			break;
+			new_distance = 0;
 
 		/* for far > 1 always use the lowest address */
-		if (conf->far_copies > 1)
+		else if (conf->far_copies > 1)
 			new_distance = r10_bio->devs[slot].addr;
 		else
 			new_distance = abs(r10_bio->devs[slot].addr -
@@ -829,6 +833,9 @@ static int make_request(mddev_t *mddev,
 		read_bio->bi_bdev = mirror->rdev->bdev;
 		read_bio->bi_end_io = raid10_end_read_request;
 		read_bio->bi_rw = READ | do_sync;
+		if (test_bit(FailFast, &mirror->rdev->flags) &&
+		    test_bit(R10BIO_FailFast, &r10_bio->state))
+			read_bio->bi_rw |= REQ_FAILFAST_DEV;
 		read_bio->bi_private = r10_bio;
 
 		generic_make_request(read_bio);
@@ -953,6 +960,7 @@ static void error(mddev_t *mddev, mdk_rd
 {
 	char b[BDEVNAME_SIZE];
 	conf_t *conf = mddev->private;
+	unsigned long flags;
 
 	/*
 	 * If it is not operational, then we have already marked it as dead
@@ -960,8 +968,9 @@ static void error(mddev_t *mddev, mdk_rd
 	 * next level up know.
 	 * else mark the drive as failed
 	 */
+	spin_lock_irqsave(&conf->device_lock, flags);
 	if (test_bit(In_sync, &rdev->flags)
-	    && conf->raid_disks-mddev->degraded == 1)
+	    && conf->raid_disks-mddev->degraded == 1) {
 		/*
 		 * Don't fail the drive, just return an IO error.
 		 * The test should really be more sophisticated than
@@ -969,12 +978,11 @@ static void error(mddev_t *mddev, mdk_rd
 		 * can wait until we do more sophisticated "is the drive
 		 * really dead" tests...
 		 */
+		spin_unlock_irqrestore(&conf->device_lock, flags);
 		return;
+	}
 	if (test_and_clear_bit(In_sync, &rdev->flags)) {
-		unsigned long flags;
-		spin_lock_irqsave(&conf->device_lock, flags);
 		mddev->degraded++;
-		spin_unlock_irqrestore(&conf->device_lock, flags);
 		/*
 		 * if recovery is running, make sure it aborts.
 		 */
@@ -982,6 +990,7 @@ static void error(mddev_t *mddev, mdk_rd
 	}
 	set_bit(Faulty, &rdev->flags);
 	set_bit(MD_CHANGE_DEVS, &mddev->flags);
+	spin_unlock_irqrestore(&conf->device_lock, flags);
 	printk(KERN_ALERT
 	       "md/raid10:%s: Disk failure on %s, disabling device.\n"
 	       "md/raid10:%s: Operation continuing on %d devices.\n",
@@ -1279,6 +1288,7 @@ static void sync_request_write(mddev_t *
 	for (i=0 ; i < conf->copies ; i++) {
 		int  j, d;
 		int vcnt = r10_bio->sectors >> (PAGE_SHIFT-9);
+		mdk_rdev_t *rdev;
 
 		tbio = r10_bio->devs[i].bio;
 
@@ -1286,6 +1296,8 @@ static void sync_request_write(mddev_t *
 			continue;
 		if (i == first)
 			continue;
+		d = r10_bio->devs[i].devnum;
+		rdev = conf->mirrors[d].rdev;
 		if (test_bit(BIO_UPTODATE, &r10_bio->devs[i].bio->bi_flags)) {
 			/* We know that the bi_io_vec layout is the same for
 			 * both 'first' and 'i', so we just compare them.
@@ -1299,10 +1311,14 @@ static void sync_request_write(mddev_t *
 			if (j == vcnt)
 				continue;
 			mddev->resync_mismatches += r10_bio->sectors;
-		}
-		if (test_bit(MD_RECOVERY_CHECK, &mddev->recovery))
-			/* Don't fix anything. */
+			if (test_bit(MD_RECOVERY_CHECK, &mddev->recovery))
+				/* Don't fix anything. */
+				continue;
+		} else if (test_bit(FailFast, &rdev->flags)) {
+			/* Just give up on this device */
+			md_error(rdev->mddev, rdev);
 			continue;
+		}
 		/* Ok, we need to write this bio
 		 * First we need to fixup bv_offset, bv_len and
 		 * bi_vecs, as the read request might have corrupted these
@@ -1328,7 +1344,6 @@ static void sync_request_write(mddev_t *
 		}
 		tbio->bi_end_io = end_sync_write;
 
-		d = r10_bio->devs[i].devnum;
 		atomic_inc(&conf->mirrors[d].rdev->nr_pending);
 		atomic_inc(&r10_bio->remaining);
 		md_sync_acct(conf->mirrors[d].rdev->bdev, tbio->bi_size >> 9);
@@ -1643,16 +1658,21 @@ static void raid10d(mddev_t *mddev)
 			 * This is all done synchronously while the array is
 			 * frozen.
 			 */
-			if (mddev->ro == 0) {
+			rdev = conf->mirrors[mirror].rdev;
+			bio = r10_bio->devs[slot].bio;
+			if (mddev->ro)
+				r10_bio->devs[slot].bio = IO_BLOCKED;
+			else if (!test_bit(FailFast, &rdev->flags)) {
 				freeze_array(conf);
 				fix_read_error(conf, mddev, r10_bio);
 				unfreeze_array(conf);
-			}
-			rdev_dec_pending(conf->mirrors[mirror].rdev, mddev);
+				r10_bio->devs[slot].bio = NULL;
+			} else
+				md_error(mddev, rdev);
+
+			rdev_dec_pending(rdev, mddev);
 
 			bio = r10_bio->devs[slot].bio;
-			r10_bio->devs[slot].bio =
-				mddev->ro ? IO_BLOCKED : NULL;
 			mirror = read_balance(conf, r10_bio);
 			if (mirror == -1) {
 				printk(KERN_ALERT "md/raid10:%s: %s: unrecoverable I/O"
@@ -1680,6 +1700,9 @@ static void raid10d(mddev_t *mddev)
 					+ rdev->data_offset;
 				bio->bi_bdev = rdev->bdev;
 				bio->bi_rw = READ | do_sync;
+				if (test_bit(FailFast, &rdev->flags) &&
+				    test_bit(R10BIO_FailFast, &r10_bio->state))
+					bio->bi_rw |= REQ_FAILFAST_DEV;
 				bio->bi_private = r10_bio;
 				bio->bi_end_io = raid10_end_read_request;
 				generic_make_request(bio);
@@ -1899,6 +1922,8 @@ static sector_t sync_request(mddev_t *md
 				bio->bi_private = r10_bio;
 				bio->bi_end_io = end_sync_read;
 				bio->bi_rw = READ;
+				if (test_bit(FailFast, &conf->mirrors[d].rdev->flags))
+					bio->bi_rw |= REQ_FAILFAST_DEV;
 				bio->bi_sector = r10_bio->devs[j].addr +
 					conf->mirrors[d].rdev->data_offset;
 				bio->bi_bdev = conf->mirrors[d].rdev->bdev;
@@ -1938,6 +1963,22 @@ static sector_t sync_request(mddev_t *md
 					       mdname(mddev));
 				break;
 			}
+			if (r10_bio->devs[0].bio->bi_rw & REQ_FAILFAST_DEV) {
+				/* only want this if there is elsewhere to
+				 * read from
+				 */
+				int targets = 1;
+				for (; j < conf->copies; j++) {
+					int d = r10_bio->devs[j].devnum;
+					if (conf->mirrors[d].rdev &&
+					    test_bit(In_sync,
+						      &conf->mirrors[d].rdev->flags))
+						targets++;
+				}
+				if (targets == 1)
+					r10_bio->devs[0].bio->bi_rw
+						&= ~REQ_FAILFAST_DEV;
+			}
 		}
 		if (biolist == NULL) {
 			while (r10_bio) {
@@ -1992,6 +2033,8 @@ static sector_t sync_request(mddev_t *md
 			bio->bi_private = r10_bio;
 			bio->bi_end_io = end_sync_read;
 			bio->bi_rw = READ;
+			if (test_bit(FailFast, &conf->mirrors[d].rdev->flags))
+				bio->bi_rw |= REQ_FAILFAST_DEV;
 			bio->bi_sector = r10_bio->devs[i].addr +
 				conf->mirrors[d].rdev->data_offset;
 			bio->bi_bdev = conf->mirrors[d].rdev->bdev;
--- linux-3.0-SLE11-SP2.orig/drivers/md/raid10.h
+++ linux-3.0-SLE11-SP2/drivers/md/raid10.h
@@ -119,4 +119,6 @@ struct r10bio_s {
 #define	R10BIO_IsSync	1
 #define	R10BIO_IsRecover 2
 #define	R10BIO_Degraded 3
+/* failfast devices did receive failfast requests. */
+#define	R10BIO_FailFast 4
 #endif
