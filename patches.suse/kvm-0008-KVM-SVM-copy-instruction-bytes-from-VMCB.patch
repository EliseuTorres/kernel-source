From: Andre Przywara <andre.przywara@amd.com>
Subject: [PATCH 8/8] KVM: SVM: copy instruction bytes from VMCB
References: FATE#309761
Git-commit: dc25e89e07d5ef31c476117d2c76b34dbb22196c
Patch-mainline: v2.6.38

In case of a nested page fault or an intercepted #PF newer SVM
implementations provide a copy of the faulting instruction bytes
in the VMCB.
Use these bytes to feed the instruction emulator and avoid the costly
guest instruction fetch in this case.

Backport of dc25e89e07d5ef31c476117d2c76b34dbb22196c

Signed-off-by: Andre Przywara <andre.przywara@amd.com>
Acked-by: Bruce Rogers <brogers@suse.com>
---
 arch/x86/include/asm/kvm_emulate.h |    3 ++-
 arch/x86/include/asm/kvm_host.h    |    8 +++++---
 arch/x86/include/asm/svm.h         |    4 +++-
 arch/x86/kvm/emulate.c             |    9 ++++++++-
 arch/x86/kvm/mmu.c                 |    5 +++--
 arch/x86/kvm/svm.c                 |    4 +++-
 arch/x86/kvm/vmx.c                 |    4 ++--
 arch/x86/kvm/x86.c                 |    9 ++++++---
 8 files changed, 32 insertions(+), 14 deletions(-)

Index: b/arch/x86/include/asm/kvm_emulate.h
===================================================================
--- a/arch/x86/include/asm/kvm_emulate.h
+++ b/arch/x86/include/asm/kvm_emulate.h
@@ -188,7 +188,8 @@ struct x86_emulate_ctxt {
 #endif
 
 int x86_decode_insn(struct x86_emulate_ctxt *ctxt,
-		    struct x86_emulate_ops *ops);
+		    struct x86_emulate_ops *ops,
+		    void *insn, int insn_len);
 int x86_emulate_insn(struct x86_emulate_ctxt *ctxt,
 		     struct x86_emulate_ops *ops);
 
Index: b/arch/x86/include/asm/kvm_host.h
===================================================================
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -575,12 +575,13 @@ enum emulation_result {
 #define EMULTYPE_TRAP_UD	    (1 << 1)
 #define EMULTYPE_SKIP		    (1 << 2)
 int x86_emulate_instruction(struct kvm_vcpu *vcpu, struct kvm_run *run,
-			unsigned long cr2, int emulation_type);
+			unsigned long cr2, int emulation_type,
+			void *insn, int insn_len);
 
 static inline int emulate_instruction(struct kvm_vcpu *vcpu,
 			struct kvm_run *run, int emulation_type)
 {
-	return x86_emulate_instruction(vcpu, run, 0, emulation_type);
+	return x86_emulate_instruction(vcpu, run, 0, emulation_type, NULL, 0);
 }
 
 void kvm_report_emulation_failure(struct kvm_vcpu *cvpu, const char *context);
@@ -666,7 +667,8 @@ int kvm_emulate_hypercall(struct kvm_vcp
 
 int kvm_fix_hypercall(struct kvm_vcpu *vcpu);
 
-int kvm_mmu_page_fault(struct kvm_vcpu *vcpu, gva_t gva, u32 error_code);
+int kvm_mmu_page_fault(struct kvm_vcpu *vcpu, gva_t gva, u32 error_code,
+		       void *insn, int insn_len);
 void kvm_mmu_invlpg(struct kvm_vcpu *vcpu, gva_t gva);
 
 void kvm_enable_tdp(void);
Index: b/arch/x86/include/asm/svm.h
===================================================================
--- a/arch/x86/include/asm/svm.h
+++ b/arch/x86/include/asm/svm.h
@@ -83,7 +83,9 @@ struct __attribute__ ((__packed__)) vmcb
 	u64 lbr_ctl;
 	u64 reserved_5;
 	u64 next_rip;
-	u8 reserved_6[816];
+	u8 insn_len;
+	u8 insn_bytes[15];
+	u8 reserved_6[800];
 };
 
 
Index: b/arch/x86/kvm/emulate.c
===================================================================
--- a/arch/x86/kvm/emulate.c
+++ b/arch/x86/kvm/emulate.c
@@ -886,7 +886,8 @@ done:
 }
 
 int
-x86_decode_insn(struct x86_emulate_ctxt *ctxt, struct x86_emulate_ops *ops)
+x86_decode_insn(struct x86_emulate_ctxt *ctxt, struct x86_emulate_ops *ops,
+		void *insn, int insn_len)
 {
 	struct decode_cache *c = &ctxt->decode;
 	int rc = 0;
@@ -900,6 +901,12 @@ x86_decode_insn(struct x86_emulate_ctxt
 	ctxt->cs_base = seg_base(ctxt, VCPU_SREG_CS);
 	memcpy(c->regs, ctxt->vcpu->arch.regs, sizeof c->regs);
 
+	if (insn_len > 0) {
+		c->fetch.start = c->eip;
+		c->fetch.end = c->fetch.start + insn_len;
+		memcpy(c->fetch.data, insn, insn_len);
+	}
+
 	switch (mode) {
 	case X86EMUL_MODE_REAL:
 	case X86EMUL_MODE_VM86:
Index: b/arch/x86/kvm/mmu.c
===================================================================
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -2818,7 +2818,8 @@ void __kvm_mmu_free_some_pages(struct kv
 	}
 }
 
-int kvm_mmu_page_fault(struct kvm_vcpu *vcpu, gva_t cr2, u32 error_code)
+int kvm_mmu_page_fault(struct kvm_vcpu *vcpu, gva_t cr2, u32 error_code,
+		       void *insn, int insn_len)
 {
 	int r;
 	enum emulation_result er;
@@ -2836,7 +2837,7 @@ int kvm_mmu_page_fault(struct kvm_vcpu *
 	if (r)
 		goto out;
 
-	er = x86_emulate_instruction(vcpu, vcpu->run, cr2, 0);
+	er = x86_emulate_instruction(vcpu, vcpu->run, cr2, 0, insn, insn_len);
 
 	switch (er) {
 	case EMULATE_DONE:
Index: b/arch/x86/kvm/svm.c
===================================================================
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@ -1258,7 +1258,9 @@ static int pf_interception(struct vcpu_s
 	trace_kvm_page_fault(fault_address, error_code);
 	if (!npt_enabled && kvm_event_needs_reinjection(&svm->vcpu))
 		kvm_mmu_unprotect_page_virt(&svm->vcpu, fault_address);
-	return kvm_mmu_page_fault(&svm->vcpu, fault_address, error_code);
+	return kvm_mmu_page_fault(&svm->vcpu, fault_address, error_code,
+				  svm->vmcb->control.insn_bytes,
+				  svm->vmcb->control.insn_len);
 }
 
 static int db_interception(struct vcpu_svm *svm, struct kvm_run *kvm_run)
Index: b/arch/x86/kvm/vmx.c
===================================================================
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@ -2895,7 +2895,7 @@ static int handle_exception(struct kvm_v
 
 		if (kvm_event_needs_reinjection(vcpu))
 			kvm_mmu_unprotect_page_virt(vcpu, cr2);
-		return kvm_mmu_page_fault(vcpu, cr2, error_code);
+		return kvm_mmu_page_fault(vcpu, cr2, error_code, NULL, 0);
 	}
 
 	if (vmx->rmode.vm86_active &&
@@ -3375,7 +3375,7 @@ static int handle_ept_violation(struct k
 
 	gpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS);
 	trace_kvm_page_fault(gpa, exit_qualification);
-	return kvm_mmu_page_fault(vcpu, gpa & PAGE_MASK, 0);
+	return kvm_mmu_page_fault(vcpu, gpa & PAGE_MASK, 0, NULL, 0);
 }
 
 static u64 ept_rsvd_mask(u64 spte, int level)
Index: b/arch/x86/kvm/x86.c
===================================================================
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -3283,7 +3283,9 @@ static void cache_all_regs(struct kvm_vc
 int x86_emulate_instruction(struct kvm_vcpu *vcpu,
 			struct kvm_run *run,
 			unsigned long cr2,
-			int emulation_type)
+			int emulation_type,
+			void *insn,
+			int insn_len)
 {
 	int r, shadow_mask;
 	struct decode_cache *c;
@@ -3314,7 +3316,8 @@ int x86_emulate_instruction(struct kvm_v
 			? X86EMUL_MODE_PROT64 :	cs_db
 			? X86EMUL_MODE_PROT32 : X86EMUL_MODE_PROT16;
 
-		r = x86_decode_insn(&vcpu->arch.emulate_ctxt, &emulate_ops);
+		r = x86_decode_insn(&vcpu->arch.emulate_ctxt, &emulate_ops,
+				    insn, insn_len);
 
 		/* Only allow emulation of specific instructions on #UD
 		 * (namely VMMCALL, sysenter, sysexit, syscall)*/
@@ -4358,7 +4361,7 @@ int kvm_arch_vcpu_ioctl_run(struct kvm_v
 		vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
 		r = x86_emulate_instruction(vcpu, kvm_run,
 					vcpu->arch.mmio_fault_cr2,
-					EMULTYPE_NO_DECODE);
+					EMULTYPE_NO_DECODE, NULL, 0);
 		srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
 		if (r == EMULATE_DO_MMIO) {
 			/*
