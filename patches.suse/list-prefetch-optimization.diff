From: Kurt Garloff <garloff@suse.de>
Subject: Do less prefetching on list walking depending on architecture
Patch-Mainline: 3.0
Git-commit: e66eed651fd18a961f11cda62f3b5286c8cc4f9f

Modern CPUs (supposedly everything that's able to run x86-64) have hardware
prefetching that's powerful enough to actually render the prefetch instruction
for the next list element in list walking code to cause more harm than good.
So we introduce a list_prefetch() macro that does a real prefetch or nothing
depending on the CPU.

In addition, prefetch(0) does cause significant harm on a number of CPUs,
as we cause a TLB miss. There, we're better off using a branch or conditional
move than risking the NULL prefetch. So, introduce a prefetch_list_nonnull()
macro for NULL terminated lists. The behavior of course is CPU dependent
again. It can do either of four things: Always prefetch, introduce a branch
to avoid NULL, introduce a cond move (or a branch by discretion of the compiler)
to avoid NULL, no prefetch if there's a risk for NULL.

This patch is heavily based on Andi Kleen's patch referenced at
http://lwn.net/Articles/404033/

The NULL ptr handling is inspired by Ingo Molnar's findings, though
we only do the NULL check for lists that really are NULL terminated.
Both apsects are put together in one patch. 

The control logic over what should be done depending on the CPU is put 
into a separate header file include/linux/prefetch_config.h; the current
logic there is simplistic -- no list prefetching on x86-64, do prefetching
on i386 (if the CPU supports it) and avoid NULL prefetching with a branch.
On all other arches, continue to do list prefetching, but avoid NULL
prefetching with a conditional move (if the compiler decides to emit 
such).
As we learn more about the specifics of various CPUs, I expect the logic
to evolve.

References:
http://lwn.net/Articles/443692/
http://lwn.net/Articles/404103/
http://lwn.net/Articles/444346/

Signed-off-by: Kurt Garloff <garloff@suse.de>

Index: linux-2.6.32-SLE11-SP2/include/linux/prefetch.h
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/include/linux/prefetch.h
+++ linux-2.6.32-SLE11-SP2/include/linux/prefetch.h
@@ -49,8 +49,35 @@
 #ifndef PREFETCH_STRIDE
 #define PREFETCH_STRIDE (4*L1_CACHE_BYTES)
 #endif
 
+/*
+ * Prefetch for list pointer chasing. The architecture defines this
+ * if it believes list prefetches are a good idea on the particular CPU.
+ */
+#include <linux/prefetch_config.h>
+#ifdef LIST_PREFETCH_NONE	/* No prefetching for lists */
+#define list_prefetch(x) ((void)0)
+#define list_prefetch_nonnull(x) ((void)0)
+#elif defined(LIST_PREFETCH)	/* Do prefetching of list elements */
+#define	list_prefetch(x) prefetch(x)
+#ifdef LIST_PREFETCH_UNCOND		/* Never mind about a NULL prefetch */
+#define	list_prefetch_nonnull(x) prefetch(x)
+#elif defined(LIST_PREFETCH_BRANCH)	/* Avoid NULL prefetch (TLB miss ...) */
+#define	list_prefetch_nonnull(x) if (likely(x)) prefetch(x)
+#elif defined(LIST_PREFETCH_CMOV)	/* Avoid NULL prefetch hoping compiler will use cond move instead of branch */
+#define	list_prefetch_nonnull(x) prefetch((void*)(x)?: (void*)&(x))
+#elif defined(LIST_PREFETCH_NEVERNULL)	/* NULL prefetch, branch or cond move are all too expensive */
+#define list_prefetch_nonnull(x) ((void)0)
+#else
+#error LIST_PREFETCH_UNCOND, _BRANCH, _CMOV, or _NEVERNULL needs to be defined
+#endif
+#else
+#warn LIST_PREFETCH_NONE or LIST_PREFETCH needs to be defined. Defaulting to unconditional prefetch.
+define list_prefetch(x) prefetch(x)
+define list_prefetch_nonnull(x) prefetch(x)
+#endif
+
 static inline void prefetch_range(void *addr, size_t len)
 {
 #ifdef ARCH_HAS_PREFETCH
 	char *cp;
Index: linux-2.6.32-SLE11-SP2/include/linux/prefetch_config.h
===================================================================
--- /dev/null
+++ linux-2.6.32-SLE11-SP2/include/linux/prefetch_config.h
@@ -0,0 +1,37 @@
+/** linux/prefetch_config.h
+ * used by linux/prefetch.h
+ *
+ * The list of rules that determines whether list_prefetch should do
+ * prefetching at all LIST_PREFETCH_NONE vs. LIST_PREFETCH.
+ * This defermines the behavior of list_prefetch(x).
+ *
+ * If it does prefetching (LIST_PREFETCH defined), is can also decide
+ * whether null pointers should be tested for and treated special with
+ * list_prefetch_nonnull(x):
+ * Always prefetch unconditionally (LIST_PREFETCH_UNCOND)
+ * prefetching only nonnull ptr with a branch (LIST_PREFETCH_BRANCH)
+ * prefetching only nonnull ptr with a cond move (LIST_PREFETCH_CMOV)
+ * if there's a risk for NULL ptr, don't prefetch (LIST_PREFETCH_NEVERNULL)
+ */
+
+#ifndef _LINUX_PREFETCH_CONFIG_H
+#define _LINUX_PREFETCH_CONFIG_H
+
+//#include <linux/autoconf.h>
+
+/* The rules here can become rather complex and be optimized for CPU types
+ * testing the CONFIG_Mxxx symboles.
+ */
+
+#ifdef __i386__
+# define LIST_PREFETCH
+# define LIST_PREFETCH_BRANCH
+#elif defined(__x86_64__)
+# define LIST_PREFETCH_NONE
+//#define LIST_PREFETCH_BRANCH
+#else
+# define LIST_PREFETCH
+# define LIST_PREFETCH_CMOV
+#endif
+
+#endif
Index: linux-2.6.32-SLE11-SP2/fs/dcache.c
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/fs/dcache.c
+++ linux-2.6.32-SLE11-SP2/fs/dcache.c
@@ -355,9 +355,9 @@ static struct dentry * __d_find_alias(st
 	next = inode->i_dentry.next;
 	while (next != head) {
 		tmp = next;
 		next = tmp->next;
-		prefetch(next);
+		list_prefetch(next);
 		alias = list_entry(tmp, struct dentry, d_alias);
  		if (S_ISDIR(inode->i_mode) || !d_unhashed(alias)) {
 			if (IS_ROOT(alias) &&
 			    (alias->d_flags & DCACHE_DISCONNECTED))
Index: linux-2.6.32-SLE11-SP2/include/linux/list.h
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/include/linux/list.h
+++ linux-2.6.32-SLE11-SP2/include/linux/list.h
@@ -2,10 +2,10 @@
 #define _LINUX_LIST_H
 
 #include <linux/stddef.h>
 #include <linux/poison.h>
-#include <linux/prefetch.h>
 #include <asm/system.h>
+#include <linux/prefetch.h>
 
 /*
  * Simple doubly linked list implementation.
  *
@@ -364,9 +364,9 @@ static inline void list_splice_tail_init
  * @pos:	the &struct list_head to use as a loop cursor.
  * @head:	the head for your list.
  */
 #define list_for_each(pos, head) \
-	for (pos = (head)->next; prefetch(pos->next), pos != (head); \
+	for (pos = (head)->next; list_prefetch(pos->next), pos != (head); \
         	pos = pos->next)
 
 /**
  * __list_for_each	-	iterate over a list
@@ -386,9 +386,9 @@ static inline void list_splice_tail_init
  * @pos:	the &struct list_head to use as a loop cursor.
  * @head:	the head for your list.
  */
 #define list_for_each_prev(pos, head) \
-	for (pos = (head)->prev; prefetch(pos->prev), pos != (head); \
+	for (pos = (head)->prev; list_prefetch(pos->prev), pos != (head); \
         	pos = pos->prev)
 
 /**
  * list_for_each_safe - iterate over a list safe against removal of list entry
@@ -407,9 +407,9 @@ static inline void list_splice_tail_init
  * @head:	the head for your list.
  */
 #define list_for_each_prev_safe(pos, n, head) \
 	for (pos = (head)->prev, n = pos->prev; \
-	     prefetch(pos->prev), pos != (head); \
+	     list_prefetch(pos->prev), pos != (head); \
 	     pos = n, n = pos->prev)
 
 /**
  * list_for_each_entry	-	iterate over list of given type
@@ -418,9 +418,9 @@ static inline void list_splice_tail_init
  * @member:	the name of the list_struct within the struct.
  */
 #define list_for_each_entry(pos, head, member)				\
 	for (pos = list_entry((head)->next, typeof(*pos), member);	\
-	     prefetch(pos->member.next), &pos->member != (head); 	\
+	     list_prefetch(pos->member.next), &pos->member != (head); 	\
 	     pos = list_entry(pos->member.next, typeof(*pos), member))
 
 /**
  * list_for_each_entry_reverse - iterate backwards over list of given type.
@@ -429,9 +429,9 @@ static inline void list_splice_tail_init
  * @member:	the name of the list_struct within the struct.
  */
 #define list_for_each_entry_reverse(pos, head, member)			\
 	for (pos = list_entry((head)->prev, typeof(*pos), member);	\
-	     prefetch(pos->member.prev), &pos->member != (head); 	\
+	     list_prefetch(pos->member.prev), &pos->member != (head); 	\
 	     pos = list_entry(pos->member.prev, typeof(*pos), member))
 
 /**
  * list_prepare_entry - prepare a pos entry for use in list_for_each_entry_continue()
@@ -454,9 +454,9 @@ static inline void list_splice_tail_init
  * the current position.
  */
 #define list_for_each_entry_continue(pos, head, member) 		\
 	for (pos = list_entry(pos->member.next, typeof(*pos), member);	\
-	     prefetch(pos->member.next), &pos->member != (head);	\
+	     list_prefetch(pos->member.next), &pos->member != (head);	\
 	     pos = list_entry(pos->member.next, typeof(*pos), member))
 
 /**
  * list_for_each_entry_continue_reverse - iterate backwards from the given point
@@ -468,9 +468,9 @@ static inline void list_splice_tail_init
  * the current position.
  */
 #define list_for_each_entry_continue_reverse(pos, head, member)		\
 	for (pos = list_entry(pos->member.prev, typeof(*pos), member);	\
-	     prefetch(pos->member.prev), &pos->member != (head);	\
+	     list_prefetch(pos->member.prev), &pos->member != (head);	\
 	     pos = list_entry(pos->member.prev, typeof(*pos), member))
 
 /**
  * list_for_each_entry_from - iterate over list of given type from the current point
@@ -480,9 +480,9 @@ static inline void list_splice_tail_init
  *
  * Iterate over list of given type, continuing from current position.
  */
 #define list_for_each_entry_from(pos, head, member) 			\
-	for (; prefetch(pos->member.next), &pos->member != (head);	\
+	for (; list_prefetch(pos->member.next), &pos->member != (head);	\
 	     pos = list_entry(pos->member.next, typeof(*pos), member))
 
 /**
  * list_for_each_entry_safe - iterate over list of given type safe against removal of list entry
@@ -648,9 +648,9 @@ static inline void hlist_move_list(struc
 
 #define hlist_entry(ptr, type, member) container_of(ptr,type,member)
 
 #define hlist_for_each(pos, head) \
-	for (pos = (head)->first; pos && ({ prefetch(pos->next); 1; }); \
+	for (pos = (head)->first; pos && ({ list_prefetch_nonnull(pos->next); 1; }); \
 	     pos = pos->next)
 
 #define hlist_for_each_safe(pos, n, head) \
 	for (pos = (head)->first; pos && ({ n = pos->next; 1; }); \
@@ -664,9 +664,9 @@ static inline void hlist_move_list(struc
  * @member:	the name of the hlist_node within the struct.
  */
 #define hlist_for_each_entry(tpos, pos, head, member)			 \
 	for (pos = (head)->first;					 \
-	     pos && ({ prefetch(pos->next); 1;}) &&			 \
+	     pos && ({ list_prefetch_nonnull(pos->next); 1;}) &&	 \
 		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); \
 	     pos = pos->next)
 
 /**
@@ -676,9 +676,9 @@ static inline void hlist_move_list(struc
  * @member:	the name of the hlist_node within the struct.
  */
 #define hlist_for_each_entry_continue(tpos, pos, member)		 \
 	for (pos = (pos)->next;						 \
-	     pos && ({ prefetch(pos->next); 1;}) &&			 \
+	     pos && ({ list_prefetch_nonnull(pos->next); 1;}) &&	 \
 		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); \
 	     pos = pos->next)
 
 /**
@@ -687,9 +687,9 @@ static inline void hlist_move_list(struc
  * @pos:	the &struct hlist_node to use as a loop cursor.
  * @member:	the name of the hlist_node within the struct.
  */
 #define hlist_for_each_entry_from(tpos, pos, member)			 \
-	for (; pos && ({ prefetch(pos->next); 1;}) &&			 \
+	for (; pos && ({ list_prefetch_nonnull(pos->next); 1;}) &&	 \
 		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); \
 	     pos = pos->next)
 
 /**
Index: linux-2.6.32-SLE11-SP2/include/linux/rculist.h
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/include/linux/rculist.h
+++ linux-2.6.32-SLE11-SP2/include/linux/rculist.h
@@ -240,9 +240,9 @@ static inline void list_splice_init_rcu(
  * as long as the traversal is guarded by rcu_read_lock().
  */
 #define list_for_each_entry_rcu(pos, head, member) \
 	for (pos = list_entry_rcu((head)->next, typeof(*pos), member); \
-		prefetch(pos->member.next), &pos->member != (head); \
+		list_prefetch(pos->member.next), &pos->member != (head); \
 		pos = list_entry_rcu(pos->member.next, typeof(*pos), member))
 
 
 /**
@@ -257,9 +257,9 @@ static inline void list_splice_init_rcu(
  * as long as the traversal is guarded by rcu_read_lock().
  */
 #define list_for_each_continue_rcu(pos, head) \
 	for ((pos) = rcu_dereference((pos)->next); \
-		prefetch((pos)->next), (pos) != (head); \
+		list_prefetch((pos)->next), (pos) != (head); \
 		(pos) = rcu_dereference((pos)->next))
 
 /**
  * hlist_del_rcu - deletes entry from hash list without re-initialization
@@ -404,9 +404,9 @@ static inline void hlist_add_after_rcu(s
  * as long as the traversal is guarded by rcu_read_lock().
  */
 #define hlist_for_each_entry_rcu(tpos, pos, head, member)		 \
 	for (pos = rcu_dereference((head)->first);			 \
-		pos && ({ prefetch(pos->next); 1; }) &&			 \
+		pos && ({ list_prefetch_nonnull(pos->next); 1; }) &&	 \
 		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1; }); \
 		pos = rcu_dereference(pos->next))
 
 #endif	/* __KERNEL__ */
Index: linux-2.6.32-SLE11-SP2/include/linux/skbuff.h
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/include/linux/skbuff.h
+++ linux-2.6.32-SLE11-SP2/include/linux/skbuff.h
@@ -1721,18 +1721,18 @@ static inline int pskb_trim_rcsum(struct
 }
 
 #define skb_queue_walk(queue, skb) \
 		for (skb = (queue)->next;					\
-		     prefetch(skb->next), (skb != (struct sk_buff *)(queue));	\
+		     list_prefetch(skb->next), (skb != (struct sk_buff *)(queue));	\
 		     skb = skb->next)
 
 #define skb_queue_walk_safe(queue, skb, tmp)					\
 		for (skb = (queue)->next, tmp = skb->next;			\
 		     skb != (struct sk_buff *)(queue);				\
 		     skb = tmp, tmp = skb->next)
 
 #define skb_queue_walk_from(queue, skb)						\
-		for (; prefetch(skb->next), (skb != (struct sk_buff *)(queue));	\
+		for (; list_prefetch(skb->next), (skb != (struct sk_buff *)(queue));	\
 		     skb = skb->next)
 
 #define skb_queue_walk_from_safe(queue, skb, tmp)				\
 		for (tmp = skb->next;						\
@@ -1740,9 +1740,9 @@ static inline int pskb_trim_rcsum(struct
 		     skb = tmp, tmp = skb->next)
 
 #define skb_queue_reverse_walk(queue, skb) \
 		for (skb = (queue)->prev;					\
-		     prefetch(skb->prev), (skb != (struct sk_buff *)(queue));	\
+		     list_prefetch(skb->prev), (skb != (struct sk_buff *)(queue));	\
 		     skb = skb->prev)
 
 
 static inline bool skb_has_frags(const struct sk_buff *skb)
Index: linux-2.6.32-SLE11-SP2/net/netlabel/netlabel_addrlist.h
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/net/netlabel/netlabel_addrlist.h
+++ linux-2.6.32-SLE11-SP2/net/netlabel/netlabel_addrlist.h
@@ -95,14 +95,14 @@ static inline struct netlbl_af4list *__a
 }
 
 #define netlbl_af4list_foreach(iter, head)				\
 	for (iter = __af4list_valid((head)->next, head);		\
-	     prefetch(iter->list.next), &iter->list != (head);		\
+	     list_prefetch(iter->list.next), &iter->list != (head);	\
 	     iter = __af4list_valid(iter->list.next, head))
 
 #define netlbl_af4list_foreach_rcu(iter, head)				\
 	for (iter = __af4list_valid_rcu((head)->next, head);		\
-	     prefetch(iter->list.next),	&iter->list != (head);		\
+	     list_prefetch(iter->list.next),	&iter->list != (head);	\
 	     iter = __af4list_valid_rcu(iter->list.next, head))
 
 #define netlbl_af4list_foreach_safe(iter, tmp, head)			\
 	for (iter = __af4list_valid((head)->next, head),		\
@@ -163,14 +163,14 @@ static inline struct netlbl_af6list *__a
 }
 
 #define netlbl_af6list_foreach(iter, head)				\
 	for (iter = __af6list_valid((head)->next, head);		\
-	     prefetch(iter->list.next),	&iter->list != (head);		\
+	     list_prefetch(iter->list.next),	&iter->list != (head);	\
 	     iter = __af6list_valid(iter->list.next, head))
 
 #define netlbl_af6list_foreach_rcu(iter, head)				\
 	for (iter = __af6list_valid_rcu((head)->next, head);		\
-	     prefetch(iter->list.next),	&iter->list != (head);		\
+	     list_prefetch(iter->list.next),	&iter->list != (head);	\
 	     iter = __af6list_valid_rcu(iter->list.next, head))
 
 #define netlbl_af6list_foreach_safe(iter, tmp, head)			\
 	for (iter = __af6list_valid((head)->next, head),		\
Index: linux-2.6.32-SLE11-SP2/tools/perf/util/include/linux/prefetch.h
===================================================================
--- linux-2.6.32-SLE11-SP2.orig/tools/perf/util/include/linux/prefetch.h
+++ linux-2.6.32-SLE11-SP2/tools/perf/util/include/linux/prefetch.h
@@ -1,6 +1,6 @@
 #ifndef PERF_LINUX_PREFETCH_H
 #define PERF_LINUX_PREFETCH_H
 
-static inline void prefetch(void *a __attribute__((unused))) { }
+static inline void list_prefetch(void *a __attribute__((unused))) { }
 
 #endif
