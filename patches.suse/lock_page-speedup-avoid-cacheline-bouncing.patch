From: Jack Steiner <steiner@sgi.com>
Subject: UV - PERF cacheline contention in __lock_page reclaiming pages from pagecache
Patch-mainline: No. Depends on __lock_page version in SLES.
References: bnc#629170

The following patch addresses a scaling problem seen on large
systems (>1000p). Applications such as:

	- booting when a lot of udevd threads are spawned
	- MPT programs that fork a large number of processes
	- AIM7

tend to fork a large number of tasks where each task faults
the same set of pages from the pagecache.

Reclaiming of the pages from the page cache causes severe cacheline
bouncing of the page struct in __lock_pages(). Dropping into kdb shows
many tasks with an identical backtrace (same for udevd, etc):

 0xffff881ff03d0680   190645   190018  1   15   R  0xffff881ff03d0d10  multitask
	[<ffffffff813963f5>] _spin_unlock_irqrestore+0x5/0x10
	[<ffffffff810b37d4>] __lock_page+0x70/0xb0
	[<ffffffff810b4358>] filemap_fault+0x258/0x400
	[<ffffffff810cccb7>] __do_fault+0x57/0x540
	[<ffffffff810d128f>] handle_mm_fault+0x1cf/0x980
	[<ffffffff81398deb>] do_page_fault+0x1cb/0x400
	[<ffffffff8139677f>] page_fault+0x1f/0x30
	[<00007f56b05f9af0>] 0x7f56b05f9af0


The problem is caused by "struct page" cacheline bouncing in the following code:

	void __lock_page(struct page *page)
	{
		wait_queue_head_t *wq = page_waitqueue(page);
		DEFINE_WAIT_BIT(wait, &page->flags, PG_locked);

		do {
			prepare_to_wait(wq, &wait.wait, TASK_UNINTERRUPTIBLE);
>>>			SetPageWaiters(page);
>>>			if (likely(PageLocked(page)))
				sync_page(page);
>>>		} while (!trylock_page(page));
		finish_wait(wq, &wait.wait);
	}

If the page is alredy in the pagecache, this loop is a busy-wait but modifies
the page struct each iteration.  Statistics added to the above code show
that during aim7 startup, there are an average of 7 iterations thru the loop
for each call to __lock_page().
for

The following patch reduces unnecessary updates to the struct page & significantly
improves performance on large sysyems. It should have little affect on small systems.
Statistics now show 1.5 iterations of the loop for each call to __lock_page().

(If you have ideas for additional improvements, please let me know. I'll be
glad to test them). 


Also note: the version of __lock_pages() in SLES11SP1 is NOT in the community. SuSE
has already improved __lock_pages() but that code is not yet upstream. See the
following patch in SLEssSP1:

	in patches.suse/unlock_page-speedup.patch

	From: Nick Piggin <npiggin@suse.de>
	Subject: mm: unlock_page speedup
	References: bnc#436953
	Patch-upstream: no (could be submitted)

	Introduce a new page flag, PG_waiters, to signal there are processes waiting on
	PG_lock; and use it to avoid memory barriers and waitqueue hash lookup in the
	unlock_page fastpath.


AIM7 results (note - we use the original AIM7. Run on RAMdisks using XFS)
BASELINE
Linux version 2.6.32.13-0.4.1.1559.0.PTF-default SMP 2010-06-15 12:47:25 +0200
AIM Multiuser Benchmark - Suite VII v1.1, January 22, 1996
Copyright (C) 1996 AIM Technology

Tasks	Jobs/Min	JTI	Real	CPU	Jobs/sec/task
1	388.8		100	15.0	4.6	6.4796
2	847.2		99	13.7	6.6	7.0597
3	1339.0		99	13.0	7.9	7.4387
4	1721.9		99	13.5	12.1	7.1746
5	1905.7		92	15.3	17.9	6.3523
10	4016.6		95	14.5	29.8	6.6943
20	7519.4		95	15.5	76.5	6.2661
50	8439.7		68	34.5	486.5	2.8132
100	11213.9		69	51.9	1397.6	1.8690
150	9972.6		69	87.5	2855.5	1.1081
200	12023.6		76	96.8	4509.4	1.0020
500	5668.4		84	513.4	111764.2 0.1889
1000	3229.9		91	1801.9	854778.5 0.0538
2000   ....timed out

NEW
Linux version 2.6.32.13-jfs-uv (geeko@buildhost)
AIM Multiuser Benchmark - Suite VII v1.1, January 22, 1996
Copyright (C) 1996 AIM Technology
All Rights Reserved

Tasks	Jobs/Min	JTI	Real	CPU	Jobs/sec/task
1	464.1		100	12.5	2.2	7.7352
2	962.0		99	12.1	3.2	8.0165
3	1469.7		99	11.9	4.3	8.1650
4	1943.2		99	12.0	6.0	8.0968
5	2356.3		98	12.3	8.4	7.8543
10	4369.4		97	13.3	19.8	7.2823
20	7780.7		95	15.0	33.3	6.4840
50	10927.5		90	26.6	100.2	3.6425
100	13233.3		87	44.0	180.6	2.2055
150	12327.0		89	70.8	341.0	1.3697
200	11509.9		87	101.1	411.2	0.9592
500	12594.7		87	231.1	1461.9	0.4198
1000	10794.2		90	539.2	8582.4	0.1799

2000	11124.0		87	1046.4	35512.4	0.0927
4000	12541.0		82	1856.3	424265.4 0.0523


Signed-off-by: Nikanth Karthikesan <knikanth@suse.de>

---
 mm/filemap.c |    5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)


Index: linux-2.6.32-SLE11-SP1/mm/filemap.c
===================================================================
--- linux-2.6.32-SLE11-SP1.orig/mm/filemap.c
+++ linux-2.6.32-SLE11-SP1/mm/filemap.c
@@ -678,9 +678,12 @@ void __lock_page(struct page *page)
 
 	do {
 		prepare_to_wait(wq, &wait.wait, TASK_UNINTERRUPTIBLE);
-		SetPageWaiters(page);
+		if (!PageWaiters(page))
+			SetPageWaiters(page);
 		if (likely(PageLocked(page)))
 			sync_page(page);
+		while(PageLocked(page))
+			cpu_relax();
 	} while (!trylock_page(page));
 	finish_wait(wq, &wait.wait);
 }
