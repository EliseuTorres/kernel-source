From 3dce55f3752dece7770b3544575a0f8968e3e972 Mon Sep 17 00:00:00 2001
From: Davidlohr Bueso <davidlohr@hp.com>
Date: Thu, 17 Apr 2014 12:23:48 -0700
Subject: [PATCH] mm: enable per-thread vma caching
Git-commit: 615d6e8756c87149f2d4c1b93d471bca002bd849
Patch-mainline: v3.15-rc1
References: FATE#318083

This patch enables per-thread vma caching by removing
the CONFIG_VMA_CACHE feature guard for SLE11-SP4.

Signed-off-by: Davidlohr Bueso <dbueso@suse.de>

---
 fs/exec.c                 |    2 --
 include/linux/mm_types.h  |    4 ----
 include/linux/sched.h     |    2 --
 include/linux/vmacache.h  |    4 ----
 kernel/debug/debug_core.c |    7 -------
 kernel/fork.c             |    6 ------
 mm/Kconfig                |    4 ----
 mm/Makefile               |    3 +--
 mm/mmap.c                 |   41 -----------------------------------------
 mm/nommu.c                |   27 ---------------------------
 10 files changed, 1 insertion(+), 99 deletions(-)

--- a/fs/exec.c
+++ b/fs/exec.c
@@ -861,10 +861,8 @@ static int exec_mmap(struct mm_struct *m
 	tsk->mm = mm;
 	tsk->active_mm = mm;
 	activate_mm(active_mm, mm);
-#ifdef CONFIG_VMA_CACHE
 	tsk->mm->vmacache_seqnum = 0;
 	vmacache_flush(tsk);
-#endif
 	if (old_mm && tsk->signal->oom_score_adj == OOM_SCORE_ADJ_MIN) {
 		atomic_dec(&old_mm->oom_disable_count);
 		atomic_inc(&tsk->mm->oom_disable_count);
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -255,11 +255,7 @@ struct mm_rss_stat {
 struct mm_struct {
 	struct vm_area_struct *mmap;		/* list of VMAs */
 	struct rb_root mm_rb;
-#ifdef CONFIG_VMA_CACHE
 	u32 vmacache_seqnum; /* per-thread vmacache */
-#else
-	struct vm_area_struct *mmap_cache;     /* last find_vma result */
-#endif
 #ifdef CONFIG_MMU
 	unsigned long (*get_unmapped_area) (struct file *filp,
 				unsigned long addr, unsigned long len,
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1312,11 +1312,9 @@ struct task_struct {
 #ifdef CONFIG_COMPAT_BRK
 	unsigned brk_randomized:1;
 #endif
-#ifdef CONFIG_VMA_CACHE
 	/* per-thread vma caching */
 	u32 vmacache_seqnum;
 	struct vm_area_struct *vmacache[VMACACHE_SIZE];
-#endif
 #if defined(SPLIT_RSS_COUNTING)
 	struct task_rss_stat	rss_stat;
 #endif
--- a/include/linux/vmacache.h
+++ b/include/linux/vmacache.h
@@ -1,8 +1,6 @@
 #ifndef __LINUX_VMACACHE_H
 #define __LINUX_VMACACHE_H
 
-#ifdef CONFIG_VMA_CACHE
-
 #include <linux/sched.h>
 #include <linux/mm.h>
 
@@ -37,6 +35,4 @@ static inline void vmacache_invalidate(s
 		vmacache_flush_all(mm);
 }
 
-#endif /* CONFIG_VMA_CACHE */
-
 #endif /* __LINUX_VMACACHE_H */
--- a/kernel/debug/debug_core.c
+++ b/kernel/debug/debug_core.c
@@ -221,7 +221,6 @@ static void kgdb_flush_swbreak_addr(unsi
 	if (!CACHE_FLUSH_IS_SAFE)
 		return;
 
-#ifdef CONFIG_VMA_CACHE
 	if (current->mm) {
 		int i;
 
@@ -232,12 +231,6 @@ static void kgdb_flush_swbreak_addr(unsi
 					  addr, addr + BREAK_INSTR_SIZE);
 		}
 	}
-#else
-	if (current->mm && current->mm->mmap_cache) {
-		flush_cache_range(current->mm->mmap_cache,
-				  addr, addr + BREAK_INSTR_SIZE);
-	}
-#endif
 
 	/* Force flush instruction cache if it was outside the mm */
 	flush_icache_range(addr, addr + BREAK_INSTR_SIZE);
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -332,11 +332,7 @@ static int dup_mmap(struct mm_struct *mm
 
 	mm->locked_vm = 0;
 	mm->mmap = NULL;
-#ifdef CONFIG_VMA_CACHE
 	mm->vmacache_seqnum = 0;
-#else
-	mm->mmap_cache = NULL;
-#endif
 	mm->free_area_cache = oldmm->mmap_base;
 	mm->cached_hole_size = ~0UL;
 	mm->map_count = 0;
@@ -826,10 +822,8 @@ static int copy_mm(unsigned long clone_f
 	if (!oldmm)
 		return 0;
 
-#ifdef CONFIG_VMA_CACHE
 	/* initialize the new vmacache entries */
 	vmacache_flush(tsk);
-#endif
 
 	if (clone_flags & CLONE_VM) {
 		atomic_inc(&oldmm->mm_users);
--- a/mm/Kconfig
+++ b/mm/Kconfig
@@ -370,10 +370,6 @@ config NEED_PER_CPU_KM
 	bool
 	default y
 
-config VMA_CACHE
-	bool "Enable per-thread caching of VMAs"
-	default n
-
 config CLEANCACHE
 	bool "Enable cleancache driver to cache clean pages if tmem is present"
 	default n
--- a/mm/Makefile
+++ b/mm/Makefile
@@ -13,8 +13,7 @@ obj-y			:= filemap.o mempool.o oom_kill.
 			   readahead.o swap.o truncate.o vmscan.o shmem.o \
 			   prio_tree.o util.o mmzone.o vmstat.o backing-dev.o \
 			   page_isolation.o mm_init.o mmu_context.o percpu.o \
-			   $(mmu-y)
-obj-$(CONFIG_VMA_CACHE)	+= vmacache.o
+			   vmacache.o $(mmu-y)
 obj-y += init-mm.o
 
 ifdef CONFIG_NO_BOOTMEM
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -528,13 +528,8 @@ __vma_unlink(struct mm_struct *mm, struc
 	if (next)
 		next->vm_prev = prev;
 	rb_erase(&vma->vm_rb, &mm->mm_rb);
-#ifndef CONFIG_VMA_CACHE
-	if (mm->mmap_cache == vma)
-		mm->mmap_cache = prev;
-#else
 	/* Kill the cache */
 	vmacache_invalidate(mm);
-#endif
 }
 
 /*
@@ -1638,40 +1633,10 @@ EXPORT_SYMBOL(get_unmapped_area);
 /* Look up the first VMA which satisfies  addr < vm_end,  NULL if none. */
 struct vm_area_struct *find_vma(struct mm_struct *mm, unsigned long addr)
 {
-#ifdef CONFIG_VMA_CACHE
 	struct rb_node *rb_node;
-#endif
 	struct vm_area_struct *vma = NULL;
 
 	if (mm) {
-#ifndef CONFIG_VMA_CACHE
-		/* Check the cache first. */
-		/* (Cache hit rate is typically around 35%.) */
-		vma = ACCESS_ONCE(mm->mmap_cache);
-		if (!(vma && vma->vm_end > addr && vma->vm_start <= addr)) {
-			struct rb_node * rb_node;
-
-			rb_node = mm->mm_rb.rb_node;
-			vma = NULL;
-
-			while (rb_node) {
-				struct vm_area_struct * vma_tmp;
-
-				vma_tmp = rb_entry(rb_node,
-						struct vm_area_struct, vm_rb);
-
-				if (vma_tmp->vm_end > addr) {
-					vma = vma_tmp;
-					if (vma_tmp->vm_start <= addr)
-						break;
-					rb_node = rb_node->rb_left;
-				} else
-					rb_node = rb_node->rb_right;
-			}
-			if (vma)
-				mm->mmap_cache = vma;
-		}
-#else
 		vma = vmacache_find(mm, addr);
 		if (likely(vma))
 			return vma;
@@ -1695,7 +1660,6 @@ struct vm_area_struct *find_vma(struct m
 
 		if (vma)
 			vmacache_update(addr, vma);
-#endif
 	}
 	return vma;
 }
@@ -2026,13 +1990,8 @@ detach_vmas_to_be_unmapped(struct mm_str
 	else
 		addr = vma ?  vma->vm_start : mm->mmap_base;
 	mm->unmap_area(mm, addr);
-#ifndef CONFIG_VMA_CACHE
-	mm->mmap_cache = NULL;		/* Kill the cache. */
-#else
-
 	/* Kill the cache */
 	vmacache_invalidate(mm);
-#endif
 }
 
 /*
--- a/mm/nommu.c
+++ b/mm/nommu.c
@@ -766,20 +766,14 @@ static void delete_vma_from_mm(struct vm
 {
 	struct address_space *mapping;
 	struct mm_struct *mm = vma->vm_mm;
-#ifdef CONFIG_VMA_CACHE
 	int i;
 	struct task_struct *curr = current;
-#endif
 
 	kenter("%p", vma);
 
 	protect_vma(vma, 0);
 
 	mm->map_count--;
-#ifndef CONFIG_VMA_CACHE
-	if (mm->mmap_cache == vma)
-		mm->mmap_cache = NULL;
-#else
 	for (i = 0; i < VMACACHE_SIZE; i++) {
 		/* if the vma is cached, invalidate the entire cache */
 		if (curr->vmacache[i] == vma) {
@@ -787,7 +781,6 @@ static void delete_vma_from_mm(struct vm
 			break;
 		}
 	}
-#endif
 
 	/* remove the VMA from the mapping */
 	if (vma->vm_file) {
@@ -838,15 +831,9 @@ struct vm_area_struct *find_vma(struct m
 	struct vm_area_struct *vma;
 
 	/* check the cache first */
-#ifndef CONFIG_VMA_CACHE
-	vma = ACCESS_ONCE(mm->mmap_cache);
-	if (vma && vma->vm_start <= addr && vma->vm_end > addr)
-		return vma;
-#else
 	vma = vmacache_find(mm, addr);
 	if (likely(vma))
 		return vma;
-#endif
 
 	/* trawl the list (there may be multiple mappings in which addr
 	 * resides) */
@@ -854,11 +841,7 @@ struct vm_area_struct *find_vma(struct m
 		if (vma->vm_start > addr)
 			return NULL;
 		if (vma->vm_end > addr) {
-#ifndef CONFIG_VMA_CACHE
-			mm->mmap_cache = vma;
-#else
 			macache_update(addr, vma);
-#endif
 			return vma;
 		}
 	}
@@ -897,15 +880,9 @@ static struct vm_area_struct *find_vma_e
 	unsigned long end = addr + len;
 
 	/* check the cache first */
-#ifndef CONFIG_VMA_CACHE
-	vma = mm->mmap_cache;
-	if (vma && vma->vm_start == addr && vma->vm_end == end)
-		return vma;
-#else
 	vma = vmacache_find_exact(mm, addr, end);
 	if (vma)
 		return vma;
-#endif
 
 	/* trawl the list (there may be multiple mappings in which addr
 	 * resides) */
@@ -915,11 +892,7 @@ static struct vm_area_struct *find_vma_e
 		if (vma->vm_start > addr)
 			return NULL;
 		if (vma->vm_end == end) {
-#ifndef CONFIG_VMA_CACHE
-			mm->mmap_cache = vma;
-#else
 			vmacache_update(addr, vma);
-#endif
 			return vma;
 		}
 	}
