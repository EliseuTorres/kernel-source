From 8081111586eaf340c2a7463d8de97167d3242239 Mon Sep 17 00:00:00 2001
From: Mel Gorman <mgorman@suse.de>
Date: Thu, 3 Apr 2014 16:25:07 +0100
Subject: [PATCH] mm: shmem: Avoid atomic operation during shmem_getpage_gfp

References: VM/FS Performance
Patch-mainline: v3.16
Git-commit: 07a427884348d38a6fd56fa4d78249c407196650

shmem_getpage_gfp uses an atomic operation to set the SwapBacked field
before it's even added to the LRU or visible. This is unnecessary as what
could it possible race against?  Use an unlocked variant.

Signed-off-by: Mel Gorman <mgorman@suse.de>
Acked-by: Johannes Weiner <hannes@cmpxchg.org>
---
 include/linux/page-flags.h | 1 +
 mm/shmem.c                 | 2 +-
 2 files changed, 2 insertions(+), 1 deletion(-)

diff --git a/include/linux/page-flags.h b/include/linux/page-flags.h
index 618da9f..912d727 100644
--- a/include/linux/page-flags.h
+++ b/include/linux/page-flags.h
@@ -224,6 +224,7 @@ PAGEFLAG(SavePinned, savepinned);			/* Xen */
 PAGEFLAG(SavePinned, savepinned);			/* Xen */
 PAGEFLAG(Reserved, reserved) __CLEARPAGEFLAG(Reserved, reserved)
 PAGEFLAG(SwapBacked, swapbacked) __CLEARPAGEFLAG(SwapBacked, swapbacked)
+	__SETPAGEFLAG(SwapBacked, swapbacked)
 
 __PAGEFLAG(SlobFree, slob_free)
 
diff --git a/mm/shmem.c b/mm/shmem.c
index 30f4b34..6cc7f0b 100644
--- a/mm/shmem.c
+++ b/mm/shmem.c
@@ -1214,7 +1214,7 @@ repeat:
 			goto decused;
 		}
 
-		SetPageSwapBacked(page);
+		__SetPageSwapBacked(page);
 		__set_page_locked(page);
 		error = mem_cgroup_cache_charge(page, current->mm,
 						gfp & GFP_RECLAIM_MASK);
