From: David Sterba <dsterba@suse.cz>
Date: Thu Dec  8 03:32:58 CET 2011
Patch-mainline: no
References: FATE#306586 bnc#734522
Subject: [PATCH] btrfs: use irqsave spinlocks everywhere

Workaround for rcu stall when timer interrupt fires but is not able to continue
for yet unknown reasons.
All _irq variants are changed to _irqsave.

Signed-off-by: David Sterba <dsterba@suse.cz>
---
 fs/btrfs/async-thread.c     |   45 +++++++++++++++++++++++++-------------------
 fs/btrfs/disk-io.c          |    6 +++--
 fs/btrfs/extent_io.c        |    5 ++--
 fs/btrfs/free-space-cache.c |    5 ++--
 4 files changed, 36 insertions(+), 25 deletions(-)

--- a/fs/btrfs/async-thread.c
+++ b/fs/btrfs/async-thread.c
@@ -225,8 +225,9 @@ static void put_worker(struct btrfs_work
 static int try_worker_shutdown(struct btrfs_worker_thread *worker)
 {
 	int freeit = 0;
+	unsigned long flags;
 
-	spin_lock_irq(&worker->lock);
+	spin_lock_irqsave(&worker->lock, flags);
 	spin_lock(&worker->workers->lock);
 	if (worker->workers->num_workers > 1 &&
 	    worker->idle &&
@@ -240,7 +241,7 @@ static int try_worker_shutdown(struct bt
 		worker->workers->num_workers--;
 	}
 	spin_unlock(&worker->workers->lock);
-	spin_unlock_irq(&worker->lock);
+	spin_unlock_irqrestore(&worker->lock, flags);
 
 	if (freeit)
 		put_worker(worker);
@@ -253,6 +254,7 @@ static struct btrfs_work *get_next_work(
 {
 	struct btrfs_work *work = NULL;
 	struct list_head *cur = NULL;
+	unsigned long flags;
 
 	if(!list_empty(prio_head))
 		cur = prio_head->next;
@@ -268,7 +270,7 @@ static struct btrfs_work *get_next_work(
 		goto out;
 
 refill:
-	spin_lock_irq(&worker->lock);
+	spin_lock_irqsave(&worker->lock, flags);
 	list_splice_tail_init(&worker->prio_pending, prio_head);
 	list_splice_tail_init(&worker->pending, head);
 
@@ -276,7 +278,7 @@ refill:
 		cur = prio_head->next;
 	else if (!list_empty(head))
 		cur = head->next;
-	spin_unlock_irq(&worker->lock);
+	spin_unlock_irqrestore(&worker->lock, flags);
 
 	if (!cur)
 		goto out_fail;
@@ -297,6 +299,7 @@ static int worker_loop(void *arg)
 	struct list_head head;
 	struct list_head prio_head;
 	struct btrfs_work *work;
+	unsigned long flags;
 
 	INIT_LIST_HEAD(&head);
 	INIT_LIST_HEAD(&prio_head);
@@ -328,15 +331,15 @@ again:
 
 		}
 
-		spin_lock_irq(&worker->lock);
+		spin_lock_irqsave(&worker->lock, flags);
 		check_idle_worker(worker);
 
 		if (freezing(current)) {
 			worker->working = 0;
-			spin_unlock_irq(&worker->lock);
+			spin_unlock_irqrestore(&worker->lock, flags);
 			refrigerator();
 		} else {
-			spin_unlock_irq(&worker->lock);
+			spin_unlock_irqrestore(&worker->lock, flags);
 			if (!kthread_should_stop()) {
 				cpu_relax();
 				/*
@@ -366,7 +369,7 @@ again:
 					break;
 
 				/* still no more work?, sleep for real */
-				spin_lock_irq(&worker->lock);
+				spin_lock_irqsave(&worker->lock, flags);
 				set_current_state(TASK_INTERRUPTIBLE);
 				if (!list_empty(&worker->pending) ||
 				    !list_empty(&worker->prio_pending)) {
@@ -380,7 +383,7 @@ again:
 				 * adds something new to the queue
 				 */
 				worker->working = 0;
-				spin_unlock_irq(&worker->lock);
+				spin_unlock_irqrestore(&worker->lock, flags);
 
 				if (!kthread_should_stop()) {
 					schedule_timeout(HZ * 120);
@@ -404,8 +407,9 @@ int btrfs_stop_workers(struct btrfs_work
 	struct list_head *cur;
 	struct btrfs_worker_thread *worker;
 	int can_stop;
+	unsigned long flags;
 
-	spin_lock_irq(&workers->lock);
+	spin_lock_irqsave(&workers->lock, flags);
 	list_splice_init(&workers->idle_list, &workers->worker_list);
 	while (!list_empty(&workers->worker_list)) {
 		cur = workers->worker_list.next;
@@ -420,13 +424,13 @@ int btrfs_stop_workers(struct btrfs_work
 			can_stop = 1;
 		} else
 			can_stop = 0;
-		spin_unlock_irq(&workers->lock);
+		spin_unlock_irqrestore(&workers->lock, flags);
 		if (can_stop)
 			kthread_stop(worker->task);
-		spin_lock_irq(&workers->lock);
+		spin_lock_irqsave(&workers->lock, flags);
 		put_worker(worker);
 	}
-	spin_unlock_irq(&workers->lock);
+	spin_unlock_irqrestore(&workers->lock, flags);
 	return 0;
 }
 
@@ -460,6 +464,7 @@ static int __btrfs_start_workers(struct
 {
 	struct btrfs_worker_thread *worker;
 	int ret = 0;
+	unsigned long flags;
 
 	worker = kzalloc(sizeof(*worker), GFP_NOFS);
 	if (!worker) {
@@ -483,27 +488,29 @@ static int __btrfs_start_workers(struct
 		kfree(worker);
 		goto fail;
 	}
-	spin_lock_irq(&workers->lock);
+	spin_lock_irqsave(&workers->lock, flags);
 	list_add_tail(&worker->worker_list, &workers->idle_list);
 	worker->idle = 1;
 	workers->num_workers++;
 	workers->num_workers_starting--;
 	WARN_ON(workers->num_workers_starting < 0);
-	spin_unlock_irq(&workers->lock);
+	spin_unlock_irqrestore(&workers->lock, flags);
 
 	return 0;
 fail:
-	spin_lock_irq(&workers->lock);
+	spin_lock_irqsave(&workers->lock, flags);
 	workers->num_workers_starting--;
-	spin_unlock_irq(&workers->lock);
+	spin_unlock_irqrestore(&workers->lock, flags);
 	return ret;
 }
 
 int btrfs_start_workers(struct btrfs_workers *workers)
 {
-	spin_lock_irq(&workers->lock);
+	unsigned long flags;
+
+	spin_lock_irqsave(&workers->lock, flags);
 	workers->num_workers_starting++;
-	spin_unlock_irq(&workers->lock);
+	spin_unlock_irqrestore(&workers->lock, flags);
 	return __btrfs_start_workers(workers);
 }
 
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -3458,12 +3458,14 @@ static int btrfs_destroy_marked_extents(
 
 			lock_page(page);
 			if (PageDirty(page)) {
+				unsigned long flags;
+
 				clear_page_dirty_for_io(page);
-				spin_lock_irq(&page->mapping->tree_lock);
+				spin_lock_irqsave(&page->mapping->tree_lock, flags);
 				radix_tree_tag_clear(&page->mapping->page_tree,
 							page_index(page),
 							PAGECACHE_TAG_DIRTY);
-				spin_unlock_irq(&page->mapping->tree_lock);
+				spin_unlock_irqrestore(&page->mapping->tree_lock, flags);
 			}
 
 			page->mapping->a_ops->invalidatepage(page, 0);
--- a/fs/btrfs/extent_io.c
+++ b/fs/btrfs/extent_io.c
@@ -3782,6 +3782,7 @@ int clear_extent_buffer_dirty(struct ext
 	unsigned long i;
 	unsigned long num_pages;
 	struct page *page;
+	unsigned long flags;
 
 	num_pages = num_extent_pages(eb->start, eb->len);
 
@@ -3798,13 +3799,13 @@ int clear_extent_buffer_dirty(struct ext
 			set_page_extent_head(page, eb->len);
 
 		clear_page_dirty_for_io(page);
-		spin_lock_irq(&page->mapping->tree_lock);
+		spin_lock_irqsave(&page->mapping->tree_lock, flags);
 		if (!PageDirty(page)) {
 			radix_tree_tag_clear(&page->mapping->page_tree,
 						page_index(page),
 						PAGECACHE_TAG_DIRTY);
 		}
-		spin_unlock_irq(&page->mapping->tree_lock);
+		spin_unlock_irqrestore(&page->mapping->tree_lock, flags);
 		ClearPageError(page);
 		unlock_page(page);
 	}
--- a/fs/btrfs/free-space-cache.c
+++ b/fs/btrfs/free-space-cache.c
@@ -2100,10 +2100,11 @@ u64 btrfs_find_space_for_alloc(struct bt
 {
 	struct btrfs_free_space_ctl *ctl = block_group->free_space_ctl;
 	struct btrfs_free_space *entry = NULL;
+	unsigned long flags;
 	u64 bytes_search = bytes + empty_size;
 	u64 ret = 0;
 
-	spin_lock_irq(&ctl->tree_lock);
+	spin_lock_irqsave(&ctl->tree_lock, flags);
 	entry = find_free_space(ctl, &offset, &bytes_search);
 	if (!entry)
 		goto out;
@@ -2124,7 +2125,7 @@ u64 btrfs_find_space_for_alloc(struct bt
 	}
 
 out:
-	spin_unlock_irq(&ctl->tree_lock);
+	spin_unlock_irqrestore(&ctl->tree_lock, flags);
 
 	return ret;
 }
