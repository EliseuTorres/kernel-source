Subject: sched: Add a lock break for PREEMPT=y
From: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date: Thu Dec 17 18:10:09 2009 +0100
Patch-mainline: commit baa8c1102f0cd86e69c1497d61d2ee177e663663
References:

Since load-balancing can hold rq->locks for quite a long while, allow
breaking out early when there is lock contention.

Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
LKML-Reference: <new-submission>
Signed-off-by: Ingo Molnar <mingo@elte.hu>
Acked-by: Mike Galbraith <mgalbraith@suse.de>

---
 kernel/sched_fair.c |    4 ++++
 1 file changed, 4 insertions(+)

Index: linux-2.6.32/kernel/sched_fair.c
===================================================================
--- linux-2.6.32.orig/kernel/sched_fair.c
+++ linux-2.6.32/kernel/sched_fair.c
@@ -2072,6 +2072,10 @@ static int move_tasks(struct rq *this_rq
 		 */
 		if (idle == CPU_NEWLY_IDLE && this_rq->nr_running)
 			break;
+
+		if (raw_spin_is_contended(&this_rq->lock) ||
+				raw_spin_is_contended(&busiest->lock))
+			break;
 #endif
 	} while (load_moved && max_load_move > total_load_moved);
 
