From: Eli Cohen <eli@dev.mellanox.co.il>
Date: Wed, 23 Oct 2013 09:53:18 +0300
Subject: mlx5: Fix cleanup flow when DMA mapping fails
Patch-mainline: v3.13-rc1
Git-commit: 952f5f6e807ba82e1b82fcfcf7f73db022342aa7
References: bnc#858727 FATE#315946

If DMA mapping fails, the driver cleared the object that holds the
previously DMA mapped pages. Fix this by allocating a new object for
the command that reports back to firmware that pages can't be
supplied.

Signed-off-by: Eli Cohen <eli@mellanox.com>
Signed-off-by: Roland Dreier <roland@purestorage.com>
Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
Acked-by: Benjamin Poirier <bpoirier@suse.de>
---
 drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c |   18 +++++++++++++-----
 1 file changed, 13 insertions(+), 5 deletions(-)
--- a/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c
@@ -181,6 +181,7 @@ static int give_pages(struct mlx5_core_d
 {
 	struct mlx5_manage_pages_inbox *in;
 	struct mlx5_manage_pages_outbox out;
+	struct mlx5_manage_pages_inbox *nin;
 	struct page *page;
 	int inlen;
 	u64 addr;
@@ -247,13 +248,20 @@ static int give_pages(struct mlx5_core_d
 
 out_alloc:
 	if (notify_fail) {
-		memset(in, 0, inlen);
+		nin = kzalloc(sizeof(*nin), GFP_KERNEL);
+		if (!nin) {
+			mlx5_core_warn(dev, "allocation failed\n");
+			goto unmap;
+		}
 		memset(&out, 0, sizeof(out));
-		in->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_MANAGE_PAGES);
-		in->hdr.opmod = cpu_to_be16(MLX5_PAGES_CANT_GIVE);
-		if (mlx5_cmd_exec(dev, in, sizeof(*in), &out, sizeof(out)))
-			mlx5_core_warn(dev, "\n");
+		nin->hdr.opcode = cpu_to_be16(MLX5_CMD_OP_MANAGE_PAGES);
+		nin->hdr.opmod = cpu_to_be16(MLX5_PAGES_CANT_GIVE);
+		if (mlx5_cmd_exec(dev, nin, sizeof(*nin), &out, sizeof(out)))
+			mlx5_core_warn(dev, "page notify failed\n");
+		kfree(nin);
 	}
+
+unmap:
 	for (i--; i >= 0; i--) {
 		addr = be64_to_cpu(in->pas[i]);
 		page = remove_page(dev, addr);
