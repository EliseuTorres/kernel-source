From: Alexander Duyck <alexander.h.duyck@intel.com>
Date: Tue, 27 Oct 2009 15:52:07 +0000
Subject: igb: move rx_buffer_len into the ring structure
References: FATE#311863 ,bnc#699089
Patch-mainline: v2.6.33-rc1
Git-commit: 4c844851d15cc08d995179ab5118172711be6eb0

This patch moves the rx_buffer_len value into the ring structure.  This allows
greater flexibility and the option of doing things such as supporting packet
split only on some queues, or enabling virtualization.

Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
Signed-off-by: David S. Miller <davem@davemloft.net>
Acked-by: David Chang <dchang@suse.com>
---
 drivers/net/igb/igb.h      |    3 +--
 drivers/net/igb/igb_main.c |   41 ++++++++++++++++++++++-------------------
 2 files changed, 23 insertions(+), 21 deletions(-)

--- a/drivers/net/igb/igb.h
+++ b/drivers/net/igb/igb.h
@@ -206,7 +206,7 @@ struct igb_ring {
 		/* RX */
 		struct {
 			struct igb_rx_queue_stats rx_stats;
-			u64 rx_queue_drops;
+			u32 rx_buffer_len;
 		};
 	};
 };
@@ -226,7 +226,6 @@ struct igb_adapter {
 	struct vlan_group *vlgrp;
 	u16 mng_vlan_id;
 	u32 bd_number;
-	u32 rx_buffer_len;
 	u32 wol;
 	u32 en_mng_pt;
 	u16 link_speed;
--- a/drivers/net/igb/igb_main.c
+++ b/drivers/net/igb/igb_main.c
@@ -406,6 +406,7 @@ static int igb_alloc_queues(struct igb_a
 		ring->count = adapter->rx_ring_count;
 		ring->queue_index = i;
 		ring->pdev = adapter->pdev;
+		ring->rx_buffer_len = MAXIMUM_ETHERNET_VLAN_SIZE;
 	}
 
 	igb_cache_ring_register(adapter);
@@ -1937,7 +1938,6 @@ static int __devinit igb_sw_init(struct
 
 	adapter->tx_ring_count = IGB_DEFAULT_TXD;
 	adapter->rx_ring_count = IGB_DEFAULT_RXD;
-	adapter->rx_buffer_len = MAXIMUM_ETHERNET_VLAN_SIZE;
 	adapter->max_frame_size = netdev->mtu + ETH_HLEN + ETH_FCS_LEN;
 	adapter->min_frame_size = ETH_ZLEN + ETH_FCS_LEN;
 
@@ -2478,8 +2478,8 @@ static void igb_configure_rx_ring(struct
 	writel(0, ring->tail);
 
 	/* set descriptor configuration */
-	if (adapter->rx_buffer_len < IGB_RXBUFFER_1024) {
-		srrctl = ALIGN(adapter->rx_buffer_len, 64) <<
+	if (ring->rx_buffer_len < IGB_RXBUFFER_1024) {
+		srrctl = ALIGN(ring->rx_buffer_len, 64) <<
 		         E1000_SRRCTL_BSIZEHDRSIZE_SHIFT;
 #if (PAGE_SIZE / 2) > IGB_RXBUFFER_16384
 		srrctl |= IGB_RXBUFFER_16384 >>
@@ -2490,7 +2490,7 @@ static void igb_configure_rx_ring(struct
 #endif
 		srrctl |= E1000_SRRCTL_DESCTYPE_HDR_SPLIT_ALWAYS;
 	} else {
-		srrctl = ALIGN(adapter->rx_buffer_len, 1024) >>
+		srrctl = ALIGN(ring->rx_buffer_len, 1024) >>
 		         E1000_SRRCTL_BSIZEPKT_SHIFT;
 		srrctl |= E1000_SRRCTL_DESCTYPE_ADV_ONEBUF;
 	}
@@ -2739,7 +2739,6 @@ static void igb_free_all_rx_resources(st
  **/
 static void igb_clean_rx_ring(struct igb_ring *rx_ring)
 {
-	struct igb_adapter *adapter = rx_ring->q_vector->adapter;
 	struct igb_buffer *buffer_info;
 	unsigned long size;
 	unsigned int i;
@@ -2752,7 +2751,7 @@ static void igb_clean_rx_ring(struct igb
 		if (buffer_info->dma) {
 			pci_unmap_single(rx_ring->pdev,
 			                 buffer_info->dma,
-					 adapter->rx_buffer_len,
+					 rx_ring->rx_buffer_len,
 					 PCI_DMA_FROMDEVICE);
 			buffer_info->dma = 0;
 		}
@@ -3860,6 +3859,7 @@ static int igb_change_mtu(struct net_dev
 {
 	struct igb_adapter *adapter = netdev_priv(netdev);
 	int max_frame = new_mtu + ETH_HLEN + ETH_FCS_LEN;
+	u32 rx_buffer_len, i;
 
 	if ((max_frame < ETH_ZLEN + ETH_FCS_LEN) ||
 	    (max_frame > MAX_JUMBO_FRAME_SIZE)) {
@@ -3877,9 +3877,6 @@ static int igb_change_mtu(struct net_dev
 
 	/* igb_down has a dependency on max_frame_size */
 	adapter->max_frame_size = max_frame;
-	if (netif_running(netdev))
-		igb_down(adapter);
-
 	/* NOTE: netdev_alloc_skb reserves 16 bytes, and typically NET_IP_ALIGN
 	 * means we reserve 2 more, this pushes us to allocate from the next
 	 * larger slab size.
@@ -3887,16 +3884,22 @@ static int igb_change_mtu(struct net_dev
 	 */
 
 	if (max_frame <= IGB_RXBUFFER_1024)
-		adapter->rx_buffer_len = IGB_RXBUFFER_1024;
+		rx_buffer_len = IGB_RXBUFFER_1024;
 	else if (max_frame <= MAXIMUM_ETHERNET_VLAN_SIZE)
-		adapter->rx_buffer_len = MAXIMUM_ETHERNET_VLAN_SIZE;
+		rx_buffer_len = MAXIMUM_ETHERNET_VLAN_SIZE;
 	else
-		adapter->rx_buffer_len = IGB_RXBUFFER_128;
+		rx_buffer_len = IGB_RXBUFFER_128;
+
+	if (netif_running(netdev))
+		igb_down(adapter);
 
 	dev_info(&adapter->pdev->dev, "changing MTU from %d to %d\n",
 		 netdev->mtu, new_mtu);
 	netdev->mtu = new_mtu;
 
+	for (i = 0; i < adapter->num_rx_queues; i++)
+		adapter->rx_ring[i].rx_buffer_len = rx_buffer_len;
+
 	if (netif_running(netdev))
 		igb_up(adapter);
 	else
@@ -5117,7 +5120,7 @@ static inline void igb_rx_hwtstamp(struc
 	igb_systim_to_hwtstamp(adapter, skb_hwtstamps(skb), regval);
 }
 
-static inline u16 igb_get_hlen(struct igb_adapter *adapter,
+static inline u16 igb_get_hlen(struct igb_ring *rx_ring,
                                union e1000_adv_rx_desc *rx_desc)
 {
 	/* HW will not DMA in data larger than the given buffer, even if it
@@ -5126,8 +5129,8 @@ static inline u16 igb_get_hlen(struct ig
 	 */
 	u16 hlen = (le16_to_cpu(rx_desc->wb.lower.lo_dword.hdr_info) &
 	           E1000_RXDADV_HDRBUFLEN_MASK) >> E1000_RXDADV_HDRBUFLEN_SHIFT;
-	if (hlen > adapter->rx_buffer_len)
-		hlen = adapter->rx_buffer_len;
+	if (hlen > rx_ring->rx_buffer_len)
+		hlen = rx_ring->rx_buffer_len;
 	return hlen;
 }
 
@@ -5177,14 +5180,14 @@ static bool igb_clean_rx_irq_adv(struct
 
 		if (buffer_info->dma) {
 			pci_unmap_single(pdev, buffer_info->dma,
-					 adapter->rx_buffer_len,
+					 rx_ring->rx_buffer_len,
 					 PCI_DMA_FROMDEVICE);
 			buffer_info->dma = 0;
-			if (adapter->rx_buffer_len >= IGB_RXBUFFER_1024) {
+			if (rx_ring->rx_buffer_len >= IGB_RXBUFFER_1024) {
 				skb_put(skb, length);
 				goto send_up;
 			}
-			skb_put(skb, igb_get_hlen(adapter, rx_desc));
+			skb_put(skb, igb_get_hlen(rx_ring, rx_desc));
 		}
 
 		if (length) {
@@ -5278,7 +5281,7 @@ static void igb_alloc_rx_buffers_adv(str
 	i = rx_ring->next_to_use;
 	buffer_info = &rx_ring->buffer_info[i];
 
-	bufsz = adapter->rx_buffer_len;
+	bufsz = rx_ring->rx_buffer_len;
 
 	while (cleaned_count--) {
 		rx_desc = E1000_RX_DESC_ADV(*rx_ring, i);
