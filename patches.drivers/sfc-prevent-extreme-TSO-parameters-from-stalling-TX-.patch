From: Benjamin Poirier <bpoirier@suse.de>
Date: Thu, 20 Sep 2012 16:18:24 -0400
Subject: [PATCH] sfc: prevent extreme TSO parameters from stalling TX queues
Patch-mainline: Never, see commit description
References: bnc#774523 CVE-2012-3412

On Linux, a peer (or local user) may cause TCP to use a nominal MSS of
as little as 88 (actual MSS of 76 with timestamps).  Given that we have
a sufficiently prodigious local sender and the peer ACKs quickly enough,
it is nevertheless possible to grow the window for such a connection
to the point that we will try to send just under 64K at once.  This
results in a single skb that expands to 861 segments.

In the sfc driver, such an skb will require hundreds of DMA descriptors;
a substantial fraction of a TX ring or even more than a full ring.  The
TX queue selected for the skb may stall and trigger the TX watchdog
repeatedly (since the problem skb will be retried after the TX reset).

Set the maximum number of TSO segments for our devices to 100.  This
should make no difference to behaviour unless the actual MSS is less
than about 700.

This problem was fixed upstream in v3.6-rc2 by
30b678d net: Allow driver to limit number of GSO segments per skb
7e6d06f sfc: Fix maximum number of TSO segments and minimum TX queue size
1485348 tcp: Apply device TSO segment limit earlier
but thse modifiy the kernel ABI.

The simpler version used here is extracted verbatim from the out-of-tree sfc
driver version 3.2.1.6099, available from <https://support.solarflare.com>.

Signed-off-by: Benjamin Poirier <bpoirier@suse.de>
---
 drivers/net/sfc/tx.c |   16 ++++++++++++++++
 1 file changed, 16 insertions(+)

--- a/drivers/net/sfc/tx.c
+++ b/drivers/net/sfc/tx.c
@@ -1132,6 +1132,22 @@ static int efx_enqueue_skb_tso(struct ef
 	int frag_i, rc, rc2 = NETDEV_TX_OK;
 	struct tso_state state;
 
+#define TCP_MAX_GSO_SEGS 100
+	/* Since the TCP does not limit the number of segments per
+	 * skb, we must do so.  Otherwise an attacker may be able to
+	 * make the TCP produce skbs that will never fit in our TX
+	 * queue, causing repeated resets.
+	 */
+	if (unlikely(skb_shinfo(skb)->gso_segs > TCP_MAX_GSO_SEGS)) {
+		unsigned int excess =
+			(skb_shinfo(skb)->gso_segs - TCP_MAX_GSO_SEGS) *
+			skb_shinfo(skb)->gso_size;
+		if (__pskb_trim(skb, skb->len - excess)) {
+			dev_kfree_skb_any(skb);
+			return NETDEV_TX_OK;
+		}
+	}
+
 	/* Find the packet protocol and sanity-check it */
 	state.protocol = efx_tso_check_protocol(skb);
 
