From: Dave Hansen <dave@linux.vnet.ibm.com>
Date: Wed, 21 Nov 2012 14:21:51 -0500
Subject: [PATCH] fix incorrect NR_FREE_PAGES accounting (appears like memory
 leak)

References: Compaction functionality
Patch-mainline: Yes (v3.7)
Git-commit: ef6c5be658f6a70c1256fbd18e18ee0dc24c3386

There have been some 3.7-rc reports of vm issues, including some kswapd
bugs and, more importantly, some memory "leaks":

	http://www.spinics.net/lists/linux-mm/msg46187.html
	https://bugzilla.kernel.org/show_bug.cgi?id=50181

Commit 1fb3f8ca0e92 ("mm: compaction: capture a suitable high-order page
immediately when it is made available") took split_free_page() and
reused it for the compaction code.  It does something curious with
capture_free_page() (previously known as split_free_page()):

  int capture_free_page(struct page *page, int alloc_order,
  ...
          __mod_zone_page_state(zone, NR_FREE_PAGES, -(1UL << order));

  -       /* Split into individual pages */
  -       set_page_refcounted(page);
  -       split_page(page, order);
  +       if (alloc_order != order)
  +               expand(zone, page, alloc_order, order,
  +                       &zone->free_area[order], migratetype);

Note that expand() puts the pages _back_ in the allocator, but it does
not bump NR_FREE_PAGES.  We "return" 'alloc_order' worth of pages, but
we accounted for removing 'order' in the __mod_zone_page_state() call.

For the old split_page()-style use (order==alloc_order) the bug will not
trigger.  But, when called from the compaction code where we
occasionally get a larger page out of the buddy allocator than we need,
we will run in to this.

This patch simply changes the NR_FREE_PAGES manipulation to the correct
'alloc_order' instead of 'order'.

I've been able to repeatedly trigger this in my testing environment.
The amount "leaked" very closely tracks the imbalance I see in buddy
pages vs.  NR_FREE_PAGES.  I have confirmed that this patch fixes the
imbalance

Signed-off-by: Dave Hansen <dave@linux.vnet.ibm.com>
Acked-by: Mel Gorman <mgorman@suse.de>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 mm/page_alloc.c |    4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 1a2ff48..1aa3523 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1319,7 +1319,7 @@ int capture_free_page(struct page *page, int alloc_order, int migratetype)
 	list_del(&page->lru);
 	zone->free_area[order].nr_free--;
 	rmv_page_order(page);
-	__mod_zone_page_state(zone, NR_FREE_PAGES, -(1UL << order));
+	__mod_zone_page_state(zone, NR_FREE_PAGES, -(1UL << alloc_order));
 
 	if (alloc_order != order)
 		expand(zone, page, alloc_order, order,
@@ -1332,7 +1332,7 @@ int capture_free_page(struct page *page, int alloc_order, int migratetype)
 			set_pageblock_migratetype(page, MIGRATE_MOVABLE);
 	}
 
-	return 1UL << order;
+	return 1UL << alloc_order;
 }
 
 /*
