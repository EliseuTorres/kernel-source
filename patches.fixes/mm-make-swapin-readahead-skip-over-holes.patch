From: Mel Gorman <mgorman@suse.de>
Date: Tue, 6 Mar 2012 16:15:10 +0000
Subject: [PATCH] mm: make swapin readahead skip over holes
References: VM performance
Patch-mainline: Not yet, expected 3.5

Ever since abandoning the virtual scan of processes, for scalability reasons,
swap space has been a little more fragmented than before.  This can lead
to the situation where a large memory user is killed, swap space ends up
full of "holes" and swapin readahead is totally ineffective.

On my home system, after killing a leaky firefox it took over an hour to
page just under 2GB of memory back in, slowing the virtual machines down
to a crawl.

This patch makes swapin readahead simply skip over holes, instead of
stopping at them.  This allows the system to swap things back in at rates
of several MB/second, instead of a few hundred kB/second.

NOTE: This is a minimal backport that continues to use
      valid_swaphandles as frontswap would need additional work for the
      full patch to work.

Signed-off-by: Rik van Riel <riel@redhat.com>
Cc: Minchan Kim <minchan.kim@gmail.com>
Cc: KOSAKI Motohiro <kosaki.motohiro@gmail.com>
Acked-by: Johannes Weiner <hannes@cmpxchg.org>
Acked-by: Mel Gorman <mgorman@suse.de>
Cc: Adrian Drzewiecki <z@drze.net>
Cc: Hugh Dickins <hughd@google.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 mm/swap_state.c |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/mm/swap_state.c b/mm/swap_state.c
index 787ca54..02e9624 100644
--- a/mm/swap_state.c
+++ b/mm/swap_state.c
@@ -392,7 +392,7 @@ struct page *swapin_readahead(swp_entry_t entry, gfp_t gfp_mask,
 		page = read_swap_cache_async(swp_entry(swp_type(entry), offset),
 						gfp_mask, vma, addr);
 		if (!page)
-			break;
+			continue;
 		page_cache_release(page);
 	}
 	lru_add_drain();	/* Push any new pages onto the LRU now */
