From: Michal Kubecek <mkubecek@suse.cz>
Date: Wed, 19 Mar 2014 13:28:32 +0100
Subject: inetpeer: prevent unlinking from unused list twice
Patch-mainline: Never, SLE11-SP3 specific code
References: bnc#867953

The bnc#779969 backport reuses the memory occupied by unused
member of struct inet_peer for the base pointer needed by
inet_putpeer().

However, a race between cleanup_once() and inet_getpeer() can
cause unlink_from_unused() trying to unlink even if this was
already done in cleanup_once(). In the original code, this is
not a problem as cleanup_once() uses list_del_init() so that the
list_del() in unlink_from_unused() is a no-op. With the backport,
unused.next is already rewritten by the base pointer so that the
list_del() will rewrite 8 bytes at offset 8 in struct
inet_peer_base.

Avoid this by zeroing the other half of unused whenever base
pointer is set and don't try to unlink from the unused list if
it is null. Also add check that it is null into inet_putpeer()
as if it wasn't (which should not be possible), it would be
better to check this inconsistency as soon as possible; it would
break the list and lead to a serious trouble anyway.

Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
---
 include/net/inetpeer.h |  5 ++++-
 net/ipv4/inetpeer.c    | 18 ++++++++++++++----
 2 files changed, 18 insertions(+), 5 deletions(-)

diff --git a/include/net/inetpeer.h b/include/net/inetpeer.h
index 609c44a..7ae36bd 100644
--- a/include/net/inetpeer.h
+++ b/include/net/inetpeer.h
@@ -36,7 +36,10 @@ struct inet_peer {
 	__u32			avl_height;
 	union {
 		struct list_head	unused;
-		struct inet_peer_base	*base;
+		struct {
+			struct inet_peer_base	*base;
+			void			*base_padding;
+		};
 	};
 	__u32			dtime;		/* the time of last use of not
 						 * referenced entries */
diff --git a/net/ipv4/inetpeer.c b/net/ipv4/inetpeer.c
index 6212b25..a23bbcd 100644
--- a/net/ipv4/inetpeer.c
+++ b/net/ipv4/inetpeer.c
@@ -181,8 +181,11 @@ static void unlink_from_unused(struct inet_peer_base *base,
 			       struct inet_peer *p)
 {
 	spin_lock_bh(&unused_peers_lock);
-	list_del(&p->unused);
-	p->base = base;
+	if (p->base_padding) {
+		list_del(&p->unused);
+		p->base = base;
+		p->base_padding = NULL;
+	}
 	spin_unlock_bh(&unused_peers_lock);
 }
 
@@ -477,8 +480,11 @@ static int cleanup_once(struct inet_peer_base *base,
 			return -1;
 		}
 
-		list_del_init(&p->unused);
-		p->base = base;
+		if (p->base_padding) {
+			list_del(&p->unused);
+			p->base = base;
+			p->base_padding = NULL;
+		}
 
 		/* Grab an extra reference to prevent node disappearing
 		 * before unlink_from_pool() call. */
@@ -552,6 +558,7 @@ found:		/* The existing node has been found.
 		p->pmtu_orig = 0;
 		memset(&p->redirect_learned, 0, sizeof(p->redirect_learned));
 		p->base = base;
+		p->base_padding = NULL;
 
 		/* Link the node. */
 		link_to_pool(p, base);
@@ -624,6 +631,9 @@ void inet_putpeer(struct inet_peer *p)
 
 	if (atomic_dec_and_lock(&p->refcnt, &unused_peers_lock)) {
 		struct inet_peer_base *base = p->base;
+
+		/* If base_padding is not null, base doesn't make sense */
+		BUG_ON(p->base_padding);
 		list_add_tail(&p->unused, &base->unused_peers_list);
 		p->dtime = (__u32)jiffies;
 		spin_unlock(&unused_peers_lock);
-- 
1.8.1.4

