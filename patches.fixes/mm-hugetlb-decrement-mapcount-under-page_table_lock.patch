From: Mel Gorman <mgorman@suse.de>
Date: Thu, 7 Jun 2012 13:49:32 +0100
Subject: [PATCH] mm: hugetlb: Decrement mapcount under page table lock
References: Consistent mapcount decrementing under lock (bnc#762366)
Patch-mainline: Never, should be dropped in favour of bad pmd fix under review

Without this patch, a parallel fault potentially increments the mapcount
while a region is being unmapped.

Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 mm/hugetlb.c |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/mm/hugetlb.c b/mm/hugetlb.c
index e341e54..cc4611b 100644
--- a/mm/hugetlb.c
+++ b/mm/hugetlb.c
@@ -2302,12 +2302,12 @@ void __unmap_hugepage_range(struct vm_area_struct *vma, unsigned long start,
 		if (pte_dirty(pte))
 			set_page_dirty(page);
 		list_add(&page->lru, &page_list);
+		page_remove_rmap(page);
 	}
 	flush_tlb_range(vma, start, end);
 	spin_unlock(&mm->page_table_lock);
 	mmu_notifier_invalidate_range_end(mm, start, end);
 	list_for_each_entry_safe(page, tmp, &page_list, lru) {
-		page_remove_rmap(page);
 		list_del(&page->lru);
 		put_page(page);
 	}
