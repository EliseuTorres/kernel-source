From 97a6c37b34f46feed2544bd40891ee6dd0fd1554 Mon Sep 17 00:00:00 2001
From: Johannes Weiner <hannes@cmpxchg.org>
Date: Wed, 23 Mar 2011 16:42:27 -0700
Subject: [PATCH] memcg: change page_cgroup_zoneinfo signature
Patch-mainline: 97a6c37b34f46feed2544bd40891ee6dd0fd1554
References: bnc#704592

Mhocko: 
Also remove pointless page_cgroup_zoneinfo from __mem_cgroup_uncharge_common
which is never used (the complete patch for this cleanup is bd0d24bf but I
didn't include it for 11sp2 because I focused only on fixes)

The original description:
Instead of passing a whole struct page_cgroup to this function, let it
take only what it really needs from it: the struct mem_cgroup and the
page.

This has the advantage that reading pc->mem_cgroup is now done at the same
place where the ordering rules for this pointer are enforced and
explained.

It is also in preparation for removing the pc->page backpointer.

Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
Cc: Minchan Kim <minchan.kim@gmail.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Acked-by: Michal Hocko <mhocko@suse.cz>

---
 include/linux/page_cgroup.h |   10 ----------
 mm/memcontrol.c             |   21 +++++++++------------
 2 files changed, 9 insertions(+), 22 deletions(-)
Index: linux-2.6.32-memcg-backports/include/linux/page_cgroup.h
===================================================================
--- linux-2.6.32-memcg-backports.orig/include/linux/page_cgroup.h
+++ linux-2.6.32-memcg-backports/include/linux/page_cgroup.h
@@ -82,16 +82,6 @@ SETPCGFLAG(Migration, MIGRATION)
 CLEARPCGFLAG(Migration, MIGRATION)
 TESTPCGFLAG(Migration, MIGRATION)
 
-static inline int page_cgroup_nid(struct page_cgroup *pc)
-{
-	return page_to_nid(pc->page);
-}
-
-static inline enum zone_type page_cgroup_zid(struct page_cgroup *pc)
-{
-	return page_zonenum(pc->page);
-}
-
 static inline void lock_page_cgroup(struct page_cgroup *pc)
 {
 	bit_spin_lock(PCG_LOCK, &pc->flags);
Index: linux-2.6.32-memcg-backports/mm/memcontrol.c
===================================================================
--- linux-2.6.32-memcg-backports.orig/mm/memcontrol.c
+++ linux-2.6.32-memcg-backports/mm/memcontrol.c
@@ -305,11 +305,10 @@ struct cgroup_subsys_state *mem_cgroup_c
 }
 
 static struct mem_cgroup_per_zone *
-page_cgroup_zoneinfo(struct page_cgroup *pc)
+page_cgroup_zoneinfo(struct mem_cgroup *mem, struct page *page)
 {
-	struct mem_cgroup *mem = pc->mem_cgroup;
-	int nid = page_cgroup_nid(pc);
-	int zid = page_cgroup_zid(pc);
+	int nid = page_to_nid(page);
+	int zid = page_zonenum(page);
 
 	return mem_cgroup_zoneinfo(mem, nid, zid);
 }
@@ -678,7 +677,7 @@ void mem_cgroup_del_lru_list(struct page
 	 * We don't check PCG_USED bit. It's cleared when the "page" is finally
 	 * removed from global LRU.
 	 */
-	mz = page_cgroup_zoneinfo(pc);
+	mz = page_cgroup_zoneinfo(pc->mem_cgroup, page);
 	/* huge page split is done under lru_lock. so, we have no races. */
 	MEM_CGROUP_ZSTAT(mz, lru) -= 1 << compound_order(page);
 	if (mem_cgroup_is_root(pc->mem_cgroup))
@@ -715,7 +714,7 @@ void mem_cgroup_rotate_reclaimable_page(
 	smp_rmb();
 	if (mem_cgroup_is_root(pc->mem_cgroup))
 		return;
-	mz = page_cgroup_zoneinfo(pc);
+	mz = page_cgroup_zoneinfo(pc->mem_cgroup, page);
 	list_move_tail(&pc->lru, &mz->lists[lru]);
 }
 
@@ -736,7 +735,7 @@ void mem_cgroup_rotate_lru_list(struct p
 	/* unused or root page is not rotated. */
 	if (!PageCgroupUsed(pc) || mem_cgroup_is_root(pc->mem_cgroup))
 		return;
-	mz = page_cgroup_zoneinfo(pc);
+	mz = page_cgroup_zoneinfo(pc->mem_cgroup, page);
 	list_move(&pc->lru, &mz->lists[lru]);
 }
 
@@ -757,7 +756,7 @@ void mem_cgroup_add_lru_list(struct page
 	if (!PageCgroupUsed(pc))
 		return;
 
-	mz = page_cgroup_zoneinfo(pc);
+	mz = page_cgroup_zoneinfo(pc->mem_cgroup, page);
 	/* huge page split is done under lru_lock. so, we have no races. */
 	MEM_CGROUP_ZSTAT(mz, lru) += 1 << compound_order(page);
 	SetPageCgroupAcctLRU(pc);
@@ -930,7 +929,7 @@ mem_cgroup_get_reclaim_stat_from_page(st
 	if (!PageCgroupUsed(pc))
 		return NULL;
 
-	mz = page_cgroup_zoneinfo(pc);
+	mz = page_cgroup_zoneinfo(pc->mem_cgroup, page);
 	if (!mz)
 		return NULL;
 
@@ -1804,7 +1803,7 @@ void mem_cgroup_split_huge_fixup(struct
 		 * We hold lru_lock, then, reduce counter directly.
 		 */
 		lru = page_lru(head);
-		mz = page_cgroup_zoneinfo(head_pc);
+		mz = page_cgroup_zoneinfo(head_pc->mem_cgroup, head);
 		MEM_CGROUP_ZSTAT(mz, lru) -= 1;
 	}
 	tail_pc->flags = head_pc->flags & ~PCGF_NOCOPY_AT_SPLIT;
@@ -2234,7 +2233,6 @@ __mem_cgroup_uncharge_common(struct page
 {
 	struct page_cgroup *pc;
 	struct mem_cgroup *mem = NULL;
-	struct mem_cgroup_per_zone *mz;
 	int nr_pages = 1;
 	bool file = !PageAnon(page);
 
@@ -2294,7 +2292,6 @@ __mem_cgroup_uncharge_common(struct page
 	 * special functions.
 	 */
 
-	mz = page_cgroup_zoneinfo(pc);
 	unlock_page_cgroup(pc);
 
 	if (mem_cgroup_soft_limit_check(mem))
