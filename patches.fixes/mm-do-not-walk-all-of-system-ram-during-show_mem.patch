From: Mel Gorman <mgorman@suse.de>
Date: Mon, 14 Oct 2013 10:48:03 +0100
Subject: [PATCH] mm: Do not walk all of system memory during show_mem

References: Reduce tasklist_lock hold times (bnc#821259)
Patch-mainline: Yes (v3.13-rc1)
Git-commit: c78e93630d15b5f5774213aad9bdc9f52473a89b

NOTE: This is not an exact backport as zone->managed_pages is not available.
	Backporting that information is overkill just for show_mem as I do
	not believe that anyone uses PageReserved information when debugging
	OOM conditions.

It has been reported on very large machines that show_mem is taking almost
5 minutes to display information. This is a serious problem if there is
an OOM storm. The bulk of the cost is in show_mem doing a very expensive
PFN walk to give us the following information

Total RAM:	Also available as totalram_pages
Highmem pages:	Also available as totalhigh_pages
Reserved pages:	PFN walk required
Shared pages:	PFN walk required
Unshared pages:	PFN walk required
Quick pages:	Per-cpu walk required

The reserved and shared/unshared pages require a full PFN walk but that
information is useless. It is also inaccurate as page pins of unshared pages
would be accounted for as shared.  Even if the information was accurate,
I'm struggling to think how the shared/unshared information could be useful
for debugging OOM conditions. Maybe it was useful before rmap existed when
reclaiming shared pages was costly but it is less relevant today.

The PFN walk could be optimised a bit but why bother as the information
is useless. This patch deletes the PFN walker and infers the total RAM and
highmem from struct zone. It no longer reports on shared/unshared page and
reserved page usage on the grounds that it is useless and expensive.  It also
corrects the reporting of HighMem as HighMem/MovableOnly as ZONE_MOVABLE
has similar problems to HighMem with respect to lowmem/highmem exhaustion.

Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 lib/show_mem.c | 35 +++++++++--------------------------
 1 file changed, 9 insertions(+), 26 deletions(-)

diff --git a/lib/show_mem.c b/lib/show_mem.c
index 4407f8c..217a017 100644
--- a/lib/show_mem.c
+++ b/lib/show_mem.c
@@ -12,39 +12,25 @@
 void show_mem(unsigned int filter)
 {
 	pg_data_t *pgdat;
-	unsigned long total = 0, reserved = 0, shared = 0,
-		nonshared = 0, highmem = 0;
+	unsigned long total = 0, highmem = 0;
 
 	printk("Mem-Info:\n");
 	show_free_areas(filter);
 
 	for_each_online_pgdat(pgdat) {
-		unsigned long i, flags;
+		unsigned long flags;
+		int zoneid;
 
 		pgdat_resize_lock(pgdat, &flags);
-		for (i = 0; i < pgdat->node_spanned_pages; i++) {
-			struct page *page;
-			unsigned long pfn = pgdat->node_start_pfn + i;
-
-			if (unlikely(!(i % MAX_ORDER_NR_PAGES)))
-				touch_nmi_watchdog();
-
-			if (!pfn_valid(pfn))
+		for (zoneid = 0; zoneid < MAX_NR_ZONES; zoneid++) {
+			struct zone *zone = &pgdat->node_zones[zoneid];
+			if (!populated_zone(zone))
 				continue;
 
-			page = pfn_to_page(pfn);
-
-			if (PageHighMem(page))
-				highmem++;
-
-			if (PageReserved(page))
-				reserved++;
-			else if (page_count(page) == 1)
-				nonshared++;
-			else if (page_count(page) > 1)
-				shared += page_count(page) - 1;
+			total += zone->present_pages;
 
-			total++;
+			if (is_highmem_idx(zoneid))
+				highmem += zone->present_pages;
 		}
 		pgdat_resize_unlock(pgdat, &flags);
 	}
@@ -53,9 +39,6 @@ void show_mem(unsigned int filter)
 #ifdef CONFIG_HIGHMEM
 	printk("%lu pages HighMem\n", highmem);
 #endif
-	printk("%lu pages reserved\n", reserved);
-	printk("%lu pages shared\n", shared);
-	printk("%lu pages non-shared\n", nonshared);
 #ifdef CONFIG_QUICKLIST
 	printk("%lu pages in pagetable cache\n",
 		quicklist_total_size());
