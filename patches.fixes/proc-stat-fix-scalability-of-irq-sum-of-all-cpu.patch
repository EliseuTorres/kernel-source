From: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Subject: /proc/stat: fix scalability of irq sum of all cpu
References: bnc#648112
Git-commit: 478735e38887077ac77a9756121b6ce0cb956e2f
Patch-mainline: v2.6.37-rc1

In /proc/stat, the number of per-IRQ event is shown by making a sum each
irq's events on all cpus.  But we can make use of kstat_irqs().
    
kstat_irqs() do the same calculation, If !CONFIG_GENERIC_HARDIRQ,
it's not a big cost. (Both of the number of cpus and irqs are small.)
    
If a system is very big and CONFIG_GENERIC_HARDIRQ, it does
    
 	for_each_irq()
    		for_each_cpu()
    			- look up a radix tree
    			- read desc->irq_stat[cpu]
This seems not efficient. This patch adds kstat_irqs() for
CONFIG_GENRIC_HARDIRQ and change the calculation as
    
    	for_each_irq()
    		look up radix tree
    		for_each_cpu()
    			- read desc->irq_stat[cpu]
    
This reduces cost.
    
A test on (4096cpusp, 256 nodes, 4592 irqs) host (by Jack Steiner)
    
%time cat /proc/stat > /dev/null
    
Before Patch:	 2.459 sec
After Patch :	  .561 sec
    
[akpm@linux-foundation.org: unexport kstat_irqs, coding-style tweaks]
[akpm@linux-foundation.org: fix unused variable 'per_irq_sum']
Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Tested-by: Jack Steiner <steiner@sgi.com>
Acked-by: Jack Steiner <steiner@sgi.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Rafael J. Wysocki <rjw@suse.de>
---
 fs/proc/stat.c              |   10 ++--------
 include/linux/kernel_stat.h |    4 ++++
 kernel/irq/handle.c         |   15 +++++++++++++++
 3 files changed, 21 insertions(+), 8 deletions(-)

Index: linux-2.6.32-SLE11-SP1/fs/proc/stat.c
===================================================================
--- linux-2.6.32-SLE11-SP1.orig/fs/proc/stat.c
+++ linux-2.6.32-SLE11-SP1/fs/proc/stat.c
@@ -32,7 +32,6 @@ static int show_stat(struct seq_file *p,
 	u64 sum_softirq = 0;
 	unsigned int per_softirq_sums[NR_SOFTIRQS] = {0};
 	struct timespec boottime;
-	unsigned int per_irq_sum;
 
 	user = nice = system = idle = iowait =
 		irq = softirq = steal = cputime64_zero;
@@ -102,13 +101,8 @@ static int show_stat(struct seq_file *p,
 	seq_printf(p, "intr %llu", (unsigned long long)sum);
 
 	/* sum again ? it could be updated? */
-	for_each_irq_nr(j) {
-		per_irq_sum = 0;
-		for_each_possible_cpu(i)
-			per_irq_sum += kstat_irqs_cpu(j, i);
-
-		seq_printf(p, " %u", per_irq_sum);
-	}
+	for_each_irq_nr(j)
+		seq_printf(p, " %u", kstat_irqs(j));
 
 	seq_printf(p,
 		"\nctxt %llu\n"
Index: linux-2.6.32-SLE11-SP1/include/linux/kernel_stat.h
===================================================================
--- linux-2.6.32-SLE11-SP1.orig/include/linux/kernel_stat.h
+++ linux-2.6.32-SLE11-SP1/include/linux/kernel_stat.h
@@ -89,6 +89,7 @@ static inline unsigned int kstat_softirq
 /*
  * Number of interrupts per specific IRQ source, since bootup
  */
+#ifndef CONFIG_GENERIC_HARDIRQS
 static inline unsigned int kstat_irqs(unsigned int irq)
 {
 	unsigned int sum = 0;
@@ -99,6 +100,9 @@ static inline unsigned int kstat_irqs(un
 
 	return sum;
 }
+#else
+extern unsigned int kstat_irqs(unsigned int irq);
+#endif
 
 /*
  * Number of interrupts per cpu, since bootup
Index: linux-2.6.32-SLE11-SP1/kernel/irq/handle.c
===================================================================
--- linux-2.6.32-SLE11-SP1.orig/kernel/irq/handle.c
+++ linux-2.6.32-SLE11-SP1/kernel/irq/handle.c
@@ -552,6 +552,21 @@ void early_init_irq_lock_class(void)
 	}
 }
 
+#ifdef CONFIG_GENERIC_HARDIRQS
+unsigned int kstat_irqs(unsigned int irq)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	int cpu;
+	int sum = 0;
+
+	if (!desc)
+		return 0;
+	for_each_possible_cpu(cpu)
+		sum += desc->kstat_irqs[cpu];
+	return sum;
+}
+#endif /* CONFIG_GENERIC_HARDIRQS */
+
 unsigned int kstat_irqs_cpu(unsigned int irq, int cpu)
 {
 	struct irq_desc *desc = irq_to_desc(irq);
