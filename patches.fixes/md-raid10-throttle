From: NeilBrown <neilb@suse.de>
Subject: Throttle number of pending write requests in md/raid10
References: bnc#833858
Git-commit: 34db0cd60f8a1f4ab73d118a8be3797c20388223
Patch-mainline: v3.2

Currently write requests are added to a queue to be processed later by
the raid1d thread.  This allows an arbitrary number of requests to
queue up which is bad for latency.

So count the number of requests and allow it to be limited.

Currently the limit is virtually infinity and must be set by changing
  /sys/modules/raid10/parameters/max_queued
to be effective.

This is because there is still some uncertainty about the exact
behaviour required.  Once this is resolved the default might be
changed.  For now it is here as a place-holder and subsequent patches
change this code, so we wont to some something in place.

Signed-off-by: NeilBrown <neilb@suse.de>

---
 drivers/md/raid10.c |   18 ++++++++++++++++++
 drivers/md/raid10.h |    2 +-
 2 files changed, 19 insertions(+), 1 deletion(-)

--- linux-3.0-SLE11-SP2.orig/drivers/md/raid10.c
+++ linux-3.0-SLE11-SP2/drivers/md/raid10.c
@@ -702,12 +702,18 @@ retry:
 	return disk;
 }
 
+static int max_queued = INT_MAX;
+
 static int raid10_congested(void *data, int bits)
 {
 	mddev_t *mddev = data;
 	conf_t *conf = mddev->private;
 	int i, ret = 0;
 
+	if ((bits & (1 << BDI_async_congested)) &&
+	    conf->pending_count >= max_queued)
+		return 1;
+
 	if (mddev_congested(mddev, bits))
 		return 1;
 	rcu_read_lock();
@@ -736,7 +742,9 @@ static void flush_pending_writes(conf_t
 	if (conf->pending_bio_list.head) {
 		struct bio *bio;
 		bio = bio_list_get(&conf->pending_bio_list);
+		conf->pending_count = 0;
 		spin_unlock_irq(&conf->device_lock);
+		wake_up(&conf->wait_barrier);
 		/* flush any pending bitmap writes to disk
 		 * before proceeding w/ I/O */
 		raid10_log(conf->mddev, "bitmap unplug");
@@ -1059,6 +1067,11 @@ static int make_request(mddev_t *mddev,
 	/*
 	 * WRITE:
 	 */
+	if (conf->pending_count >= max_queued) {
+		md_wakeup_thread(mddev->thread);
+		wait_event(conf->wait_barrier,
+			   conf->pending_count < max_queued);
+	}
 	/* first select target devices under rcu_lock and
 	 * inc refcount on their rdev.  Record them by setting
 	 * bios[x] to bio
@@ -1138,6 +1151,7 @@ static int make_request(mddev_t *mddev,
 				      r10_bio->sector);
 		mbio->bi_bdev = (void *)conf->mirrors[d].rdev;
 		bio_list_add(&conf->pending_bio_list, mbio);
+		conf->pending_count++;
 		spin_unlock_irqrestore(&conf->device_lock, flags);
 	}
 
@@ -2677,6 +2691,8 @@ static conf_t *setup_conf(mddev_t *mddev
 
 	spin_lock_init(&conf->resync_lock);
 	init_waitqueue_head(&conf->wait_barrier);
+	bio_list_init(&conf->pending_bio_list);
+	conf->pending_count = 0;
 
 	conf->thread = md_register_thread(raid10d, mddev, NULL);
 	if (!conf->thread)
@@ -3796,3 +3812,5 @@ MODULE_DESCRIPTION("RAID10 (striped mirr
 MODULE_ALIAS("md-personality-9"); /* RAID10 */
 MODULE_ALIAS("md-raid10");
 MODULE_ALIAS("md-level-10");
+
+module_param(max_queued, int, S_IRUGO|S_IWUSR);
--- linux-3.0-SLE11-SP2.orig/drivers/md/raid10.h
+++ linux-3.0-SLE11-SP2/drivers/md/raid10.h
@@ -48,7 +48,7 @@ struct r10_private_data_s {
 	struct list_head	retry_list;
 	/* queue pending writes and submit them on unplug */
 	struct bio_list		pending_bio_list;
-
+	int			pending_count;
 
 	spinlock_t		resync_lock;
 	int nr_pending;
