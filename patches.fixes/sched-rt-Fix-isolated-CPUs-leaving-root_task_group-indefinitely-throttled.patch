Subject: sched,rt: fix isolated CPUs leaving root_task_group indefinitely throttled
From: Mike Galbraith <efault@gmx.de>
Date: Tue, 10 Apr 2012 11:08:45 +0200
Patch-mainline: submitted
References: bnc#754085

Root task group bandwidth replenishment must service all CPUs regardless of
where it was last started.

Note: while submitted, this patch is not going anywhere.  Peterz suggested a partial
fix for isolcpus, disabling the throttle for such CPUs.  That will not fix the case
where CPUs are isolated via cpusets, and extending his suggestion add cycles to the
fast path needlessly, and takes the throttle away as a debugging aid.  Fix this in
the manner best for our customers instead.

Signed-off-by: Mike Galbraith <efault@gmx.de>
Acked-by: Mike Galbraith <mgalbraith@suse.de>
---
 kernel/sched_rt.c |   13 +++++++++++++
 1 file changed, 13 insertions(+)

--- a/kernel/sched_rt.c
+++ b/kernel/sched_rt.c
@@ -596,6 +596,19 @@ static int do_sched_rt_period_timer(stru
 		return 1;
 
 	span = sched_rt_period_mask();
+#ifdef CONFIG_RT_GROUP_SCHED
+	/*
+	 * FIXME: isolated CPUs should really leave the root task group,
+	 * whether they are isolcpus or were isolated via cpusets, lest
+	 * the timer run on a CPU which does not service all runqueues,
+	 * potentially leaving other CPUs indefinitely throttled.  If
+	 * isolation is really required, the user will turn the throttle
+	 * off to kill the perturbations it causes anyway.  Meanwhile,
+	 * this maintains functionality for boot and/or troubleshooting.
+	 */
+	if (rt_b == &root_task_group.rt_bandwidth)
+		span = cpu_online_mask;
+#endif
 	for_each_cpu(i, span) {
 		int enqueue = 0;
 		struct rt_rq *rt_rq = sched_rt_period_rt_rq(rt_b, i);
