Subject: sched: ratelimit nohz
From: Mike Galbraith <mgalbraith@suse.de>
Date: Mon Jun 11 18:21:05 CEST 2012
Patch-mainline: never
References: Scheduler enhancements for I7 (bnc#754690)

Entering nohz code on every micro-idle is costing ~10% throughput for netperf
TCP_RR when scheduling cross-cpu.

The higher the context switch rate, the more nohz entry costs.  With this patch
and some cycle recovery patches in my tree, max cross cpu context switch rate is
improved by ~16%, a large portion of which of which is this ratelimiting.

Note: a similar patch was in mainline briefly, but was reverted due to one
complaint wrt laptop using more power.  The earlier version raised ticks/s
on my Q6600 bof from ~85c to ~128, this version does not, and also blocks
the mb() in rcu_needs_cpu().

Signed-off-by: Mike Galbraith <mgalbraith@suse.de>

---
 include/linux/sched.h    |    5 +++++
 kernel/sched.c           |    5 +++++
 kernel/time/tick-sched.c |    4 ++--
 3 files changed, 12 insertions(+), 2 deletions(-)

--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -274,8 +274,13 @@ extern cpumask_var_t nohz_cpu_mask;
 #if defined(CONFIG_SMP) && defined(CONFIG_NO_HZ)
 extern void select_nohz_load_balancer(int stop_tick);
 extern int get_nohz_timer_target(void);
+extern int sched_needs_cpu(int cpu);
 #else
 static inline void select_nohz_load_balancer(int stop_tick) { }
+static inline int sched_needs_cpu(int cpu)
+{
+	return 0;
+}
 #endif
 
 /*
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -1415,6 +1415,11 @@ static inline bool got_nohz_idle_kick(vo
 	return idle_cpu(smp_processor_id()) && this_rq()->nohz_balance_kick;
 }
 
+int sched_needs_cpu(int cpu)
+{
+	return  cpu_rq(cpu)->avg_idle < sysctl_sched_migration_cost;
+}
+
 #else /* CONFIG_NO_HZ */
 
 static inline bool got_nohz_idle_kick(void)
--- a/kernel/time/tick-sched.c
+++ b/kernel/time/tick-sched.c
@@ -323,8 +323,8 @@ void tick_nohz_stop_sched_tick(int inidl
 		time_delta = timekeeping_max_deferment();
 	} while (read_seqretry(&xtime_lock, seq));
 
-	if (rcu_needs_cpu(cpu) || printk_needs_cpu(cpu) ||
-	    arch_needs_cpu(cpu)) {
+	if (sched_needs_cpu(cpu) || rcu_needs_cpu(cpu) ||
+	    printk_needs_cpu(cpu) || arch_needs_cpu(cpu)) {
 		next_jiffies = last_jiffies + 1;
 		delta_jiffies = 1;
 	} else {
