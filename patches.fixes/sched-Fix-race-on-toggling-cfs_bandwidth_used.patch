Subject: sched: Fix race on toggling cfs_bandwidth_used
From: Ben Segall <bsegall@google.com>
Date: Wed, 16 Oct 2013 11:16:12 -0700
Git-commit: 1ee14e6c8cddeeb8a490d7b54cd9016e4bb900b4
Patch-mainline: v3.12
References: bnc#848336

When we transition cfs_bandwidth_used to false, any currently
throttled groups will incorrectly return false from cfs_rq_throttled.
While tg_set_cfs_bandwidth will unthrottle them eventually, currently
running code (including at least dequeue_task_fair and
distribute_cfs_runtime) will cause errors.

Fix this by turning off cfs_bandwidth_used only after unthrottling all
cfs_rqs.

Tested: toggle bandwidth back and forth on a loaded cgroup. Caused
crashes in minutes without the patch, hasn't crashed with it.

Signed-off-by: Ben Segall <bsegall@google.com>
Signed-off-by: Peter Zijlstra <peterz@infradead.org>
Cc: pjt@google.com
Link: http://lkml.kernel.org/r/20131016181611.22647.80365.stgit@sword-of-the-dawn.mtv.corp.google.com
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Acked-by: Mike Galbraith <mgalbraith@suse.de>

---
 kernel/sched.c |   25 +++++++++++++++++--------
 1 file changed, 17 insertions(+), 8 deletions(-)

--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -509,13 +509,14 @@ static inline bool cfs_bandwidth_used(vo
 	return static_branch(&__cfs_bandwidth_used);
 }
 
-static void account_cfs_bandwidth_used(int enabled, int was_enabled)
+static void cfs_bandwidth_usage_inc(void)
 {
-	/* only need to count groups transitioning between enabled/!enabled */
-	if (enabled && !was_enabled)
-		jump_label_inc(&__cfs_bandwidth_used);
-	else if (!enabled && was_enabled)
-		jump_label_dec(&__cfs_bandwidth_used);
+	jump_label_inc(&__cfs_bandwidth_used);
+}
+
+static void cfs_bandwidth_usage_dec(void)
+{
+	jump_label_dec(&__cfs_bandwidth_used);
 }
 #else /* !HAVE_JUMP_LABEL */
 /* static_branch doesn't help unless supported */
@@ -523,7 +524,8 @@ static int cfs_bandwidth_used(void)
 {
 	return 1;
 }
-static void account_cfs_bandwidth_used(int enabled, int was_enabled) {}
+static void cfs_bandwidth_usage_inc(void) {}
+static void cfs_bandwidth_usage_dec(void) {}
 #endif /* HAVE_JUMP_LABEL */
 #else /* !CONFIG_CFS_BANDWIDTH */
 static void init_cfs_rq_runtime(struct cfs_rq *cfs_rq) {}
@@ -9414,7 +9416,12 @@ static int tg_set_cfs_bandwidth(struct t
 
 	runtime_enabled = quota != RUNTIME_INF;
 	runtime_was_enabled = cfs_b->quota != RUNTIME_INF;
-	account_cfs_bandwidth_used(runtime_enabled, runtime_was_enabled);
+	/*
+	 * If we need to toggle cfs_bandwidth_used, off->on must occur
+	 * before making related changes, and on->off must occur afterwards
+	 */
+	if (runtime_enabled && !runtime_was_enabled)
+		cfs_bandwidth_usage_inc();
 
 	raw_spin_lock_irq(&cfs_b->lock);
 	cfs_b->period = ns_to_ktime(period);
@@ -9441,6 +9448,8 @@ static int tg_set_cfs_bandwidth(struct t
 			unthrottle_cfs_rq(cfs_rq);
 		raw_spin_unlock_irq(&rq->lock);
 	}
+	if (runtime_was_enabled && !runtime_enabled)
+		cfs_bandwidth_usage_dec();
 out_unlock:
 	mutex_unlock(&cfs_constraints_mutex);
 
