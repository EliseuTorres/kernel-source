From: Mel Gorman <mgorman@suse.de>
Subject: mm: vmscan: Stop looping in kswapd if high-order reclaim is failing
Patch-mainline: No
References: bnc#682567

A customer identified a problem whereby kswapd consumes 99% of CPU
in a tight loop. It was determined that there are constant sources of
high-order allocations and eventually the system becomes fragmented
and unable to service the allocations. However, as kswapd makes forward
progress, it continues to reclaim large numbers of pages consuming CPU
and dumping too much memory.

This patch allows kswapd to give up faster for costly high-order
allocations. A number of pages will still end up getting reclaimed
but the system cannot tell in advance that the allocation cannot be
satisfied so it still has to make a reasonable effort.

Signed-off-by: Mel Gorman <mgorman@suse.de>
Acked-by: Michal Hocko <mhocko@suse.cz>

---
 mm/vmscan.c |   12 +++++++++++-
 1 files changed, 11 insertions(+), 1 deletions(-)

Index: linux-2.6.32-bnc682567/mm/vmscan.c
===================================================================
--- linux-2.6.32-bnc682567.orig/mm/vmscan.c
+++ linux-2.6.32-bnc682567/mm/vmscan.c
@@ -1982,6 +1982,7 @@ static unsigned long balance_pgdat(pg_da
 	int i;
 	int end_zone = 0;	/* Inclusive.  0 = ZONE_DMA */
 	unsigned long total_scanned;
+	unsigned long total_reclaimed;
 	struct reclaim_state *reclaim_state = current->reclaim_state;
 	struct scan_control sc = {
 		.gfp_mask = GFP_KERNEL,
@@ -2002,6 +2003,7 @@ static unsigned long balance_pgdat(pg_da
 
 loop_again:
 	total_scanned = 0;
+	total_reclaimed = 0;
 	sc.nr_reclaimed = 0;
 	sc.may_writepage = !laptop_mode;
 	count_vm_event(PAGEOUTRUN);
@@ -2150,6 +2152,8 @@ loop_again:
 			break;
 	}
 out:
+	total_reclaimed += sc.nr_reclaimed;
+
 	/*
 	 * Note within each zone the priority level at which this zone was
 	 * brought into a happy state.  So that the next thread which scans this
@@ -2180,12 +2184,18 @@ out:
 		 * little point trying all over again as kswapd may
 		 * infinite loop.
 		 *
+		 * Similarly, if we have reclaimed far more pages than the
+		 * original request size, it's likely that contiguous reclaim
+		 * is not finding the pages it needs and it should give
+		 * up.
+		 *
 		 * Instead, recheck all watermarks at order-0 as they
 		 * are the most important. If watermarks are ok, kswapd will go
 		 * back to sleep. High-order users can still perform direct
 		 * reclaim if they wish.
 		 */
-		if (sc.nr_reclaimed < SWAP_CLUSTER_MAX)
+		if (sc.nr_reclaimed < SWAP_CLUSTER_MAX ||
+				(order > PAGE_ALLOC_COSTLY_ORDER && total_reclaimed > (4UL << order)) )
 			order = sc.order = 0;
 
 		goto loop_again;
