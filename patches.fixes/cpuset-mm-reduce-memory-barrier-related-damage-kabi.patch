From: Mel Gorman <mgorman@suse.de>
Date: Tue, 6 Mar 2012 19:17:35 +0000
Subject: [PATCH] cpuset: mm: Reduce large amounts of memory barrier related
References: VM performance
Patch-mainline: No

KABI compatability. seqcount_t should fit inside an unsigned int

Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 include/linux/init_t.. |    2 +-
 include/linux/cpuset.h |    5 +++--
 include/linux/sched.h  |    2 +-
 kernel/cpuset.c        |    4 ++--
 kernel/fork.c          |    2 +-
 5 files changed, 8 insertions(+), 7 deletions(-)

diff --git a/include/linux/init_task.h b/include/linux/init_task.h
index c5efec7..37ba7e0 100644
--- a/include/linux/init_task.h
+++ b/include/linux/init_task.h
@@ -32,7 +32,7 @@ extern struct fs_struct init_fs;
 
 #ifdef CONFIG_CPUSETS
 #define INIT_CPUSET_SEQ							\
-	.mems_allowed_seq = SEQCNT_ZERO,
+	.mems_allowed_change_disable = 0,
 #else
 #define INIT_CPUSET_SEQ
 #endif
diff --git a/include/linux/cpuset.h b/include/linux/cpuset.h
index 8f15695..173402a 100644
--- a/include/linux/cpuset.h
+++ b/include/linux/cpuset.h
@@ -97,7 +97,7 @@ extern void cpuset_print_task_mems_allowed(struct task_struct *p);
  */
 static inline unsigned int get_mems_allowed(void)
 {
-	return read_seqcount_begin(&current->mems_allowed_seq);
+	return read_seqcount_begin((seqcount_t *)&current->mems_allowed_change_disable);
 }
 
 /*
@@ -107,7 +107,8 @@ static inline unsigned int get_mems_allowed(void)
  */
 static inline bool put_mems_allowed(unsigned int seq)
 {
-	return !read_seqcount_retry(&current->mems_allowed_seq, seq);
+	BUG_ON(sizeof(seqcount_t) != sizeof(int));
+	return !read_seqcount_retry((seqcount_t *)&current->mems_allowed_change_disable, seq);
 }
 
 static inline void set_mems_allowed(nodemask_t nodemask)
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 70ce0e3..0bb7c5d 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1492,7 +1492,7 @@ struct task_struct {
 #endif
 #ifdef CONFIG_CPUSETS
 	nodemask_t mems_allowed;	/* Protected by alloc_lock */
-	seqcount_t mems_allowed_seq;	/* Seqence no to catch updates */
+	int mems_allowed_change_disable;
 	int cpuset_mem_spread_rotor;
 	int cpuset_slab_spread_rotor;
 #endif
diff --git a/kernel/cpuset.c b/kernel/cpuset.c
index dd1254a..8fe60f4 100644
--- a/kernel/cpuset.c
+++ b/kernel/cpuset.c
@@ -984,7 +984,7 @@ static void cpuset_change_task_nodemask(struct task_struct *tsk,
 			!nodes_intersects(*newmems, tsk->mems_allowed);
 
 	if (need_loop)
-		write_seqcount_begin(&tsk->mems_allowed_seq);
+		write_seqcount_begin((seqcount_t *)&tsk->mems_allowed_change_disable);
 
 	nodes_or(tsk->mems_allowed, tsk->mems_allowed, *newmems);
 	mpol_rebind_task(tsk, newmems, MPOL_REBIND_STEP1);
@@ -993,7 +993,7 @@ static void cpuset_change_task_nodemask(struct task_struct *tsk,
 	tsk->mems_allowed = *newmems;
 
 	if (need_loop)
-		write_seqcount_end(&tsk->mems_allowed_seq);
+		write_seqcount_end((seqcount_t *)&tsk->mems_allowed_change_disable);
 
 	task_unlock(tsk);
 }
diff --git a/kernel/fork.c b/kernel/fork.c
index bb9b842..22f3eae 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -983,7 +983,7 @@ static int copy_signal(unsigned long clone_flags, struct task_struct *tsk)
 	init_rwsem(&sig->threadgroup_fork_lock);
 #endif
 #ifdef CONFIG_CPUSETS
-	seqcount_init(&tsk->mems_allowed_seq);
+	seqcount_init((seqcount_t *)&current->mems_allowed_change_disable);
 #endif
 
 	sig->oom_adj = current->signal->oom_adj;
