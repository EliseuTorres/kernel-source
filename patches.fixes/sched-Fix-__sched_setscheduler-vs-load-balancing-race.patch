Subject: sched: fix __sched_setscheduler() vs load balancing race
From: Mike Galbraith <mgalbraith@suse.de>
Date: Wed May 27 14:52:51 CEST 2015
Patch-mainline: never, will be fixed differently in mainline
Git-commit:
References: bnc#921430

__sched_setscheduler() may release rq->lock in pull_rt_task() as a task is
being changed rt -> fair class.  load balancing may sneak in, move the task
behind __sched_setscheduler()'s back, which explodes in switched_to_fair()
when the passed but no longer valid rq is used.  Tell can_migrate_task() to
say no if ->pi_lock is held.

NOTE: mainline has to do much more due to SCHED_DEADLINE.  We don't have
that problem, can close the hole very simply, no 18 patch series needed.

Signed-off-by: Mike Galbraith <mgalbraith@suse.de>
---
 kernel/sched_fair.c |    9 +++++++++
 1 file changed, 9 insertions(+)

--- a/kernel/sched_fair.c
+++ b/kernel/sched_fair.c
@@ -2748,6 +2748,7 @@ int can_migrate_task(struct task_struct
 	 * 1) running (obviously), or
 	 * 2) cannot be migrated to this CPU due to cpus_allowed, or
 	 * 3) are cache-hot on their current CPU.
+	 * 4) p->pi_lock is held.
 	 */
 	if (!cpumask_test_cpu(this_cpu, tsk_cpus_allowed(p))) {
 		schedstat_inc(p, se.statistics.nr_failed_migrations_affine);
@@ -2761,6 +2762,14 @@ int can_migrate_task(struct task_struct
 	}
 
 	/*
+	 * rt -> fair class change may be in progress.  If we sneak in should
+	 * double_lock_balance() release rq->lock, and move the task, we will
+	 * cause switched_to_fair() to meet a passed but no longer valid rq.
+	 */
+	if (raw_spin_is_locked(&p->pi_lock))
+		return 0;
+
+	/*
 	 * Aggressive migration if:
 	 * 1) task is cache cold, or
 	 * 2) too many balance attempts have failed.
