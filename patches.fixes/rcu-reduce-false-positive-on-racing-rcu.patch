From: Michal Hocko <mhocko@suse.cz>
Subject: rcu: Do not trigger false positive RCU stall detection
Patch-mainline: no - different fix
References: bnc#834204

mhocko@suse.cz:
The upstream will fix it in a slightly different way but the primary idea is
same as in this patch. We took this approach because it has been tested by
the customer and proved to suppress the issue. This patch should be dropped
once we rebase on top of the kernel with the upstream fix.

There have been reports about RCU stall detections with grace period taking 0
Jiffies: 
[56315.876909] INFO: rcu_bh_state detected stall on CPU 64 (t=0 jiffies)
which is really strange and it turned out that those stalls were false positives.
Instrumented kernel has shown:
[38511.076299] INFO: rcu_bh_state detected stall on CPU 23 (t=0 jiffies) gp_start:4304520065 jiffies:4304520065 j:4304520065 js:4304520025 completed:1936 gpnum:1937

that the grace period has just started because gp_start matches the current
jiffies. check_cpu_stall sees both updated gpnum and gp_start but it still sees
the old jiffies_stall (js above which is in the past). check_cpu_stall doesn't
take rnp->lock so it is inherently racy.

One way to fix this issue would be taking the rnp->lock around the test but
that might cause the lock bouncing as this is called from every timer tick.

Another way would be trying to detect these false positives. jiffies_stall must
be always larger than gp_start and the current jiffies must be at least
RCU_STATE_INITIALIZER away from gp_start. We can use this invariant and use it
in the stall check for both CPU stall paths in check_cpu_stall. If the previous
jiffies > jiffies_stall check tells us we should warn we will re-check the
invariant and do not report any stall if it is not valid because that would
mean a race.

Signed-off-by: Michal Hocko <mhocko@suse.cz>

---
 kernel/rcutree.c |   22 +++++++++++++++++++---
 1 file changed, 19 insertions(+), 3 deletions(-)

--- a/kernel/rcutree.c
+++ b/kernel/rcutree.c
@@ -629,15 +629,31 @@ static void check_cpu_stall(struct rcu_s
 	rnp = rdp->mynode;
 	if (rcu_gp_in_progress(rsp) &&
 	    (ACCESS_ONCE(rnp->qsmask) & rdp->grpmask) && ULONG_CMP_GE(j, js)) {
+		unsigned long gp_start = ACCESS_ONCE(rsp->gp_start);
 
-		/* We haven't checked in, so go dump stack. */
-		print_cpu_stall(rsp);
+		/*
+		 * We have to recheck js > gp_start in both branches because we
+		 * are not holding rpn->lock and so we might race with
+		 * rcu_start_gp and see the new grace period which has started
+		 * right now but jiffies_stall has been fetched before it has
+		 * been updated or the update made visible. To be really sure
+		 * that we haven't missed record_gp_stall_check_time we have
+		 * to check that at least RCU_SECONDS_TILL_STALL_CHECK has
+		 * passed since the last update.
+		 */
+		if (ULONG_CMP_GE(js, gp_start) &&
+				(j - gp_start >= RCU_SECONDS_TILL_STALL_CHECK))
+			print_cpu_stall(rsp);
 
 	} else if (rcu_gp_in_progress(rsp) &&
 		   ULONG_CMP_GE(j, js + RCU_STALL_RAT_DELAY)) {
+		unsigned long gp_start = ACCESS_ONCE(rsp->gp_start);
 
 		/* They had a few time units to dump stack, so complain. */
-		print_other_cpu_stall(rsp);
+		if (ULONG_CMP_GE(js, gp_start) &&
+				(j - gp_start >= RCU_SECONDS_TILL_STALL_CHECK))
+			print_other_cpu_stall(rsp);
+
 	}
 }
 
