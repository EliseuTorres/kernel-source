From: Robin Holt <holt@sgi.com>
Subject: FS: fix max_files overflow
References: bnc#652391
Patch-mainline: never

We attempted to boot a machine with 16TB of memory.  It failed during
the initrd when udevd attempted to create a unix domain socket.
We tracked it down to unix_create1().  It is comparing unix_nr_socks >
2 * get_max_files().  Unfortunately, get_max_files is returning a value
large enough that the multiplication turns it into a negative value.

We figured there were numerous ways to fix it.  My first attempt at this
is to just limit max_files to 1/2 MAX_INT.

I am completely open to suggestions.  Unfortunately, booting this system
takes nearly five hours so "quick" testing of changes is not possible.

Fixed by 518de9b39e854542de59bfb8b9f61c8f7ecf808b upstream.

Signed-off-by: Robin Holt <holt@sgi.com>
Signed-off-by: Jiri Slaby <jslaby@suse.cz>

Index: linux-2.6.32/fs/file_table.c
===================================================================
--- linux-2.6.32.orig/fs/file_table.c	2010-10-03 11:58:34.000000000 -0500
+++ linux-2.6.32/fs/file_table.c	2010-10-03 12:21:51.435824997 -0500
@@ -451,7 +451,7 @@ void __init files_init(unsigned long mem
 	 * Per default don't use more than 10% of our memory for files. 
 	 */ 
 
-	n = (mempages * (PAGE_SIZE / 1024)) / 10;
+	n = min_t(unsigned long, INT_MAX >> 1, (mempages * (PAGE_SIZE / 1024)) / 10);
 	files_stat.max_files = n; 
 	if (files_stat.max_files < NR_FILE)
 		files_stat.max_files = NR_FILE;
