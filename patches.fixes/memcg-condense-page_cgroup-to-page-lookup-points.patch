From 5564e88ba6fd2f6dcd83a592771810cd84b5ae80 Mon Sep 17 00:00:00 2001
From: Johannes Weiner <hannes@cmpxchg.org>
Date: Wed, 23 Mar 2011 16:42:29 -0700
Subject: [PATCH] memcg: condense page_cgroup-to-page lookup points
Patch-mainline: 5564e88ba6fd2f6dcd83a592771810cd84b5ae80
References: bnc#704592

The per-cgroup LRU lists string up 'struct page_cgroup's.  To get from
those structures to the page they represent, a lookup is required.
Currently, the lookup is done through a direct pointer in struct
page_cgroup, so a lot of functions down the callchain do this lookup by
themselves instead of receiving the page pointer from their callers.

The next patch removes this pointer, however, and the lookup is no longer
that straight-forward.  In preparation for that, this patch only leaves
the non-optional lookups when coming directly from the LRU list and passes
the page down the stack.

Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
Cc: Balbir Singh <balbir@linux.vnet.ibm.com>
Cc: Minchan Kim <minchan.kim@gmail.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Acked-by: Michal Hocko <mhocko@suse.cz>

---
 mm/memcontrol.c |   38 +++++++++++++++++++++++---------------
 1 files changed, 23 insertions(+), 15 deletions(-)

Index: linux-2.6.32-memcg-backports/mm/memcontrol.c
===================================================================
--- linux-2.6.32-memcg-backports.orig/mm/memcontrol.c
+++ linux-2.6.32-memcg-backports/mm/memcontrol.c
@@ -964,9 +964,11 @@ unsigned long mem_cgroup_isolate_pages(u
 		if (scan >= nr_to_scan)
 			break;
 
-		page = pc->page;
 		if (unlikely(!PageCgroupUsed(pc)))
 			continue;
+
+		page = pc->page;
+
 		if (unlikely(!PageLRU(page)))
 			continue;
 
@@ -1725,6 +1727,7 @@ struct mem_cgroup *try_get_mem_cgroup_fr
  * USED state. If already USED, uncharge and return.
  */
 static void __mem_cgroup_commit_charge(struct mem_cgroup *mem,
+				       struct page *page,
 				       unsigned int nr_pages,
 				       struct page_cgroup *pc,
 				       enum charge_type ctype)
@@ -1825,7 +1828,7 @@ void mem_cgroup_split_huge_fixup(struct
  * new cgroup. It should be done by a caller.
  */
 
-static void __mem_cgroup_move_account(struct page_cgroup *pc,
+static void __mem_cgroup_move_account(struct page *page, struct page_cgroup *pc,
 	struct mem_cgroup *from, struct mem_cgroup *to,
 	unsigned int nr_pages)
 {
@@ -1836,7 +1839,7 @@ static void __mem_cgroup_move_account(st
 	unsigned long bytes = nr_pages * PAGE_SIZE;
 
 	VM_BUG_ON(from == to);
-	VM_BUG_ON(PageLRU(pc->page));
+	VM_BUG_ON(PageLRU(page));
 	VM_BUG_ON(!page_is_cgroup_locked(pc));
 	VM_BUG_ON(!PageCgroupUsed(pc));
 	VM_BUG_ON(pc->mem_cgroup != from);
@@ -1879,18 +1882,18 @@ static void __mem_cgroup_move_account(st
  * check whether the @pc is valid for moving account and call
  * __mem_cgroup_move_account()
  */
-static int mem_cgroup_move_account(struct page_cgroup *pc,
+static int mem_cgroup_move_account(struct page *page, struct page_cgroup *pc,
 				unsigned int nr_pages,
 				struct mem_cgroup *from, struct mem_cgroup *to)
 {
 	int ret = -EINVAL;
 
-	if ((nr_pages > 1) && !PageTransHuge(pc->page))
+	if ((nr_pages > 1) && !PageTransHuge(page))
 		return -EBUSY;
 
 	lock_page_cgroup(pc);
 	if (PageCgroupUsed(pc) && pc->mem_cgroup == from) {
-		__mem_cgroup_move_account(pc, from, to, nr_pages);
+		__mem_cgroup_move_account(page, pc, from, to, nr_pages);
 		ret = 0;
 	}
 	unlock_page_cgroup(pc);
@@ -1901,11 +1904,11 @@ static int mem_cgroup_move_account(struc
  * move charges to its parent.
  */
 
-static int mem_cgroup_move_parent(struct page_cgroup *pc,
+static int mem_cgroup_move_parent(struct page *page,
+				  struct page_cgroup *pc,
 				  struct mem_cgroup *child,
 				  gfp_t gfp_mask)
 {
-	struct page *page = pc->page;
 	struct cgroup *cg = child->css.cgroup;
 	struct cgroup *pcg = cg->parent;
 	struct mem_cgroup *parent;
@@ -1933,7 +1936,7 @@ static int mem_cgroup_move_parent(struct
 	if (nr_pages > 1)
 		flags = compound_lock_irqsave(page);
 
-	ret = mem_cgroup_move_account(pc, nr_pages, child, parent);
+	ret = mem_cgroup_move_account(page, pc, nr_pages, child, parent);
 	if (!ret)
 		css_put(&parent->css);	/* drop extra refcnt by try_charge() */
 	else
@@ -1982,7 +1985,7 @@ static int mem_cgroup_charge_common(stru
 	if (ret || !mem)
 		return ret;
 
-	__mem_cgroup_commit_charge(mem, nr_pages, pc, ctype);
+	__mem_cgroup_commit_charge(mem, page, nr_pages, pc, ctype);
 	return 0;
 }
 
@@ -2118,7 +2121,7 @@ __mem_cgroup_commit_charge_swapin(struct
 	cgroup_exclude_rmdir(&ptr->css);
 	pc = lookup_page_cgroup(page);
 	mem_cgroup_lru_del_before_commit_swapcache(page);
-	__mem_cgroup_commit_charge(ptr, 1, pc, ctype);
+	__mem_cgroup_commit_charge(ptr, page, 1, pc, ctype);
 	mem_cgroup_lru_add_after_commit_swapcache(page);
 	/*
 	 * Now swap is on-memory. This means this page may be
@@ -2517,7 +2520,7 @@ int mem_cgroup_prepare_migration(struct
 		ctype = MEM_CGROUP_CHARGE_TYPE_CACHE;
 	else
 		ctype = MEM_CGROUP_CHARGE_TYPE_SHMEM;
-	__mem_cgroup_commit_charge(mem, 1, pc, ctype);
+	__mem_cgroup_commit_charge(mem, page, 1, pc, ctype);
 	return ret;
 }
 
@@ -2842,6 +2845,8 @@ static int mem_cgroup_force_empty_list(s
 	loop += 256;
 	busy = NULL;
 	while (loop--) {
+		struct page *page;
+
 		ret = 0;
 		spin_lock_irqsave(&zone->lru_lock, flags);
 		if (list_empty(list)) {
@@ -2857,7 +2862,9 @@ static int mem_cgroup_force_empty_list(s
 		}
 		spin_unlock_irqrestore(&zone->lru_lock, flags);
 
-		ret = mem_cgroup_move_parent(pc, mem, GFP_KERNEL);
+		page = pc->page;
+
+		ret = mem_cgroup_move_parent(page, pc, mem, GFP_KERNEL);
 		if (ret == -ENOMEM)
 			break;
 
