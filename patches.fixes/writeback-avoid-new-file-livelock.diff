From: Jan Kara <jack@suse.cz>
Subject: mm: avoid resetting wb_start after each writeback round
Patch-mainline: yes
Git-commit-commit-id: 7624ee72aa09334af072853457a5d46d9901c3f8
References: bnc#649000

WB_SYNC_NONE writeback is done in rounds of 1024 pages so that we don't
write out some huge inode for too long while starving writeout of other
inodes.  To avoid livelocks, we record time we started writeback in
wbc->wb_start and do not write out inodes which were dirtied after this
time.  But currently, writeback_inodes_wb() resets wb_start each time it
is called thus effectively invalidating this logic and making any
WB_SYNC_NONE writeback prone to livelocks.

This patch makes sure wb_start is set only once when we start writeback.

Signed-off-by: Jan Kara <jack@suse.cz>
Reviewed-by: Wu Fengguang <fengguang.wu@intel.com>
Acked-by: Jens Axboe <jaxboe@fusionio.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

 fs/fs-writeback.c |   12 +++++++-----
 1 file changed, 7 insertions(+), 5 deletions(-)

diff -rupX /crypted/home/jack/.kerndiffexclude linux-2.6.32-writeback-SLE11-SP1-3-stop_background/fs/fs-writeback.c linux-2.6.32-writeback-SLE11-SP1-4-avoid_WB_SYNC_NONE_livelock/fs/fs-writeback.c
--- linux-2.6.32-writeback-SLE11-SP1-3-stop_background/fs/fs-writeback.c	2011-03-03 15:26:32.882118077 +0100
+++ linux-2.6.32-writeback-SLE11-SP1-4-avoid_WB_SYNC_NONE_livelock/fs/fs-writeback.c	2011-03-03 17:15:09.489652533 +0100
@@ -640,11 +640,11 @@ pinned:
 }
 
 static void writeback_inodes_wb(struct bdi_writeback *wb,
-				struct writeback_control *wbc, int locked)
+				struct writeback_control *wbc, int locked,
+				unsigned long start_jif)
 {
 	struct super_block *sb = wbc->sb, *pin_sb = NULL;
 	const int is_blkdev_sb = sb_is_blkdev_sb(sb);
-	const unsigned long start = jiffies;	/* livelock avoidance */
 
 	spin_lock(&inode_lock);
 
@@ -698,7 +698,7 @@ static void writeback_inodes_wb(struct b
 		 * Was this inode dirtied after sync_sb_inodes was called?
 		 * This keeps sync from extra jobs and livelock.
 		 */
-		if (inode_dirtied_after(inode, start))
+		if (inode_dirtied_after(inode, start_jif))
 			break;
 
 		if (pin_sb_for_writeback(sb, locked, &pin_sb)) {
@@ -739,7 +739,8 @@ void writeback_inodes_wbc(struct writeba
 {
 	struct backing_dev_info *bdi = wbc->bdi;
 
-	writeback_inodes_wb(&bdi->wb, wbc, wbc->sync_mode == WB_SYNC_ALL);
+	writeback_inodes_wb(&bdi->wb, wbc, wbc->sync_mode == WB_SYNC_ALL,
+			    jiffies);
 }
 
 /*
@@ -790,6 +791,7 @@ static long wb_writeback(struct bdi_writ
 	unsigned long oldest_jif;
 	long wrote = 0;
 	struct inode *inode;
+	unsigned long start_jif = jiffies;	/* Livelock avoidance */
 
 	if (wbc.for_kupdate) {
 		wbc.older_than_this = &oldest_jif;
@@ -829,7 +831,7 @@ static long wb_writeback(struct bdi_writ
 		wbc.encountered_congestion = 0;
 		wbc.nr_to_write = MAX_WRITEBACK_PAGES;
 		wbc.pages_skipped = 0;
-		writeback_inodes_wb(wb, &wbc, args->locked);
+		writeback_inodes_wb(wb, &wbc, args->locked, start_jif);
 		args->nr_pages -= MAX_WRITEBACK_PAGES - wbc.nr_to_write;
 		wrote += MAX_WRITEBACK_PAGES - wbc.nr_to_write;
 

