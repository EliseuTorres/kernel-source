From 9b9870b9985f2f3851587e5bd735314147036e48 Mon Sep 17 00:00:00 2001
From: Chris Wilson <chris@chris-wilson.co.uk>
Date: Tue, 28 Sep 2010 10:07:56 +0100
Patch-mainline: 2.6.37
References: fate#310916
Git-commit: a56ba56c275b1c2b982c8901ab92bf5a0fd0b757
Subject: [PATCH 1500/2588] Revert "drm/i915: Drop ring->lazy_request"

With multiple rings generating requests independently, the outstanding
requests must also be track independently.

Reported-by: Wang Jinjin <jinjin.wang@intel.com>
Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=30380
Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
(cherry picked from commit a56ba56c275b1c2b982c8901ab92bf5a0fd0b757)

Signed-off-by: Takashi Iwai <tiwai@suse.de>
---
 drivers/gpu/drm/i915/i915_gem.c         |   43 +++++++++++++++++++++---------
 drivers/gpu/drm/i915/intel_ringbuffer.h |    5 +++
 2 files changed, 35 insertions(+), 13 deletions(-)

diff --git a/drivers/gpu/drm/i915/i915_gem.c b/drivers/gpu/drm/i915/i915_gem.c
index 1d99b8b..868b786 100644
--- a/drivers/gpu/drm/i915/i915_gem.c
+++ b/drivers/gpu/drm/i915/i915_gem.c
@@ -1547,12 +1547,23 @@ i915_gem_object_put_pages(struct drm_gem_object *obj)
 	obj_priv->pages = NULL;
 }
 
+static uint32_t
+i915_gem_next_request_seqno(struct drm_device *dev,
+			    struct intel_ring_buffer *ring)
+{
+	drm_i915_private_t *dev_priv = dev->dev_private;
+
+	ring->outstanding_lazy_request = true;
+	return dev_priv->next_seqno;
+}
+
 static void
 i915_gem_object_move_to_active(struct drm_gem_object *obj,
 			       struct intel_ring_buffer *ring)
 {
-	struct drm_i915_private *dev_priv = obj->dev->dev_private;
+	struct drm_device *dev = obj->dev;
 	struct drm_i915_gem_object *obj_priv = to_intel_bo(obj);
+	uint32_t seqno = i915_gem_next_request_seqno(dev, ring);
 
 	BUG_ON(ring == NULL);
 	obj_priv->ring = ring;
@@ -1565,7 +1576,7 @@ i915_gem_object_move_to_active(struct drm_gem_object *obj,
 
 	/* Move from whatever list we were on to the tail of execution. */
 	list_move_tail(&obj_priv->list, &ring->active_list);
-	obj_priv->last_rendering_seqno = dev_priv->next_seqno;
+	obj_priv->last_rendering_seqno = seqno;
 }
 
 static void
@@ -1688,6 +1699,7 @@ i915_add_request(struct drm_device *dev,
 	}
 
 	seqno = ring->add_request(dev, ring, 0);
+	ring->outstanding_lazy_request = false;
 
 	request->seqno = seqno;
 	request->ring = ring;
@@ -1932,11 +1944,12 @@ i915_do_wait_request(struct drm_device *dev, uint32_t seqno,
 	if (atomic_read(&dev_priv->mm.wedged))
 		return -EAGAIN;
 
-	if (seqno == dev_priv->next_seqno) {
+	if (ring->outstanding_lazy_request) {
 		seqno = i915_add_request(dev, NULL, NULL, ring);
 		if (seqno == 0)
 			return -ENOMEM;
 	}
+	BUG_ON(seqno == dev_priv->next_seqno);
 
 	if (!i915_seqno_passed(ring->get_seqno(dev, ring), seqno)) {
 		if (HAS_PCH_SPLIT(dev))
@@ -1995,7 +2008,7 @@ i915_do_wait_request(struct drm_device *dev, uint32_t seqno,
  */
 static int
 i915_wait_request(struct drm_device *dev, uint32_t seqno,
-		struct intel_ring_buffer *ring)
+		  struct intel_ring_buffer *ring)
 {
 	return i915_do_wait_request(dev, seqno, 1, ring);
 }
@@ -2141,12 +2154,21 @@ i915_gem_object_unbind(struct drm_gem_object *obj)
 	return ret;
 }
 
+static int i915_ring_idle(struct drm_device *dev,
+			  struct intel_ring_buffer *ring)
+{
+	i915_gem_flush_ring(dev, NULL, ring,
+			    I915_GEM_GPU_DOMAINS, I915_GEM_GPU_DOMAINS);
+	return i915_wait_request(dev,
+				 i915_gem_next_request_seqno(dev, ring),
+				 ring);
+}
+
 int
 i915_gpu_idle(struct drm_device *dev)
 {
 	drm_i915_private_t *dev_priv = dev->dev_private;
 	bool lists_empty;
-	u32 seqno;
 	int ret;
 
 	lists_empty = (list_empty(&dev_priv->mm.flushing_list) &&
@@ -2157,18 +2179,12 @@ i915_gpu_idle(struct drm_device *dev)
 		return 0;
 
 	/* Flush everything onto the inactive list. */
-	seqno = dev_priv->next_seqno;
-	i915_gem_flush_ring(dev, NULL, &dev_priv->render_ring,
-			    I915_GEM_GPU_DOMAINS, I915_GEM_GPU_DOMAINS);
-	ret = i915_wait_request(dev, seqno, &dev_priv->render_ring);
+	ret = i915_ring_idle(dev, &dev_priv->render_ring);
 	if (ret)
 		return ret;
 
 	if (HAS_BSD(dev)) {
-		seqno = dev_priv->next_seqno;
-		i915_gem_flush_ring(dev, NULL, &dev_priv->bsd_ring,
-				    I915_GEM_GPU_DOMAINS, I915_GEM_GPU_DOMAINS);
-		ret = i915_wait_request(dev, seqno, &dev_priv->bsd_ring);
+		ret = i915_ring_idle(dev, &dev_priv->bsd_ring);
 		if (ret)
 			return ret;
 	}
@@ -3941,6 +3957,7 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
 		DRM_INFO("%s: move to exec list %p\n", __func__, obj);
 #endif
 	}
+
 	i915_add_request(dev, file_priv, request, ring);
 	request = NULL;
 
diff --git a/drivers/gpu/drm/i915/intel_ringbuffer.h b/drivers/gpu/drm/i915/intel_ringbuffer.h
index c509192..9725f78 100644
--- a/drivers/gpu/drm/i915/intel_ringbuffer.h
+++ b/drivers/gpu/drm/i915/intel_ringbuffer.h
@@ -81,6 +81,11 @@ struct  intel_ring_buffer {
 	 */
 	struct list_head request_list;
 
+	/**
+	 * Do we have some not yet emitted requests outstanding?
+	 */
+	bool outstanding_lazy_request;
+
 	wait_queue_head_t irq_queue;
 	drm_local_map_t map;
 };
-- 
1.7.6

