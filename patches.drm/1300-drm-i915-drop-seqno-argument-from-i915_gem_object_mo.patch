From f2ebe119918335aaba4d9a1e1635c25b4be9a71a Mon Sep 17 00:00:00 2001
From: Daniel Vetter <daniel.vetter@ffwll.ch>
Date: Thu, 11 Feb 2010 22:16:02 +0100
Patch-mainline: 2.6.37
References: fate#310916
Git-commit: 617dbe2787568316eed976f533f93c31fdbc75b9
Subject: [PATCH 1300/2588] drm/i915: drop seqno argument from
 i915_gem_object_move_to_active

By moving one i915_add_request we can solely depend on the new
auto-seqno-numbering behaviour.

Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
(cherry picked from commit 617dbe2787568316eed976f533f93c31fdbc75b9)

Signed-off-by: Takashi Iwai <tiwai@suse.de>
---
 drivers/gpu/drm/i915/i915_gem.c |   28 ++++++++++++++--------------
 1 files changed, 14 insertions(+), 14 deletions(-)

diff --git a/drivers/gpu/drm/i915/i915_gem.c b/drivers/gpu/drm/i915/i915_gem.c
index 1f4c89d..9affbb6 100644
--- a/drivers/gpu/drm/i915/i915_gem.c
+++ b/drivers/gpu/drm/i915/i915_gem.c
@@ -1483,12 +1483,14 @@ i915_gem_next_request_seqno(struct drm_device *dev,
 }
 
 static void
-i915_gem_object_move_to_active(struct drm_gem_object *obj, uint32_t seqno,
+i915_gem_object_move_to_active(struct drm_gem_object *obj,
 			       struct intel_ring_buffer *ring)
 {
 	struct drm_device *dev = obj->dev;
 	drm_i915_private_t *dev_priv = dev->dev_private;
 	struct drm_i915_gem_object *obj_priv = to_intel_bo(obj);
+	uint32_t seqno = i915_gem_next_request_seqno(dev, ring);
+
 	BUG_ON(ring == NULL);
 	obj_priv->ring = ring;
 
@@ -1498,10 +1500,6 @@ i915_gem_object_move_to_active(struct drm_gem_object *obj, uint32_t seqno,
 		obj_priv->active = 1;
 	}
 
-	/* Take the seqno of the next request if none is given */
-	if (seqno == 0)
-		seqno = i915_gem_next_request_seqno(dev, ring);
-
 	/* Move from whatever list we were on to the tail of execution. */
 	spin_lock(&dev_priv->mm.active_list_lock);
 	list_move_tail(&obj_priv->list, &ring->active_list);
@@ -1592,7 +1590,7 @@ i915_gem_process_flushing_list(struct drm_device *dev,
 
 			obj->write_domain = 0;
 			list_del_init(&obj_priv->gpu_write_list);
-			i915_gem_object_move_to_active(obj, 0, ring);
+			i915_gem_object_move_to_active(obj, ring);
 
 			/* update the fence lru list */
 			if (obj_priv->fence_reg != I915_FENCE_REG_NONE) {
@@ -3833,6 +3831,16 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
 
 	i915_verify_inactive(dev, __FILE__, __LINE__);
 
+	for (i = 0; i < args->buffer_count; i++) {
+		struct drm_gem_object *obj = object_list[i];
+		obj_priv = to_intel_bo(obj);
+
+		i915_gem_object_move_to_active(obj, ring);
+#if WATCH_LRU
+		DRM_INFO("%s: move to exec list %p\n", __func__, obj);
+#endif
+	}
+
 	/*
 	 * Get a seqno representing the execution of the current buffer,
 	 * which we can wait on.  We would like to mitigate these interrupts,
@@ -3841,15 +3849,7 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
 	 * wait on when trying to clear up gtt space).
 	 */
 	seqno = i915_add_request(dev, file_priv, ring);
-	for (i = 0; i < args->buffer_count; i++) {
-		struct drm_gem_object *obj = object_list[i];
-		obj_priv = to_intel_bo(obj);
 
-		i915_gem_object_move_to_active(obj, seqno, ring);
-#if WATCH_LRU
-		DRM_INFO("%s: move to exec list %p\n", __func__, obj);
-#endif
-	}
 #if WATCH_LRU
 	i915_dump_lru(dev, __func__);
 #endif
-- 
1.7.6

