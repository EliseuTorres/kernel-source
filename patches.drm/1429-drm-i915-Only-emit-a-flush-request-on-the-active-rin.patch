From 1fe90fc03aa0b3b49fa20c3022ce8d999e26a099 Mon Sep 17 00:00:00 2001
From: Chris Wilson <chris@chris-wilson.co.uk>
Date: Sat, 18 Sep 2010 11:02:01 +0100
Patch-mainline: 2.6.37
References: fate#310916
Git-commit: 9220434a8768902cd9cf248709972678b74aa8c1
Subject: [PATCH 1429/2588] drm/i915: Only emit a flush request on the active
 ring.

When flushing the GPU domains,we emit a flush on *both* rings, even
though they share a unified cache. Only emit the flush on the currently
active ring.

Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
(cherry picked from commit 9220434a8768902cd9cf248709972678b74aa8c1)

Signed-off-by: Takashi Iwai <tiwai@suse.de>
---
 drivers/gpu/drm/i915/i915_drv.h         |    5 +--
 drivers/gpu/drm/i915/i915_gem.c         |   58 +++++++++++++++++++++++--------
 drivers/gpu/drm/i915/intel_ringbuffer.c |    6 +--
 drivers/gpu/drm/i915/intel_ringbuffer.h |    4 ++
 4 files changed, 51 insertions(+), 22 deletions(-)

diff --git a/drivers/gpu/drm/i915/i915_drv.h b/drivers/gpu/drm/i915/i915_drv.h
index 4b6aeb5..ed09846 100644
--- a/drivers/gpu/drm/i915/i915_drv.h
+++ b/drivers/gpu/drm/i915/i915_drv.h
@@ -623,6 +623,8 @@ typedef struct drm_i915_private {
 
 		/* storage for physical objects */
 		struct drm_i915_gem_phys_object *phys_objs[I915_MAX_PHYS_OBJECT];
+
+		uint32_t flush_rings;
 	} mm;
 	struct sdvo_device_mapping sdvo_mappings[2];
 	/* indicate whether the LVDS_BORDER should be enabled or not */
@@ -1014,9 +1016,6 @@ int i915_do_wait_request(struct drm_device *dev,
 			 bool interruptible,
 			 struct intel_ring_buffer *ring);
 int i915_gem_fault(struct vm_area_struct *vma, struct vm_fault *vmf);
-void i915_gem_process_flushing_list(struct drm_device *dev,
-				    uint32_t flush_domains,
-				    struct intel_ring_buffer *ring);
 int i915_gem_object_set_to_gtt_domain(struct drm_gem_object *obj,
 				      int write);
 int i915_gem_object_set_to_display_plane(struct drm_gem_object *obj,
diff --git a/drivers/gpu/drm/i915/i915_gem.c b/drivers/gpu/drm/i915/i915_gem.c
index d930478..a4c74b1 100644
--- a/drivers/gpu/drm/i915/i915_gem.c
+++ b/drivers/gpu/drm/i915/i915_gem.c
@@ -1569,7 +1569,7 @@ i915_gem_object_move_to_inactive(struct drm_gem_object *obj)
 	i915_verify_inactive(dev, __FILE__, __LINE__);
 }
 
-void
+static void
 i915_gem_process_flushing_list(struct drm_device *dev,
 			       uint32_t flush_domains,
 			       struct intel_ring_buffer *ring)
@@ -1882,23 +1882,36 @@ i915_wait_request(struct drm_device *dev, uint32_t seqno,
 }
 
 static void
+i915_gem_flush_ring(struct drm_device *dev,
+		    struct intel_ring_buffer *ring,
+		    uint32_t invalidate_domains,
+		    uint32_t flush_domains)
+{
+	ring->flush(dev, ring, invalidate_domains, flush_domains);
+	i915_gem_process_flushing_list(dev, flush_domains, ring);
+}
+
+static void
 i915_gem_flush(struct drm_device *dev,
 	       uint32_t invalidate_domains,
-	       uint32_t flush_domains)
+	       uint32_t flush_domains,
+	       uint32_t flush_rings)
 {
 	drm_i915_private_t *dev_priv = dev->dev_private;
 
 	if (flush_domains & I915_GEM_DOMAIN_CPU)
 		drm_agp_chipset_flush(dev);
 
-	dev_priv->render_ring.flush(dev, &dev_priv->render_ring,
-			invalidate_domains,
-			flush_domains);
-
-	if (HAS_BSD(dev))
-		dev_priv->bsd_ring.flush(dev, &dev_priv->bsd_ring,
-				invalidate_domains,
-				flush_domains);
+	if ((flush_domains | invalidate_domains) & I915_GEM_GPU_DOMAINS) {
+		if (flush_rings & RING_RENDER)
+			i915_gem_flush_ring(dev,
+					    &dev_priv->render_ring,
+					    invalidate_domains, flush_domains);
+		if (flush_rings & RING_BSD)
+			i915_gem_flush_ring(dev,
+					    &dev_priv->bsd_ring,
+					    invalidate_domains, flush_domains);
+	}
 }
 
 /**
@@ -2024,7 +2037,9 @@ i915_gpu_idle(struct drm_device *dev)
 		return 0;
 
 	/* Flush everything onto the inactive list. */
-	i915_gem_flush(dev, I915_GEM_GPU_DOMAINS, I915_GEM_GPU_DOMAINS);
+	i915_gem_flush_ring(dev,
+			    &dev_priv->render_ring,
+			    I915_GEM_GPU_DOMAINS, I915_GEM_GPU_DOMAINS);
 
 	ret = i915_wait_request(dev,
 				i915_gem_next_request_seqno(dev, &dev_priv->render_ring),
@@ -2033,6 +2048,10 @@ i915_gpu_idle(struct drm_device *dev)
 		return ret;
 
 	if (HAS_BSD(dev)) {
+		i915_gem_flush_ring(dev,
+				    &dev_priv->bsd_ring,
+				    I915_GEM_GPU_DOMAINS, I915_GEM_GPU_DOMAINS);
+
 		ret = i915_wait_request(dev,
 					i915_gem_next_request_seqno(dev, &dev_priv->bsd_ring),
 					&dev_priv->bsd_ring);
@@ -2599,7 +2618,9 @@ i915_gem_object_flush_gpu_write_domain(struct drm_gem_object *obj,
 
 	/* Queue the GPU write cache flushing we need. */
 	old_write_domain = obj->write_domain;
-	i915_gem_flush(dev, 0, obj->write_domain);
+	i915_gem_flush_ring(dev,
+			    to_intel_bo(obj)->ring,
+			    0, obj->write_domain);
 	BUG_ON(obj->write_domain);
 
 	trace_i915_gem_object_change_domain(obj,
@@ -2909,6 +2930,7 @@ static void
 i915_gem_object_set_to_gpu_domain(struct drm_gem_object *obj)
 {
 	struct drm_device		*dev = obj->dev;
+	struct drm_i915_private		*dev_priv = dev->dev_private;
 	struct drm_i915_gem_object	*obj_priv = to_intel_bo(obj);
 	uint32_t			invalidate_domains = 0;
 	uint32_t			flush_domains = 0;
@@ -2973,6 +2995,8 @@ i915_gem_object_set_to_gpu_domain(struct drm_gem_object *obj)
 
 	dev->invalidate_domains |= invalidate_domains;
 	dev->flush_domains |= flush_domains;
+	if (obj_priv->ring)
+		dev_priv->mm.flush_rings |= obj_priv->ring->id;
 #if WATCH_BUF
 	DRM_INFO("%s: read %08x write %08x invalidate %08x flush %08x\n",
 		 __func__,
@@ -3687,6 +3711,7 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
 	 */
 	dev->invalidate_domains = 0;
 	dev->flush_domains = 0;
+	dev_priv->mm.flush_rings = 0;
 
 	for (i = 0; i < args->buffer_count; i++) {
 		struct drm_gem_object *obj = object_list[i];
@@ -3706,7 +3731,8 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
 #endif
 		i915_gem_flush(dev,
 			       dev->invalidate_domains,
-			       dev->flush_domains);
+			       dev->flush_domains,
+			       dev_priv->mm.flush_rings);
 	}
 
 	if (dev_priv->render_ring.outstanding_lazy_request) {
@@ -4173,8 +4199,10 @@ i915_gem_busy_ioctl(struct drm_device *dev, void *data,
 		 * use this buffer rather sooner than later, so issuing the required
 		 * flush earlier is beneficial.
 		 */
-		if (obj->write_domain) {
-			i915_gem_flush(dev, 0, obj->write_domain);
+		if (obj->write_domain & I915_GEM_GPU_DOMAINS) {
+			i915_gem_flush_ring(dev,
+					    obj_priv->ring,
+					    0, obj->write_domain);
 			(void)i915_add_request(dev, file_priv, NULL, obj_priv->ring);
 		}
 
diff --git a/drivers/gpu/drm/i915/intel_ringbuffer.c b/drivers/gpu/drm/i915/intel_ringbuffer.c
index 670f94a..45f66e2 100644
--- a/drivers/gpu/drm/i915/intel_ringbuffer.c
+++ b/drivers/gpu/drm/i915/intel_ringbuffer.c
@@ -116,8 +116,6 @@ render_ring_flush(struct drm_device *dev,
 		intel_ring_emit(dev, ring, MI_NOOP);
 		intel_ring_advance(dev, ring);
 	}
-
-	i915_gem_process_flushing_list(dev, flush_domains, ring);
 }
 
 static unsigned int render_ring_get_head(struct drm_device *dev,
@@ -386,8 +384,6 @@ bsd_ring_flush(struct drm_device *dev,
 	intel_ring_emit(dev, ring, MI_FLUSH);
 	intel_ring_emit(dev, ring, MI_NOOP);
 	intel_ring_advance(dev, ring);
-
-	i915_gem_process_flushing_list(dev, flush_domains, ring);
 }
 
 static inline unsigned int bsd_ring_get_head(struct drm_device *dev,
@@ -799,6 +795,7 @@ void intel_fill_struct(struct drm_device *dev,
 
 struct intel_ring_buffer render_ring = {
 	.name			= "render ring",
+	.id			= RING_RENDER,
 	.regs                   = {
 		.ctl = PRB0_CTL,
 		.head = PRB0_HEAD,
@@ -836,6 +833,7 @@ struct intel_ring_buffer render_ring = {
 
 struct intel_ring_buffer bsd_ring = {
 	.name                   = "bsd ring",
+	.id			= RING_BSD,
 	.regs			= {
 		.ctl = BSD_RING_CTL,
 		.head = BSD_RING_HEAD,
diff --git a/drivers/gpu/drm/i915/intel_ringbuffer.h b/drivers/gpu/drm/i915/intel_ringbuffer.h
index fa5d84f..8dc0e62 100644
--- a/drivers/gpu/drm/i915/intel_ringbuffer.h
+++ b/drivers/gpu/drm/i915/intel_ringbuffer.h
@@ -10,6 +10,10 @@ struct  intel_hw_status_page {
 struct drm_i915_gem_execbuffer2;
 struct  intel_ring_buffer {
 	const char	*name;
+	enum intel_ring_id {
+		RING_RENDER = 0x1,
+		RING_BSD = 0x2,
+	} id;
 	struct		ring_regs {
 			u32 ctl;
 			u32 head;
-- 
1.7.6

